{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nani: []\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "USE_MIXED = False\n",
    "USE_PRESSURE_TEMP = False\n",
    "noise_std_dev = 1e-3\n",
    "\n",
    "\n",
    "if USE_MIXED:\n",
    "    filenames_vis = ['fog_data_vis_clear.dat', 'fog_data_vis_ice.dat', 'fog_data_vis_mixed.dat', 'fog_data_vis_water.dat']\n",
    "    filenames_ir = ['fog_data_ir_clear.dat', 'fog_data_ir_ice.dat', 'fog_data_ir_mixed.dat', 'fog_data_ir_water.dat']\n",
    "else:\n",
    "    filenames_vis = ['fog_data_vis_clear.dat', 'fog_data_vis_ice.dat', 'fog_data_vis_water.dat']\n",
    "    filenames_ir = ['fog_data_ir_clear.dat', 'fog_data_ir_ice.dat', 'fog_data_ir_water.dat']\n",
    "\n",
    "target_i = 30 # Visibility\n",
    "if USE_PRESSURE_TEMP:\n",
    "    features_i = np.concatenate((np.arange(4, 17), np.arange(20, 30), np.arange(31,36))) # 13 ir bands, 10 vis bands, 3 angles, pressure, temp\n",
    "else:\n",
    "    features_i = np.concatenate((np.arange(4, 17), np.arange(20, 30), np.arange(31,34)))\n",
    "\n",
    "\n",
    "\n",
    "data_ir_vis = []\n",
    "\n",
    "for file_ir, file_vis in zip(filenames_ir, filenames_vis):\n",
    "  raw_data_ir = pd.read_csv('fog_dataset/' + file_ir).to_numpy()\n",
    "  raw_data_vis = pd.read_csv('fog_dataset/' + file_vis).to_numpy()\n",
    "\n",
    "  data_ir = np.array([row[0].split() for row in raw_data_ir[25:]])\n",
    "  data_vis = np.array([row[0].split()[1:] for row in raw_data_vis[41:]])\n",
    "\n",
    "  if len(data_ir_vis) == 0:\n",
    "    data_ir_vis = np.hstack([data_ir, data_vis])\n",
    "  else:\n",
    "    data_ir_vis = np.vstack([data_ir_vis, np.hstack([data_ir, data_vis])])\n",
    "\n",
    "\n",
    "# Remove surface description to convert to float\n",
    "data_ir_vis = data_ir_vis[:,:-1] \n",
    "data_ir_vis = data_ir_vis.astype(np.double)\n",
    "\n",
    "nan_i = np.where(np.isnan(data_ir_vis))[0]\n",
    "data_ir_vis = np.delete(data_ir_vis, nan_i, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "X = np.zeros((data_ir_vis.shape[0], len(features_i)))\n",
    "y = np.zeros(data_ir_vis.shape[0])\n",
    "\n",
    "for i in range(len(data_ir_vis)):\n",
    "  X[i] = data_ir_vis[i, features_i]\n",
    "  y[i] = data_ir_vis[i,target_i]\n",
    "\n",
    "# 19 Data points contains nan. Not sure why. Band 32 culprit, 8th feature\n",
    "nan_i = np.where(np.isnan(X))[0]\n",
    "print(f'nani: {nan_i}')\n",
    "X = np.delete(X, nan_i, axis=0)\n",
    "y = np.delete(y, nan_i, axis=0)\n",
    "\n",
    "\n",
    "# Scaling features\n",
    "feature_scaler = StandardScaler()\n",
    "X_scaled = feature_scaler.fit_transform(X)\n",
    "\n",
    "X_scaled_noisy = X_scaled + np.random.normal(0, noise_std_dev, X_scaled.shape)\n",
    "\n",
    "# Scaling target\n",
    "target_scaler = StandardScaler()\n",
    "y_scaled = target_scaler.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "\n",
    "# First split: Separate out a test set (5% of the original dataset)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X_scaled_noisy, y_scaled, test_size=(1/20), random_state=16)\n",
    "\n",
    "# Second split: Split the remaining data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=(1/19), random_state=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149989, 26)\n",
      "['band20', 'band21', 'band22', 'band23', 'band24', 'band25', 'band27', 'band28', 'band29', 'band30', 'band31', 'band32', 'band33', 'band11', 'band12', 'band13', 'band14', 'band15', 'band16', 'band17', 'band18', 'band19', 'band26', 'sat_angle', 'sun_angle', 'azimuth_angle', 'visibility']\n"
     ]
    }
   ],
   "source": [
    " \n",
    "print(X_scaled_noisy.shape)\n",
    "\n",
    "\n",
    "\n",
    "cat_cols = []\n",
    "\n",
    "num_cols = ['band20', 'band21', 'band22', 'band23', 'band24', 'band25',\n",
    "       'band27', 'band28', 'band29', 'band30', 'band31', 'band32', \n",
    "       'band33', 'band11', 'band12', 'band13', 'band14', 'band15',\n",
    "       'band16', 'band17', 'band18', 'band19', 'band26', 'sat_angle',\n",
    "       'sun_angle', 'azimuth_angle']#, 'temperature', 'pressure']\n",
    "target=[\"visibility\"]\n",
    "\n",
    "y_pd = pd.Series(y_scaled.flatten(), name='visibility')\n",
    "X_pd = pd.DataFrame(X_scaled_noisy, columns=num_cols)\n",
    "data_pd = X_pd.join(y_pd)\n",
    "print(list(data_pd.columns))\n",
    "#print(list(data_pd[\"visibility\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data_pd, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset \n",
    "import copy\n",
    "\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "        \n",
    "    def copy(self):\n",
    "        return copy.deepcopy(self)\n",
    "    def loc(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "train_dataset = TabularDataset(X_train, y_train)\n",
    "val_dataset = TabularDataset(X_val, y_val)\n",
    "test_dataset = TabularDataset(X_test, y_test)\n",
    "\n",
    "print(type(y_train))\n",
    "print(type(y_val))\n",
    "print(type(y_test))\n",
    "\n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_dl = DataLoader(val_dataset, batch_size=256)\n",
    "test_dl = DataLoader(test_dataset, batch_size=256) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import (\n",
    "    CategoryEmbeddingModelConfig, \n",
    "    FTTransformerConfig, \n",
    "    TabNetModelConfig, \n",
    "    GatedAdditiveTreeEnsembleConfig, \n",
    "    TabTransformerConfig, \n",
    "    AutoIntConfig\n",
    ")\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = DataConfig(\n",
    "    target=target, #target should always be a list.\n",
    "    continuous_cols=num_cols,\n",
    ")\n",
    "\n",
    "trainer_config = TrainerConfig(\n",
    "#     auto_lr_find=True, # Runs the LRFinder to automatically derive a learning rate\n",
    "    batch_size=256,\n",
    "    max_epochs=500,\n",
    "    early_stopping=\"valid_loss\", # Monitor valid_loss for early stopping\n",
    "    early_stopping_mode = \"min\", # Set the mode as min because for val_loss, lower is better\n",
    "    early_stopping_patience=5, # No. of epochs of degradation training will wait before terminating\n",
    "    checkpoints=\"valid_loss\", # Save best checkpoint monitoring val_loss\n",
    "    load_best=True, # After training, load the best checkpoint\n",
    ")\n",
    "\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "head_config = LinearHeadConfig(\n",
    "    layers=\"\", # No additional layer in head, just a mapping layer to output_dim\n",
    "    dropout=0.1,\n",
    "    initialization=\"kaiming\"\n",
    ").__dict__ # Convert to dict to pass to the model config (OmegaConf doesn't accept objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:56:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">034</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">140</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m04\u001b[0m \u001b[1;92m14:56:44\u001b[0m,\u001b[1;36m034\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m140\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:56:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">055</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">524</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m04\u001b[0m \u001b[1;92m14:56:44\u001b[0m,\u001b[1;36m055\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m524\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:56:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">073</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:499</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m04\u001b[0m \u001b[1;92m14:56:44\u001b[0m,\u001b[1;36m073\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:499\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:56:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">162</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">574</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: FTTransformerModel     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m04\u001b[0m \u001b[1;92m14:56:44\u001b[0m,\u001b[1;36m162\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m574\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: FTTransformerModel     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:56:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">187</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">340</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m04\u001b[0m \u001b[1;92m14:56:44\u001b[0m,\u001b[1;36m187\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m340\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:56:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">586</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">652</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m04\u001b[0m \u001b[1;92m14:56:44\u001b[0m,\u001b[1;36m586\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m652\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 14:56:44.808427: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 14:56:44.839282: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 14:56:44.839303: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 14:56:44.840085: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 14:56:44.845563: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 14:56:45.600410: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/edgelab/.local/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:639: Checkpoint directory /home/edgelab/SEEX30_Cloud_Fog/fog/saved_models exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ FTTransformerBackbone │  271 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding2dLayer      │  1.7 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ LinearHead            │     33 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss               │      0 │\n",
       "└───┴──────────────────┴───────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                 \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ FTTransformerBackbone │  271 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding2dLayer      │  1.7 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ LinearHead            │     33 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss               │      0 │\n",
       "└───┴──────────────────┴───────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 273 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 273 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 1                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 273 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 273 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 1                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a67a13ab60f405492a6fd73cb804f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/edgelab/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The \n",
       "'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \n",
       "`num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/edgelab/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The \n",
       "'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \n",
       "`num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/edgelab/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The \n",
       "'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \n",
       "`num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/edgelab/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The \n",
       "'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \n",
       "`num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "model_config = FTTransformerConfig(\n",
    "    task=\"regression\",\n",
    "    learning_rate = 1e-3,\n",
    "    head = \"LinearHead\", #Linear Head\n",
    "    head_config = head_config, # Linear Head Config\n",
    ")\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=256, shuffle=True, num_workers=19)\n",
    "val_loader = DataLoader(test, batch_size=256, shuffle=False, num_workers=19) \n",
    "\n",
    "#tabular_model.fit(train)\n",
    "#tabular_model.evaluate(test)\n",
    "tabular_model.fit(train_loader) \n",
    "tabular_model.evaluate(val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

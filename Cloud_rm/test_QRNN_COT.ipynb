{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\filip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\filip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\filip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import layers\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.python.keras.callbacks import Callback\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "import functions.parse_data as parse\n",
    "import functions.models as md\n",
    "import functions.handy_functions as hf\n",
    "\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import Image\n",
    "\n",
    "from tensorflow_probability import layers as tfpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_water=parse.parse('cloudrm_water.dat')\n",
    "data_clear=parse.parse('cloudrm_clear.dat')\n",
    "data_ice=parse.parse('cloudrm_ice.dat')\n",
    "data_mixed=parse.parse('cloudrm_mixed.dat')\n",
    "\n",
    "#Concatinate all datasets\n",
    "data_all=pd.concat([data_water, data_clear, data_ice, data_mixed])\n",
    "data_all=data_all.drop(columns=['Surface_Desc','Cloud_B01','Clear_B01'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function taken from: https://github.com/sachinruk/KerasQuantileModel/blob/master/Keras%20Quantile%20Model.ipynb\n",
    "#As a notebook from reading: https://towardsdatascience.com/deep-quantile-regression-c85481548b5a\n",
    "def tilted_loss(q,y,f):\n",
    "    e = (y-f)\n",
    "    return K.mean(K.maximum(q*e, (q-1)*e), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\filip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\filip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:From c:\\Users\\filip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "1800/1800 [==============================] - 55s 30ms/step - loss: 35.7907 - mse: 35.7907 - val_loss: 11.5850 - val_mse: 11.5850\n",
      "Epoch 2/2\n",
      "1800/1800 [==============================] - 54s 30ms/step - loss: 12.6319 - mse: 12.6319 - val_loss: 10.5552 - val_mse: 10.5552\n"
     ]
    }
   ],
   "source": [
    "##Train test validation split##\n",
    "X_labels= ['Cloud_B02','Cloud_B03','Cloud_B04','Cloud_B05','Cloud_B06',\n",
    "           'Cloud_B07','Cloud_B08','Cloud_B09','Cloud_B10','Cloud_B11','Cloud_B12','Cloud_B13',\n",
    "           'Sat_Zenith_Angle','Sun_Zenith_Angle','Azimuth_Diff_Angle','Cloud_Type','Profile_ID','GOT','Water_Vapor']\n",
    "\n",
    "#Leave out 'GOT', 'Water_Vapor'\n",
    "#Band 1 no go.\n",
    "\n",
    "y_labels=['COT']\n",
    "\n",
    "df=hf.normalise_input_df(data_all,X_labels)\n",
    "df=hf.add_noise(df,X_labels,sigma=0.001)\n",
    "num_epochs=2\n",
    "batch_size=100\n",
    "\n",
    "\n",
    "##Split data##\n",
    "X=df[X_labels]\n",
    "y=df[y_labels]\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test=hf.split_data(X,y,split=[0.9,0.05,0.05])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs=[0.1,0.5,0.9]\n",
    "for q in qs:\n",
    "\n",
    "    ##Create model##\n",
    "    model=tf.keras.Sequential([\n",
    "        layers.Dense(32,input_dim=len(X_labels),activation='linear'),\n",
    "        layers.Dense(64,activation='relu'),\n",
    "        layers.Dense(64,activation='relu'),\n",
    "        layers.Dense(64,activation='relu'),\n",
    "        layers.Dense(len(y_labels),activation='linear')\n",
    "    ])\n",
    "    ##Compile model##\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=lambda y,f: tilted_loss(q,y,f),\n",
    "        metrics=[\"mse\"],\n",
    "        run_eagerly=True\n",
    "    )\n",
    "\n",
    "    ##Train model##\n",
    "    history=md.LossHistory()\n",
    "    model.fit(X_train,y_train,\n",
    "            epochs=num_epochs,\n",
    "            validation_data=(X_val,y_val),\n",
    "            batch_size=batch_size,\n",
    "            callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594/594 - 5s - loss: 10.3719 - mse: 10.3719 - 5s/epoch - 9ms/step\n",
      "Test mse: 10.371944427490234\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_mse = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Test mse: {test_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594/594 [==============================] - 2s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_predict=model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simultaneous multiple quantiles instead of a new network for each quantile may be found in:\n",
    "https://github.com/strongio/quantile-regression-tensorflow/blob/master/Quantile%20Loss.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typhon.retrieval.qrnn.qrnn import QRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Train test validation split##\n",
    "X_labels= ['Cloud_B02','Cloud_B03','Cloud_B04','Cloud_B05','Cloud_B06',\n",
    "           'Cloud_B07','Cloud_B08','Cloud_B09','Cloud_B10','Cloud_B11','Cloud_B12','Cloud_B13',\n",
    "           'Sat_Zenith_Angle','Sun_Zenith_Angle','Azimuth_Diff_Angle','Cloud_Type','Profile_ID','GOT','Water_Vapor']\n",
    "\n",
    "#Leave out 'GOT', 'Water_Vapor'\n",
    "#Band 1 no go.\n",
    "\n",
    "y_labels=['COT']\n",
    "\n",
    "df=hf.normalise_input_df(data_all,X_labels)\n",
    "df=hf.add_noise(df,X_labels,sigma=0.001)\n",
    "num_epochs=2\n",
    "batch_size=100\n",
    "\n",
    "\n",
    "##Split data##\n",
    "X=df[X_labels]\n",
    "y=df[y_labels]\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test=hf.split_data(X,y,split=[0.9,0.05,0.05])\n",
    "\n",
    "model=tf.keras.Sequential([\n",
    "    layers.Dense(32,input_dim=len(X_labels),activation='linear'),\n",
    "    layers.Dense(64,activation='relu'),\n",
    "    layers.Dense(64,activation='relu'),\n",
    "    layers.Dense(64,activation='relu'),\n",
    "    layers.Dense(len(y_labels),activation='linear')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\filip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\typhon\\retrieval\\qrnn\\models\\keras.py:448: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  self.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 4s 2ms/step - loss: 2.6062\n",
      "Epoch 2/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 2.3719\n",
      "Epoch 3/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 2.2569\n",
      "Epoch 4/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 2.1708\n",
      "Epoch 5/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 2.0850\n",
      "Epoch 6/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 2.0112\n",
      "Epoch 7/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.9357\n",
      "Epoch 8/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.8643\n",
      "Epoch 9/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.8038\n",
      "Epoch 10/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.7444\n",
      "Epoch 11/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.7098\n",
      "Epoch 12/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.6392\n",
      "Epoch 13/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.6001\n",
      "Epoch 14/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.5533\n",
      "Epoch 15/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.5252\n",
      "Epoch 16/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.4787\n",
      "Epoch 17/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.4377\n",
      "Epoch 18/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.4125\n",
      "Epoch 19/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.3642\n",
      "Epoch 20/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.3367\n",
      "Epoch 21/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.3170\n",
      "Epoch 22/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.2891\n",
      "Epoch 23/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.2647\n",
      "Epoch 24/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.2461\n",
      "Epoch 25/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.2267\n",
      "Epoch 26/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.2043\n",
      "Epoch 27/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.1879\n",
      "Epoch 28/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.1556\n",
      "Epoch 29/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.1441\n",
      "Epoch 30/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.1266\n",
      "Epoch 31/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.1092\n",
      "Epoch 32/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.1003\n",
      "Epoch 33/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.0777\n",
      "Epoch 34/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.0741\n",
      "Epoch 35/100\n",
      "1800/1800 [==============================] - 4s 2ms/step - loss: 1.0622\n",
      "Epoch 36/100\n",
      "1800/1800 [==============================] - 4s 2ms/step - loss: 1.0584\n",
      "Epoch 37/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.0389\n",
      "Epoch 38/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.0308\n",
      "Epoch 39/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.0119\n",
      "Epoch 40/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 1.0072\n",
      "Epoch 41/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.9926\n",
      "Epoch 42/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.9754\n",
      "Epoch 43/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.9848\n",
      "Epoch 44/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.9725\n",
      "Epoch 45/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.9514\n",
      "Epoch 46/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.9547\n",
      "Epoch 47/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.9463\n",
      "Epoch 48/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.9374\n",
      "Epoch 49/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.9229\n",
      "Epoch 50/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.9266\n",
      "Epoch 51/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.9167\n",
      "Epoch 52/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.9107\n",
      "Epoch 53/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.9032\n",
      "Epoch 54/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.9002\n",
      "Epoch 55/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.8871\n",
      "Epoch 56/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.8759\n",
      "Epoch 57/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.8665\n",
      "Epoch 58/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.8696\n",
      "Epoch 59/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.8617\n",
      "Epoch 60/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.8571\n",
      "Epoch 61/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.8500\n",
      "Epoch 62/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.8451\n",
      "Epoch 63/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.8346\n",
      "Epoch 64/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.8358\n",
      "Epoch 65/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.8295\n",
      "Epoch 66/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.8309\n",
      "Epoch 67/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.8231\n",
      "Epoch 68/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.8221\n",
      "Epoch 69/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.8116\n",
      "Epoch 70/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.8005\n",
      "Epoch 71/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.8082\n",
      "Epoch 72/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.8008\n",
      "Epoch 73/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.7939\n",
      "Epoch 74/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.7959\n",
      "Epoch 75/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.7851\n",
      "Epoch 76/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.7835\n",
      "Epoch 77/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.7724\n",
      "Epoch 78/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.7686\n",
      "Epoch 79/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.7601\n",
      "Epoch 80/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.7617\n",
      "Epoch 81/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.7628\n",
      "Epoch 82/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.7649\n",
      "Epoch 83/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.7511\n",
      "Epoch 84/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.7473\n",
      "Epoch 85/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.7504\n",
      "Epoch 86/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.7430\n",
      "Epoch 87/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.7358\n",
      "Epoch 88/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.7353\n",
      "Epoch 89/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.7282\n",
      "Epoch 90/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.7255\n",
      "Epoch 91/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.7274\n",
      "Epoch 92/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.7196\n",
      "Epoch 93/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.7211\n",
      "Epoch 94/100\n",
      "1800/1800 [==============================] - 4s 2ms/step - loss: 0.7111\n",
      "Epoch 95/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.7129\n",
      "Epoch 96/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.7146\n",
      "Epoch 97/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.7011\n",
      "Epoch 98/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.6991\n",
      "Epoch 99/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.6959\n",
      "Epoch 100/100\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.6907\n"
     ]
    }
   ],
   "source": [
    "quantiles=[0.1,0.5,0.9]\n",
    "qrnn=QRNN(len(X_train.columns),quantiles=quantiles,model=(3,128,'relu'))\n",
    "\n",
    "train_data_tuple=(X_train.values,y_train.values)\n",
    "val_data_tuple=(X_val.values,y_val.values)\n",
    "\n",
    "qrnn.train(training_data=train_data_tuple,\n",
    "            initial_learning_rate = 0.01,\n",
    "            learning_rate_minimum = 1e-4,\n",
    "            batch_size=100,\n",
    "            convergence_epochs=10,\n",
    "            maximum_epochs=100,\n",
    "            training_split=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\filip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\filip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\filip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\filip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\filip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\filip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"fully_connected_30\" is incompatible with the layer: expected shape=(None, 20), found shape=(None, 19)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[91], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mqrnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Why is this not working??\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\filip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\typhon\\retrieval\\qrnn\\qrnn.py:335\u001b[0m, in \u001b[0;36mQRNN.predict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    318\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;124;03m    Predict quantiles of the conditional distribution P(y|x).\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    333\u001b[0m \n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 335\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\filip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filef3_6321b.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\filip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\filip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\filip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\filip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\filip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\filip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"fully_connected_30\" is incompatible with the layer: expected shape=(None, 20), found shape=(None, 19)\n"
     ]
    }
   ],
   "source": [
    "qrnn.predict(X_test.values) # Why is this not working??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

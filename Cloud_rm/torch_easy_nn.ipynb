{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "\n",
    "\n",
    "import functions.parse_data as parse\n",
    "import functions.handy_functions as hf\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "\n",
    "from multivariate_quantile_regression.network_model import QuantileNetwork\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n",
      "Tensor is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    # CUDA is available, so let's set default device to GPU\n",
    "    torch.set_default_device(0)\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "else:\n",
    "    # CUDA is not available, so let's use the CPU\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "# Example usage:\n",
    "tensor = torch.randn(3, 3)  # Create a tensor on the selected device\n",
    "print(\"Tensor is on device:\", tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_labels= ['Cloud_B02','Cloud_B03','Cloud_B04','Cloud_B05','Cloud_B06','Cloud_B07',\n",
    "                 'Cloud_B08','Cloud_B09','Cloud_B10','Cloud_B11','Cloud_B12','Cloud_B13']\n",
    "\n",
    "data_water=parse.parse('cloudrm_water.dat')\n",
    "data_clear=parse.parse('cloudrm_clear.dat')\n",
    "data_ice=parse.parse('cloudrm_ice.dat')\n",
    "data_mixed=parse.parse('cloudrm_mixed.dat')\n",
    "\n",
    "#Concatinate all datasets\n",
    "#data_all=pd.concat([data_water, data_clear, data_ice, data_mixed])\n",
    "data_all=pd.concat([data_water, data_ice, data_mixed])\n",
    "#data_all=pd.concat([data_ice])\n",
    "data_all=data_all.drop(columns=['Surface_Desc','Cloud_B01','Clear_B01'])\n",
    "df_truth=data_all.copy()\n",
    "\n",
    "data_all=data_all[data_all['COT']<3.6]\n",
    "\n",
    "#data_all=hf.add_MSI_noise(data_all,channel_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Train test validation split##\n",
    "X_labels= ['Cloud_B02','Cloud_B03','Cloud_B04','Cloud_B05','Cloud_B06',\n",
    "           'Cloud_B07','Cloud_B08','Cloud_B09','Cloud_B10','Cloud_B11','Cloud_B12','Cloud_B13',\n",
    "           'Sat_Zenith_Angle','Sun_Zenith_Angle','Azimuth_Diff_Angle']\n",
    "\n",
    "#Leave out 'GOT', 'Water_Vapor'\n",
    "#Band 1 no go.\n",
    "y_labels=['Clear_B12']\n",
    "\n",
    "X_truth=df_truth[X_labels]\n",
    "\n",
    "df=data_all.copy()\n",
    "#df=hf.normalise_input_df(data_all,X_labels)\n",
    "#df=hf.add_noise(df,X_labels,sigma=0.001)\n",
    "\n",
    "##Split data##\n",
    "X=df[X_labels]\n",
    "y=df[y_labels]\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.05)\n",
    "\n",
    "X_test_truth=X_truth.iloc[X_test.index] #Save truth values without normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs=300\n",
    "batch_size=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "val_size=0.05\n",
    "validation_indices=np.array(random.sample(range(len(X_train['Cloud_B02'])), int(len(X_train['Cloud_B02'])*val_size)))\n",
    "train_indices=[i for i in range(len(X_train['Cloud_B02'])) if np.any(validation_indices==i)==False]\n",
    "\n",
    "quantiles=np.array([0.1,0.5,0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self,n_inputs):\n",
    "        super(MLP, self).__init__()\n",
    "        n_nodes=64\n",
    "        self.linear=nn.Sequential(\n",
    "                    nn.Linear(n_inputs, n_nodes),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(p=0.2),\n",
    "                    nn.Linear(n_nodes, n_nodes),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(n_nodes, 1) #Output dimesion is number of quantiles times number of target variables\n",
    "                )\n",
    "\n",
    "    def forward(self,X):\n",
    "        X=self.linear(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MLP(len(X_labels))\n",
    "\n",
    "loss_fn=nn.MSELoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multivariate_quantile_regression.utils import batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx=torch.tensor(X_train.to_numpy(),dtype=torch.float)#,device=device)   \n",
    "\n",
    "for epoch in range(300):\n",
    "\n",
    "    for batch in batches(train_indices, batch_size, shuffle=True):\n",
    "\n",
    "        idx = torch.tensor(batch,dtype=torch.int64)#,device=device)\n",
    "\n",
    "        model.train() #Initialise train mode\n",
    "        model.zero_grad() #Reset gradient\n",
    "\n",
    "        yhat = model(tX[idx]) #Run algorithm\n",
    "\n",
    "        loss=loss_fn(yhat,idx).sum() #Run loss function\n",
    "        loss.backward() #Calculate gradient\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss=train_loss+loss.data #Increment loss\n",
    "\n",
    "\n",
    "        validation_loss = torch.tensor([0],dtype=torch.float)#,device=device)\n",
    "    \n",
    "    for batch_idx, batch in enumerate(batches(validation_indices, batch_size, shuffle=False)):\n",
    "\n",
    "\n",
    "        idx = torch.tensor(batch,dtype=torch.int64)#,device=device)\n",
    "\n",
    "        model.eval() #Set evaluation mode\n",
    "        model.zero_grad() #Reset gradient\n",
    "\n",
    "        yhat=model(tX[idx])\n",
    "\n",
    "        validation_loss=validation_loss+loss_fn(yhat, idx).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67ed097e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 10:45:51.853530: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_probability as tfp\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aff6eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "df1 = pd.read_csv('cloudrm_clear.dat',skiprows=53, header=None, delimiter = ' ', skipinitialspace = True ,index_col = 0)\n",
    "df2 = pd.read_csv('cloudrm_mixed.dat',skiprows=53, header=None, delimiter = ' ', skipinitialspace = True ,index_col = 0)\n",
    "df3 = pd.read_csv('cloudrm_ice.dat',skiprows=53, header=None, delimiter = ' ', skipinitialspace = True ,index_col = 0)\n",
    "df4 = pd.read_csv('cloudrm_water.dat',skiprows=53, header=None, delimiter = ' ', skipinitialspace = True ,index_col = 0)\n",
    "df = pd.concat([df1, df2, df3, df4], axis=0)\n",
    "df.columns = ['Cloudy 1', 'Cloudy 2', 'Cloudy 3', 'Cloudy 4', 'Cloudy 5', 'Cloudy 6', 'Cloudy 7', 'Cloudy 8', \\\n",
    "              'Cloudy 9', 'Cloudy 10', 'Cloudy 11', 'Cloudy 12', 'Cloudy 13', 'Clear 1', 'Clear 2', 'Clear 3', \\\n",
    "              'Clear 4', 'Clear 5', 'Clear 6', 'Clear 7', 'Clear 8', 'Clear 9', 'Clear 10', 'Clear 11', 'Clear 12', \\\n",
    "              'Clear 13', 'Sat Zen', 'Sun Zen', 'Azi diff', 'COT', 'Ctype', 'Prof ID', 'GOT', 'VIWV' , 'Surf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63f04729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=({'Cloudy 2': TensorSpec(shape=(), dtype=tf.float32, name=None), 'Cloudy 3': TensorSpec(shape=(), dtype=tf.float32, name=None), 'Cloudy 4': TensorSpec(shape=(), dtype=tf.float32, name=None), 'Cloudy 5': TensorSpec(shape=(), dtype=tf.float32, name=None), 'Cloudy 6': TensorSpec(shape=(), dtype=tf.float32, name=None), 'Cloudy 7': TensorSpec(shape=(), dtype=tf.float32, name=None), 'Cloudy 8': TensorSpec(shape=(), dtype=tf.float32, name=None), 'Cloudy 9': TensorSpec(shape=(), dtype=tf.float32, name=None), 'Cloudy 10': TensorSpec(shape=(), dtype=tf.float32, name=None), 'Cloudy 11': TensorSpec(shape=(), dtype=tf.float32, name=None), 'Cloudy 12': TensorSpec(shape=(), dtype=tf.float32, name=None), 'Cloudy 13': TensorSpec(shape=(), dtype=tf.float32, name=None), 'Sat Zen': TensorSpec(shape=(), dtype=tf.float32, name=None), 'Sun Zen': TensorSpec(shape=(), dtype=tf.float32, name=None), 'Azi diff': TensorSpec(shape=(), dtype=tf.float32, name=None)}, {'Clear 2': TensorSpec(shape=(), dtype=tf.float32, name=None), 'Clear 3': TensorSpec(shape=(), dtype=tf.float32, name=None), 'Clear 4': TensorSpec(shape=(), dtype=tf.float32, name=None), 'Clear 5': TensorSpec(shape=(), dtype=tf.float32, name=None), 'Clear 6': TensorSpec(shape=(), dtype=tf.float32, name=None), 'Clear 7': TensorSpec(shape=(), dtype=tf.float32, name=None), 'Clear 8': TensorSpec(shape=(), dtype=tf.float32, name=None), 'Clear 9': TensorSpec(shape=(), dtype=tf.float32, name=None), 'Clear 10': TensorSpec(shape=(), dtype=tf.float32, name=None), 'Clear 11': TensorSpec(shape=(), dtype=tf.float32, name=None), 'Clear 12': TensorSpec(shape=(), dtype=tf.float32, name=None), 'Clear 13': TensorSpec(shape=(), dtype=tf.float32, name=None), 'COT': TensorSpec(shape=(), dtype=tf.float32, name=None)})>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Divide into X and y\n",
    "variables = ['Cloudy 2', 'Cloudy 3', 'Cloudy 4', 'Cloudy 5', 'Cloudy 6', 'Cloudy 7', 'Cloudy 8', \\\n",
    "              'Cloudy 9', 'Cloudy 10', 'Cloudy 11', 'Cloudy 12', 'Cloudy 13', 'Sat Zen', 'Sun Zen', 'Azi diff']\n",
    "targets = ['Clear 2', 'Clear 3', 'Clear 4', 'Clear 5', 'Clear 6', 'Clear 7', 'Clear 8', 'Clear 9', 'Clear 10', \\\n",
    "           'Clear 11', 'Clear 12', 'Clear 13', 'COT']\n",
    "\n",
    "X = df[variables]\n",
    "y = df[targets]\n",
    "\n",
    "#Load into tensorflow dataset\n",
    "tf_dataset = tf.data.Dataset.from_tensor_slices((X.to_dict(orient=\"list\"), y.to_dict(orient=\"list\")))\n",
    "\n",
    "tf_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1796ce1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_and_test_splits(dataset,train_size, batch_size=1):\n",
    "    # We shuffle with a buffer the same size as the dataset.\n",
    "    train_dataset = (\n",
    "        dataset.take(train_size).shuffle(buffer_size=500).batch(batch_size)\n",
    "    )\n",
    "    test_dataset = dataset.skip(train_size).batch(batch_size)\n",
    "\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b53ff965",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units = [8, 8]\n",
    "learning_rate = 0.001\n",
    "\n",
    "def run_experiment(model, loss, train_dataset, test_dataset):\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=loss,\n",
    "        metrics=[keras.metrics.RootMeanSquaredError()],\n",
    "    )\n",
    "\n",
    "    print(\"Start training the model...\")\n",
    "    model.fit(train_dataset, epochs=num_epochs, validation_data=test_dataset)\n",
    "    print(\"Model training finished.\")\n",
    "    _, rmse = model.evaluate(train_dataset, verbose=0)\n",
    "    print(f\"Train RMSE: {round(rmse, 3)}\")\n",
    "\n",
    "    print(\"Evaluating model performance...\")\n",
    "    _, rmse = model.evaluate(test_dataset, verbose=0)\n",
    "    print(f\"Test RMSE: {round(rmse, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95f7b65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_NAMES = ['Cloudy 2', 'Cloudy 3', 'Cloudy 4', 'Cloudy 5', 'Cloudy 6', 'Cloudy 7', 'Cloudy 8', \\\n",
    "              'Cloudy 9', 'Cloudy 10', 'Cloudy 11', 'Cloudy 12', 'Cloudy 13', 'Sat Zen', 'Sun Zen', 'Azi diff']\n",
    "\n",
    "\n",
    "def create_model_inputs():\n",
    "    inputs = {}\n",
    "    for feature_name in FEATURE_NAMES:\n",
    "        inputs[feature_name] = layers.Input(\n",
    "            name=feature_name, shape=(1,), dtype=tf.float32\n",
    "        )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67763b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline_model():\n",
    "    inputs = create_model_inputs()\n",
    "    input_values = [value for _, value in sorted(inputs.items())]\n",
    "    features = keras.layers.concatenate(input_values)\n",
    "    features = layers.BatchNormalization()(features)\n",
    "\n",
    "    # Create hidden layers with deterministic weights using the Dense layer.\n",
    "    for units in hidden_units:\n",
    "        features = layers.Dense(units, activation=\"relu\")(features)\n",
    "    # The output is deterministic: a single point estimate.\n",
    "    outputs = layers.Dense(units=1)(features)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b98a6420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=({'Cloudy 2': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'Cloudy 3': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'Cloudy 4': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'Cloudy 5': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'Cloudy 6': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'Cloudy 7': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'Cloudy 8': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'Cloudy 9': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'Cloudy 10': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'Cloudy 11': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'Cloudy 12': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'Cloudy 13': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'Sat Zen': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'Sun Zen': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'Azi diff': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}, {'Clear 2': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'Clear 3': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'Clear 4': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'Clear 5': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'Clear 6': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'Clear 7': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'Clear 8': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'Clear 9': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'Clear 10': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'Clear 11': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'Clear 12': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'Clear 13': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'COT': TensorSpec(shape=(None,), dtype=tf.float32, name=None)})>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_size = 200000\n",
    "batch_size = 32\n",
    "train_size = int(dataset_size * 0.85)\n",
    "train_dataset, test_dataset = get_train_and_test_splits(tf_dataset,train_size, batch_size)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c0c4e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 248, in __call__\n        y_true = self._conform_to_outputs(y_pred, y_true)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 63, in _conform_to_outputs\n        struct = map_to_output_names(outputs, self._output_names, struct)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 819, in map_to_output_names\n        raise ValueError(\n\n    ValueError: Found unexpected losses or metrics that do not correspond to any Model output: dict_keys(['Clear 2', 'Clear 3', 'Clear 4', 'Clear 5', 'Clear 6', 'Clear 7', 'Clear 8', 'Clear 9', 'Clear 10', 'Clear 11', 'Clear 12', 'Clear 13', 'COT']). Valid mode output names: ['dense_2']. Received struct is: {'Clear 2': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float32>, 'Clear 3': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=float32>, 'Clear 4': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=float32>, 'Clear 5': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=float32>, 'Clear 6': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=float32>, 'Clear 7': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=float32>, 'Clear 8': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=float32>, 'Clear 9': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float32>, 'Clear 10': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float32>, 'Clear 11': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float32>, 'Clear 12': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float32>, 'Clear 13': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float32>, 'COT': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float32>}.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m mse_loss \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mMeanSquaredError()\n\u001b[1;32m      3\u001b[0m baseline_model \u001b[38;5;241m=\u001b[39m create_baseline_model()\n\u001b[0;32m----> 4\u001b[0m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbaseline_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmse_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(model, loss, train_dataset, test_dataset)\u001b[0m\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m      7\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate),\n\u001b[1;32m      8\u001b[0m     loss\u001b[38;5;241m=\u001b[39mloss,\n\u001b[1;32m      9\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[keras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mRootMeanSquaredError()],\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart training the model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel training finished.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m _, rmse \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(train_dataset, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/jl/4ffpkv2d1r58l2w1grcxrydc0000gn/T/__autograph_generated_file67i7p15h.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 248, in __call__\n        y_true = self._conform_to_outputs(y_pred, y_true)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 63, in _conform_to_outputs\n        struct = map_to_output_names(outputs, self._output_names, struct)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 819, in map_to_output_names\n        raise ValueError(\n\n    ValueError: Found unexpected losses or metrics that do not correspond to any Model output: dict_keys(['Clear 2', 'Clear 3', 'Clear 4', 'Clear 5', 'Clear 6', 'Clear 7', 'Clear 8', 'Clear 9', 'Clear 10', 'Clear 11', 'Clear 12', 'Clear 13', 'COT']). Valid mode output names: ['dense_2']. Received struct is: {'Clear 2': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float32>, 'Clear 3': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=float32>, 'Clear 4': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=float32>, 'Clear 5': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=float32>, 'Clear 6': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=float32>, 'Clear 7': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=float32>, 'Clear 8': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=float32>, 'Clear 9': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float32>, 'Clear 10': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float32>, 'Clear 11': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float32>, 'Clear 12': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float32>, 'Clear 13': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float32>, 'COT': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float32>}.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "mse_loss = keras.losses.MeanSquaredError()\n",
    "baseline_model = create_baseline_model()\n",
    "run_experiment(baseline_model, mse_loss, train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d620627",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'baseline_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      2\u001b[0m examples, targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(test_dataset\u001b[38;5;241m.\u001b[39munbatch()\u001b[38;5;241m.\u001b[39mshuffle(batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mbatch(sample))[\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m ]\n\u001b[0;32m----> 6\u001b[0m predicted \u001b[38;5;241m=\u001b[39m \u001b[43mbaseline_model\u001b[49m(examples)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(sample):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mfloat\u001b[39m(predicted[idx][\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Actual: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtargets[idx]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'baseline_model' is not defined"
     ]
    }
   ],
   "source": [
    "sample = 10\n",
    "examples, targets = list(test_dataset.unbatch().shuffle(batch_size * 10).batch(sample))[\n",
    "    0\n",
    "]\n",
    "\n",
    "predicted = baseline_model(examples).numpy()\n",
    "for idx in range(sample):\n",
    "    print(f\"Predicted: {round(float(predicted[idx][0]), 1)} - Actual: {targets[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82f7420f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prior weight distribution as Normal of mean=0 and stddev=1.\n",
    "# Note that, in this example, the we prior distribution is not trainable,\n",
    "# as we fix its parameters.\n",
    "def prior(kernel_size, bias_size, dtype=None):\n",
    "    n = kernel_size + bias_size\n",
    "    prior_model = keras.Sequential(\n",
    "        [\n",
    "            tfp.layers.DistributionLambda(\n",
    "                lambda t: tfp.distributions.MultivariateNormalDiag(\n",
    "                    loc=tf.zeros(n), scale_diag=tf.ones(n)\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    return prior_model\n",
    "\n",
    "\n",
    "# Define variational posterior weight distribution as multivariate Gaussian.\n",
    "# Note that the learnable parameters for this distribution are the means,\n",
    "# variances, and covariances.\n",
    "def posterior(kernel_size, bias_size, dtype=None):\n",
    "    n = kernel_size + bias_size\n",
    "    posterior_model = keras.Sequential(\n",
    "        [\n",
    "            tfp.layers.VariableLayer(\n",
    "                tfp.layers.MultivariateNormalTriL.params_size(n), dtype=dtype\n",
    "            ),\n",
    "            tfp.layers.MultivariateNormalTriL(n),\n",
    "        ]\n",
    "    )\n",
    "    return posterior_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edf4f70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_probablistic_bnn_model(train_size):\n",
    "    inputs = create_model_inputs()\n",
    "    features = keras.layers.concatenate(list(inputs.values()))\n",
    "    features = layers.BatchNormalization()(features)\n",
    "\n",
    "    # Create hidden layers with weight uncertainty using the DenseVariational layer.\n",
    "    for units in hidden_units:\n",
    "        features = tfp.layers.DenseVariational(\n",
    "            units=units,\n",
    "            make_prior_fn=prior,\n",
    "            make_posterior_fn=posterior,\n",
    "            kl_weight=1 / train_size,\n",
    "            activation=\"sigmoid\",\n",
    "        )(features)\n",
    "\n",
    "    # Create a probabilistic output (Normal distribution), and use the `Dense` layer\n",
    "    # to produce the parameters of the distribution.\n",
    "    # We set units=2 to learn both the mean and the variance of the Normal distribution.\n",
    "    distribution_params = layers.Dense(units=2)(features)\n",
    "    outputs = tfp.layers.IndependentNormal(1)(distribution_params)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "136ad78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/100\n",
      "1329/1329 [==============================] - 11s 6ms/step - loss: 272.3416 - root_mean_squared_error: 18.7189 - val_loss: 70.0832 - val_root_mean_squared_error: 18.4725\n",
      "Epoch 2/100\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 42.3059 - root_mean_squared_error: 17.7305 - val_loss: 28.5231 - val_root_mean_squared_error: 17.5361\n",
      "Epoch 3/100\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 20.6584 - root_mean_squared_error: 16.8902 - val_loss: 16.1879 - val_root_mean_squared_error: 16.8149\n",
      "Epoch 4/100\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 12.8539 - root_mean_squared_error: 16.1259 - val_loss: 10.8886 - val_root_mean_squared_error: 16.0253\n",
      "Epoch 5/100\n",
      "1329/1329 [==============================] - 7s 5ms/step - loss: 9.0900 - root_mean_squared_error: 15.5203 - val_loss: 8.0594 - val_root_mean_squared_error: 15.5032\n",
      "Epoch 6/100\n",
      "1329/1329 [==============================] - 7s 5ms/step - loss: 7.0411 - root_mean_squared_error: 15.1006 - val_loss: 6.4766 - val_root_mean_squared_error: 15.1844\n",
      "Epoch 7/100\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 5.8435 - root_mean_squared_error: 14.9160 - val_loss: 5.5049 - val_root_mean_squared_error: 15.1168\n",
      "Epoch 8/100\n",
      "1329/1329 [==============================] - 6s 5ms/step - loss: 5.0994 - root_mean_squared_error: 14.9357 - val_loss: 4.8935 - val_root_mean_squared_error: 15.0168\n",
      "Epoch 9/100\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 4.6024 - root_mean_squared_error: 14.8636 - val_loss: 4.4290 - val_root_mean_squared_error: 15.0833\n",
      "Epoch 10/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 4.1437 - root_mean_squared_error: 14.4963 - val_loss: 3.9245 - val_root_mean_squared_error: 14.1402\n",
      "Epoch 11/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 3.6924 - root_mean_squared_error: 13.3970 - val_loss: 3.5146 - val_root_mean_squared_error: 12.8613\n",
      "Epoch 12/100\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 3.3563 - root_mean_squared_error: 12.2734 - val_loss: 3.2106 - val_root_mean_squared_error: 11.5351\n",
      "Epoch 13/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 3.1335 - root_mean_squared_error: 11.0516 - val_loss: 3.0134 - val_root_mean_squared_error: 10.4936\n",
      "Epoch 14/100\n",
      "1329/1329 [==============================] - 6s 5ms/step - loss: 3.0162 - root_mean_squared_error: 10.3945 - val_loss: 2.9134 - val_root_mean_squared_error: 9.9614\n",
      "Epoch 15/100\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 2.9369 - root_mean_squared_error: 9.8610 - val_loss: 2.8227 - val_root_mean_squared_error: 9.2226\n",
      "Epoch 16/100\n",
      "1329/1329 [==============================] - 8s 6ms/step - loss: 2.8888 - root_mean_squared_error: 9.4100 - val_loss: 2.7991 - val_root_mean_squared_error: 9.0274\n",
      "Epoch 17/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.8449 - root_mean_squared_error: 9.0212 - val_loss: 2.7306 - val_root_mean_squared_error: 8.9566\n",
      "Epoch 18/100\n",
      "1329/1329 [==============================] - 6s 5ms/step - loss: 2.8045 - root_mean_squared_error: 8.7444 - val_loss: 2.6626 - val_root_mean_squared_error: 8.3478\n",
      "Epoch 19/100\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 2.7457 - root_mean_squared_error: 8.4263 - val_loss: 2.6010 - val_root_mean_squared_error: 7.9983\n",
      "Epoch 20/100\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 2.6895 - root_mean_squared_error: 8.0927 - val_loss: 2.5508 - val_root_mean_squared_error: 7.8888\n",
      "Epoch 21/100\n",
      "1329/1329 [==============================] - 6s 5ms/step - loss: 2.6661 - root_mean_squared_error: 7.8907 - val_loss: 2.4723 - val_root_mean_squared_error: 7.4936\n",
      "Epoch 22/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.6148 - root_mean_squared_error: 7.6259 - val_loss: 2.4684 - val_root_mean_squared_error: 7.3723\n",
      "Epoch 23/100\n",
      "1329/1329 [==============================] - 6s 5ms/step - loss: 2.6092 - root_mean_squared_error: 7.5601 - val_loss: 2.4379 - val_root_mean_squared_error: 7.3328\n",
      "Epoch 24/100\n",
      "1329/1329 [==============================] - 7s 5ms/step - loss: 2.6058 - root_mean_squared_error: 7.6150 - val_loss: 2.3585 - val_root_mean_squared_error: 6.9950\n",
      "Epoch 25/100\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 2.5624 - root_mean_squared_error: 7.3779 - val_loss: 2.3661 - val_root_mean_squared_error: 6.8787\n",
      "Epoch 26/100\n",
      "1329/1329 [==============================] - 6s 5ms/step - loss: 2.5824 - root_mean_squared_error: 7.3728 - val_loss: 2.3932 - val_root_mean_squared_error: 7.0505\n",
      "Epoch 27/100\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 2.5731 - root_mean_squared_error: 7.3071 - val_loss: 2.4025 - val_root_mean_squared_error: 7.0014\n",
      "Epoch 28/100\n",
      "1329/1329 [==============================] - 6s 5ms/step - loss: 2.5711 - root_mean_squared_error: 7.3225 - val_loss: 2.3243 - val_root_mean_squared_error: 6.8224\n",
      "Epoch 29/100\n",
      "1329/1329 [==============================] - 6s 5ms/step - loss: 2.5426 - root_mean_squared_error: 7.1770 - val_loss: 2.3141 - val_root_mean_squared_error: 6.5968\n",
      "Epoch 30/100\n",
      "1329/1329 [==============================] - 7s 5ms/step - loss: 2.5426 - root_mean_squared_error: 7.1626 - val_loss: 2.3040 - val_root_mean_squared_error: 6.7698\n",
      "Epoch 31/100\n",
      "1329/1329 [==============================] - 6s 5ms/step - loss: 2.5486 - root_mean_squared_error: 7.0561 - val_loss: 2.3545 - val_root_mean_squared_error: 6.7905\n",
      "Epoch 32/100\n",
      "1329/1329 [==============================] - 7s 5ms/step - loss: 2.5410 - root_mean_squared_error: 7.0906 - val_loss: 2.2870 - val_root_mean_squared_error: 6.5946\n",
      "Epoch 33/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.5132 - root_mean_squared_error: 6.9432 - val_loss: 2.2991 - val_root_mean_squared_error: 6.4617\n",
      "Epoch 34/100\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 2.5443 - root_mean_squared_error: 6.9856 - val_loss: 2.2730 - val_root_mean_squared_error: 6.5280\n",
      "Epoch 35/100\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 2.4898 - root_mean_squared_error: 6.8212 - val_loss: 2.2467 - val_root_mean_squared_error: 6.1439\n",
      "Epoch 36/100\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 2.4991 - root_mean_squared_error: 6.8428 - val_loss: 2.2547 - val_root_mean_squared_error: 6.3236\n",
      "Epoch 37/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.4919 - root_mean_squared_error: 6.7181 - val_loss: 2.2325 - val_root_mean_squared_error: 6.0521\n",
      "Epoch 38/100\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 2.4860 - root_mean_squared_error: 6.7231 - val_loss: 2.2258 - val_root_mean_squared_error: 5.9513\n",
      "Epoch 39/100\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 2.4794 - root_mean_squared_error: 6.5662 - val_loss: 2.1952 - val_root_mean_squared_error: 5.9154\n",
      "Epoch 40/100\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 2.4771 - root_mean_squared_error: 6.6663 - val_loss: 2.2072 - val_root_mean_squared_error: 5.9427\n",
      "Epoch 41/100\n",
      "1329/1329 [==============================] - 6s 5ms/step - loss: 2.4558 - root_mean_squared_error: 6.5878 - val_loss: 2.2030 - val_root_mean_squared_error: 5.9248\n",
      "Epoch 42/100\n",
      "1329/1329 [==============================] - 7s 5ms/step - loss: 2.4742 - root_mean_squared_error: 6.6410 - val_loss: 2.1924 - val_root_mean_squared_error: 5.8529\n",
      "Epoch 43/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.4845 - root_mean_squared_error: 6.5792 - val_loss: 2.2181 - val_root_mean_squared_error: 6.0831\n",
      "Epoch 44/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.4776 - root_mean_squared_error: 6.5893 - val_loss: 2.2025 - val_root_mean_squared_error: 5.8583\n",
      "Epoch 45/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.4685 - root_mean_squared_error: 6.5818 - val_loss: 2.1944 - val_root_mean_squared_error: 5.8338\n",
      "Epoch 46/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.4478 - root_mean_squared_error: 6.4647 - val_loss: 2.1803 - val_root_mean_squared_error: 5.7917\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.4693 - root_mean_squared_error: 6.5301 - val_loss: 2.1836 - val_root_mean_squared_error: 5.7671\n",
      "Epoch 48/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.4674 - root_mean_squared_error: 6.5573 - val_loss: 2.2172 - val_root_mean_squared_error: 5.8995\n",
      "Epoch 49/100\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 2.4931 - root_mean_squared_error: 6.6464 - val_loss: 2.2139 - val_root_mean_squared_error: 6.1306\n",
      "Epoch 50/100\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 2.4608 - root_mean_squared_error: 6.5759 - val_loss: 2.1778 - val_root_mean_squared_error: 5.8644\n",
      "Epoch 51/100\n",
      "1329/1329 [==============================] - 7s 5ms/step - loss: 2.4751 - root_mean_squared_error: 6.4798 - val_loss: 2.2061 - val_root_mean_squared_error: 5.8513\n",
      "Epoch 52/100\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 2.4920 - root_mean_squared_error: 6.5866 - val_loss: 2.1965 - val_root_mean_squared_error: 6.0094\n",
      "Epoch 53/100\n",
      "1329/1329 [==============================] - 6s 5ms/step - loss: 2.4847 - root_mean_squared_error: 6.5790 - val_loss: 2.1962 - val_root_mean_squared_error: 5.7045\n",
      "Epoch 54/100\n",
      "1329/1329 [==============================] - 6s 5ms/step - loss: 2.4385 - root_mean_squared_error: 6.4152 - val_loss: 2.1532 - val_root_mean_squared_error: 5.6510\n",
      "Epoch 55/100\n",
      "1329/1329 [==============================] - 6s 5ms/step - loss: 2.4670 - root_mean_squared_error: 6.4734 - val_loss: 2.1793 - val_root_mean_squared_error: 5.7468\n",
      "Epoch 56/100\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 2.4555 - root_mean_squared_error: 6.3991 - val_loss: 2.1411 - val_root_mean_squared_error: 5.5838\n",
      "Epoch 57/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.4737 - root_mean_squared_error: 6.4683 - val_loss: 2.1827 - val_root_mean_squared_error: 5.8348\n",
      "Epoch 58/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.4620 - root_mean_squared_error: 6.5138 - val_loss: 2.1590 - val_root_mean_squared_error: 5.5346\n",
      "Epoch 59/100\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 2.4546 - root_mean_squared_error: 6.4489 - val_loss: 2.1831 - val_root_mean_squared_error: 5.6884\n",
      "Epoch 60/100\n",
      "1329/1329 [==============================] - 8s 6ms/step - loss: 2.4750 - root_mean_squared_error: 6.5160 - val_loss: 2.1913 - val_root_mean_squared_error: 5.8327\n",
      "Epoch 61/100\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 2.4416 - root_mean_squared_error: 6.3977 - val_loss: 2.1636 - val_root_mean_squared_error: 5.7645\n",
      "Epoch 62/100\n",
      "1329/1329 [==============================] - 7s 5ms/step - loss: 2.4565 - root_mean_squared_error: 6.2884 - val_loss: 2.1769 - val_root_mean_squared_error: 5.5318\n",
      "Epoch 63/100\n",
      "1329/1329 [==============================] - 7s 5ms/step - loss: 2.4389 - root_mean_squared_error: 6.3524 - val_loss: 2.1464 - val_root_mean_squared_error: 5.6920\n",
      "Epoch 64/100\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 2.4541 - root_mean_squared_error: 6.3885 - val_loss: 2.1696 - val_root_mean_squared_error: 5.6701\n",
      "Epoch 65/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.4506 - root_mean_squared_error: 6.4132 - val_loss: 2.1521 - val_root_mean_squared_error: 5.6321\n",
      "Epoch 66/100\n",
      "1329/1329 [==============================] - 10s 7ms/step - loss: 2.4731 - root_mean_squared_error: 6.4792 - val_loss: 2.1607 - val_root_mean_squared_error: 5.6092\n",
      "Epoch 67/100\n",
      "1329/1329 [==============================] - 7s 5ms/step - loss: 2.4706 - root_mean_squared_error: 6.4224 - val_loss: 2.1207 - val_root_mean_squared_error: 5.5825\n",
      "Epoch 68/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.4483 - root_mean_squared_error: 6.3644 - val_loss: 2.1529 - val_root_mean_squared_error: 5.4947\n",
      "Epoch 69/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.4538 - root_mean_squared_error: 6.3181 - val_loss: 2.1642 - val_root_mean_squared_error: 5.4234\n",
      "Epoch 70/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.4488 - root_mean_squared_error: 6.3988 - val_loss: 2.1424 - val_root_mean_squared_error: 5.3847\n",
      "Epoch 71/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.4512 - root_mean_squared_error: 6.2578 - val_loss: 2.1606 - val_root_mean_squared_error: 5.4819\n",
      "Epoch 72/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.4505 - root_mean_squared_error: 6.2664 - val_loss: 2.1866 - val_root_mean_squared_error: 5.6614\n",
      "Epoch 73/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.4108 - root_mean_squared_error: 6.1946 - val_loss: 2.1203 - val_root_mean_squared_error: 5.3863\n",
      "Epoch 74/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.4300 - root_mean_squared_error: 6.2158 - val_loss: 2.1298 - val_root_mean_squared_error: 5.3617\n",
      "Epoch 75/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.4662 - root_mean_squared_error: 6.3606 - val_loss: 2.1408 - val_root_mean_squared_error: 5.4561\n",
      "Epoch 76/100\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 2.4311 - root_mean_squared_error: 6.1917 - val_loss: 2.1283 - val_root_mean_squared_error: 5.1873\n",
      "Epoch 77/100\n",
      "1329/1329 [==============================] - 6s 5ms/step - loss: 2.4626 - root_mean_squared_error: 6.3341 - val_loss: 2.1544 - val_root_mean_squared_error: 5.4566\n",
      "Epoch 78/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.4447 - root_mean_squared_error: 6.2718 - val_loss: 2.1541 - val_root_mean_squared_error: 5.3025\n",
      "Epoch 79/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.4136 - root_mean_squared_error: 6.0561 - val_loss: 2.1268 - val_root_mean_squared_error: 5.3825\n",
      "Epoch 80/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.4366 - root_mean_squared_error: 6.1831 - val_loss: 2.1784 - val_root_mean_squared_error: 5.4036\n",
      "Epoch 81/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.4460 - root_mean_squared_error: 6.2320 - val_loss: 2.1442 - val_root_mean_squared_error: 5.3027\n",
      "Epoch 82/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.4245 - root_mean_squared_error: 6.1468 - val_loss: 2.1171 - val_root_mean_squared_error: 5.0917\n",
      "Epoch 83/100\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 2.4413 - root_mean_squared_error: 6.1854 - val_loss: 2.1415 - val_root_mean_squared_error: 5.2824\n",
      "Epoch 84/100\n",
      "1329/1329 [==============================] - 7s 5ms/step - loss: 2.4283 - root_mean_squared_error: 6.0840 - val_loss: 2.1069 - val_root_mean_squared_error: 5.1921\n",
      "Epoch 85/100\n",
      "1329/1329 [==============================] - 6s 5ms/step - loss: 2.4289 - root_mean_squared_error: 6.1817 - val_loss: 2.1242 - val_root_mean_squared_error: 5.1881\n",
      "Epoch 86/100\n",
      "1329/1329 [==============================] - 7s 5ms/step - loss: 2.4058 - root_mean_squared_error: 6.0883 - val_loss: 2.1397 - val_root_mean_squared_error: 5.2216\n",
      "Epoch 87/100\n",
      "1329/1329 [==============================] - 7s 5ms/step - loss: 2.4230 - root_mean_squared_error: 6.1164 - val_loss: 2.1320 - val_root_mean_squared_error: 5.3520\n",
      "Epoch 88/100\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 2.4376 - root_mean_squared_error: 6.1397 - val_loss: 2.1128 - val_root_mean_squared_error: 5.2949\n",
      "Epoch 89/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.4380 - root_mean_squared_error: 6.2318 - val_loss: 2.1154 - val_root_mean_squared_error: 5.2113\n",
      "Epoch 90/100\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 2.4055 - root_mean_squared_error: 6.0772 - val_loss: 2.1237 - val_root_mean_squared_error: 5.0772\n",
      "Epoch 91/100\n",
      "1329/1329 [==============================] - 7s 6ms/step - loss: 2.4339 - root_mean_squared_error: 6.1479 - val_loss: 2.0965 - val_root_mean_squared_error: 5.1746\n",
      "Epoch 92/100\n",
      "1329/1329 [==============================] - 7s 6ms/step - loss: 2.4164 - root_mean_squared_error: 6.0842 - val_loss: 2.1175 - val_root_mean_squared_error: 5.3506\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.4285 - root_mean_squared_error: 6.1742 - val_loss: 2.1139 - val_root_mean_squared_error: 5.2585\n",
      "Epoch 94/100\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 2.4228 - root_mean_squared_error: 6.1558 - val_loss: 2.1150 - val_root_mean_squared_error: 5.2239\n",
      "Epoch 95/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.4237 - root_mean_squared_error: 6.1726 - val_loss: 2.0935 - val_root_mean_squared_error: 5.2079\n",
      "Epoch 96/100\n",
      "1329/1329 [==============================] - 6s 5ms/step - loss: 2.4098 - root_mean_squared_error: 6.0026 - val_loss: 2.1028 - val_root_mean_squared_error: 5.0957\n",
      "Epoch 97/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.4041 - root_mean_squared_error: 6.0018 - val_loss: 2.1161 - val_root_mean_squared_error: 5.1960\n",
      "Epoch 98/100\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 2.4210 - root_mean_squared_error: 6.0755 - val_loss: 2.1198 - val_root_mean_squared_error: 5.2235\n",
      "Epoch 99/100\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 2.4061 - root_mean_squared_error: 6.0360 - val_loss: 2.0874 - val_root_mean_squared_error: 4.9827\n",
      "Epoch 100/100\n",
      "1329/1329 [==============================] - 10s 8ms/step - loss: 2.4102 - root_mean_squared_error: 6.0756 - val_loss: 2.1045 - val_root_mean_squared_error: 5.1948\n",
      "Model training finished.\n",
      "Train RMSE: 5.104\n",
      "Evaluating model performance...\n",
      "Test RMSE: 5.054\n"
     ]
    }
   ],
   "source": [
    "def negative_loglikelihood(targets, estimated_distribution):\n",
    "    return -estimated_distribution.log_prob(targets)\n",
    "\n",
    "\n",
    "num_epochs = 100\n",
    "prob_bnn_model = create_probablistic_bnn_model(train_size)\n",
    "run_experiment(prob_bnn_model, negative_loglikelihood, train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fbaf113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction mean: 30.77, stddev: 8.22, 95% CI: [46.88 - 14.67] - Actual: 28.495\n",
      "Prediction mean: 1.55, stddev: 0.98, 95% CI: [3.48 - -0.37] - Actual: 0.111\n",
      "Prediction mean: 32.16, stddev: 8.19, 95% CI: [48.21 - 16.1] - Actual: 28.475\n",
      "Prediction mean: 26.27, stddev: 7.04, 95% CI: [40.07 - 12.47] - Actual: 24.654\n",
      "Prediction mean: 46.11, stddev: 7.24, 95% CI: [60.3 - 31.92] - Actual: 49.904\n",
      "Prediction mean: 4.61, stddev: 1.55, 95% CI: [7.65 - 1.57] - Actual: 4.189\n",
      "Prediction mean: 15.16, stddev: 3.36, 95% CI: [21.75 - 8.57] - Actual: 13.089\n",
      "Prediction mean: 15.07, stddev: 3.34, 95% CI: [21.61 - 8.53] - Actual: 13.446\n",
      "Prediction mean: 34.52, stddev: 8.1, 95% CI: [50.38 - 18.65] - Actual: 49.978\n",
      "Prediction mean: 31.45, stddev: 8.26, 95% CI: [47.64 - 15.26] - Actual: 35.389\n"
     ]
    }
   ],
   "source": [
    "prediction_distribution = prob_bnn_model(examples)\n",
    "prediction_mean = prediction_distribution.mean().numpy().tolist()\n",
    "prediction_stdv = prediction_distribution.stddev().numpy()\n",
    "\n",
    "# The 95% CI is computed as mean ± (1.96 * stdv)\n",
    "upper = (prediction_mean + (1.96 * prediction_stdv)).tolist()\n",
    "lower = (prediction_mean - (1.96 * prediction_stdv)).tolist()\n",
    "prediction_stdv = prediction_stdv.tolist()\n",
    "\n",
    "for idx in range(sample):\n",
    "    print(\n",
    "        f\"Prediction mean: {round(prediction_mean[idx][0], 2)}, \"\n",
    "        f\"stddev: {round(prediction_stdv[idx][0], 2)}, \"\n",
    "        f\"95% CI: [{round(upper[idx][0], 2)} - {round(lower[idx][0], 2)}]\"\n",
    "        f\" - Actual: {targets[idx]}\"\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfae844a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

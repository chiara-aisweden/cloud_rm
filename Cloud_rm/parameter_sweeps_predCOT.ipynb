{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_151915/4205888445.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "2024-03-21 13:41:41.832926: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 13:41:41.866680: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-21 13:41:41.866701: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-21 13:41:41.867554: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-21 13:41:41.873935: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-21 13:41:42.528822: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "\n",
    "import functions.parse_data as parse\n",
    "from functions.parse_data import synth_dataloader\n",
    "import functions.handy_functions as hf\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from multivariate_quantile_regression.network_model import QuantileNetwork\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "from cot_train.utils import MLP5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n",
      "Tensor is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    # CUDA is available, so let's set default device to GPU\n",
    "    torch.set_default_device(0)\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "else:\n",
    "    # CUDA is not available, so let's use the CPU\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "# Example usage:\n",
    "tensor = torch.randn(3, 3)  # Create a tensor on the selected device\n",
    "print(\"Tensor is on device:\", tensor.device)\n",
    "device = tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find same trainval/test split as Aleksis alg.\n",
    "#Load training, val and test data for indices\n",
    "traindata = pd.read_csv('cot_train/data/synthetic-cot-data/train_df.csv', index_col=[0])\n",
    "valdata = pd.read_csv('cot_train/data/synthetic-cot-data/val_df.csv', index_col=[0])\n",
    "testdata = pd.read_csv('cot_train/data/synthetic-cot-data/test_df.csv', index_col=[0])\n",
    "\n",
    "#Merge train and val data\n",
    "trainvaldata = pd.concat([traindata,valdata])\n",
    "\n",
    "#Split X's and y's\n",
    "X_cols = ['Cloud_B02','Cloud_B03','Cloud_B04','Cloud_B05','Cloud_B06',\n",
    "          'Cloud_B07','Cloud_B08','Cloud_B08A','Cloud_B09','Cloud_B10','Cloud_B11','Cloud_B12']\n",
    "y_cols = ['COT']\n",
    "\n",
    "X_trainval = trainvaldata[X_cols]\n",
    "X_test = testdata[X_cols]\n",
    "y_trainval = trainvaldata[y_cols]\n",
    "y_test = testdata[y_cols]\n",
    "\n",
    "#Add noise to X_test\n",
    "np.random.seed(313)\n",
    "X_test = X_test + np.random.randn(np.shape(X_test)[0],np.shape(X_test)[1]) * np.mean(X_trainval.to_numpy(),axis=0)*0.03\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up network parameters\n",
    "quantiles=np.array([0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9])\n",
    "no_nodes=100\n",
    "est= np.where(quantiles==0.5)[0].item()\n",
    "\n",
    "sequence= lambda: nn.Sequential(\n",
    "    nn.Linear(len(X_cols),no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(no_nodes, len(quantiles)*len(y_cols)) #Output dimesion is number of quantiles times number of target variables\n",
    ")\n",
    "\n",
    "val_size=0.1\n",
    "num_models=5 #Set number of ensambles\n",
    "batch_size=500\n",
    "nepochs=1000\n",
    "lr=0.003\n",
    "noise_ratio = 0.03\n",
    "early_break=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 100%|██████████| 320/320 [00:00<00:00, 384.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.45978138] Validation loss [0.4870517]\n",
      "Epoch 312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:00<00:00, 381.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.45800662] Validation loss [0.47346357]\n",
      "Epoch 313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:00<00:00, 328.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.45972043] Validation loss [0.47087502]\n",
      "Epoch 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:00<00:00, 327.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.45921057] Validation loss [0.46888846]\n",
      "Epoch 315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:00<00:00, 376.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.45519096] Validation loss [0.4726142]\n",
      "Epoch 316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:00<00:00, 383.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.45903578] Validation loss [0.4719434]\n",
      "---No improvement in 100 epochs, broke early---\n",
      "Best model out of total max epochs found at epoch 216\n",
      "With validation loss: 0.4663837254047394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Choose if to save models and metrics, if so set path\n",
    "save = True\n",
    "if save:\n",
    "    test_name = \"COT_estimators\"\n",
    "    main_filepath = 'pytorch_models/'+test_name\n",
    "\n",
    "\n",
    "#Initalize models\n",
    "models = [QuantileNetwork(quantiles=quantiles) for _ in range(num_models)]\n",
    "\n",
    "#Train models\n",
    "for i,model in enumerate(models):\n",
    "    #Find new train/val splits for each model for robustness\n",
    "    validation_indices=np.array(random.sample(range(len(X_trainval['Cloud_B02'])), int((len(X_trainval['Cloud_B02'])+len(X_test['Cloud_B02']))*val_size)))\n",
    "    train_indices=[i for i in range(len(X_trainval['Cloud_B02'])) if np.any(validation_indices==i)==False]  \n",
    "    #Fit model\n",
    "    model.fit(X_trainval.to_numpy(),y_trainval.to_numpy(), \n",
    "            train_indices=train_indices, \n",
    "            validation_indices=validation_indices, \n",
    "            batch_size=batch_size,\n",
    "            nepochs=nepochs,\n",
    "            sequence=sequence(),\n",
    "            lr=lr,\n",
    "            noise_ratio=noise_ratio,\n",
    "            early_break=early_break)\n",
    "    \n",
    "    #Save models if wanted\n",
    "    if save:\n",
    "        filepath=main_filepath+'/model'+str(i)\n",
    "        os.makedirs(filepath,exist_ok=True)\n",
    "        torch.save(model,filepath+'/model_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_73203/2016707059.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  COT_model_metrics=pd.concat([COT_model_metrics,tmp_metrics])\n"
     ]
    }
   ],
   "source": [
    "#Initialize dataframe for error metrics and array for ensemble predictions\n",
    "COT_model_metrics=pd.DataFrame(columns=['Ensemble_mean','Ensemble_index','MSE','R2_score','MAE','Mean_Quantile_Loss'])\n",
    "preds_total=[]\n",
    "#Make predictions and evaluate\n",
    "for i,model in enumerate(models):\n",
    "    preds = model.predict(X_test.to_numpy())\n",
    "    #Keep track of ensemble prediction\n",
    "    if i==0:\n",
    "        preds_total=preds\n",
    "    else:\n",
    "        preds_total=preds_total+preds\n",
    "\n",
    "    #Find errors\n",
    "    mse=mean_squared_error(y_test.to_numpy(),preds[:,:,est])\n",
    "    r2=r2_score(y_test.to_numpy(),preds[:,:,est])\n",
    "    MAE=np.mean(np.abs(y_test.to_numpy()-preds[:,:,est]))\n",
    "    mean_quantile=QuantileNetwork.mean_marginal_loss(y_test.to_numpy(),preds,quantiles)\n",
    "    #Add to dataframe\n",
    "    tmp_metrics=pd.DataFrame(data=[[False,i,mse,r2,MAE,mean_quantile]],columns=['Ensemble_mean','Ensemble_index','MSE','R2_score','MAE','Mean_Quantile_Loss'])\n",
    "    COT_model_metrics=pd.concat([COT_model_metrics,tmp_metrics])\n",
    "\n",
    "\n",
    "#Now do the same for ensemble predictions\n",
    "preds_total=preds_total/num_models\n",
    "\n",
    "mse=mean_squared_error(y_test.to_numpy(),preds_total[:,:,est])\n",
    "r2=r2_score(y_test.to_numpy(),preds_total[:,:,est])\n",
    "MAE=np.mean(np.abs(y_test.to_numpy()-preds_total[:,:,est]))\n",
    "mean_quantile=QuantileNetwork.mean_marginal_loss(y_test.to_numpy(),preds_total,quantiles)\n",
    "\n",
    "tmp_metrics=pd.DataFrame(data=[[True,np.nan,mse,r2,MAE,mean_quantile]],columns=['Ensemble_mean','Ensemble_index','MSE','R2_score','MAE','Mean_Quantile_Loss'])\n",
    "COT_model_metrics=pd.concat([COT_model_metrics,tmp_metrics])\n",
    "\n",
    "#Save metrics if we want to\n",
    "if save:\n",
    "    COT_model_metrics=COT_model_metrics.reset_index(drop=True)\n",
    "    COT_model_metrics.to_csv(main_filepath+'/model_metrics.csv',index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123537/3934616882.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  COT2_model_metrics=pd.concat([COT2_model_metrics,tmp_metrics])\n"
     ]
    }
   ],
   "source": [
    "#Load in Aleks alg models\n",
    "\n",
    "#Choose if to save metrics, if so set path\n",
    "save = True\n",
    "if save:\n",
    "    filepath='smhi_models2'\n",
    "\n",
    "#Set up paths for importing COT est models\n",
    "COT_model_paths = ['smhi_models2/0/model_it_2000000','smhi_models2/1/model_it_2000000','smhi_models2/2/model_it_2000000','smhi_models2/3/model_it_2000000','smhi_models2/4/model_it_2000000']\n",
    "\n",
    "#Initialize and load COT estimation models\n",
    "COT_est_models = [MLP5(12, 1, apply_relu=True) for _ in range(len(COT_model_paths))]\n",
    "for i,model in enumerate(COT_est_models):\n",
    "    model.load_state_dict(torch.load(COT_model_paths[i],map_location=device))\n",
    "\n",
    "#Normalize X_test w.r.t X_train and turn to tensor\n",
    "X_mu = np.mean(X_trainval.to_numpy(),axis=0)\n",
    "X_std = np.std(X_trainval.to_numpy(),axis=0)\n",
    "X_test_norm = (X_test.to_numpy()-X_mu)/X_std\n",
    "tX_test_norm = torch.Tensor(X_test_norm).to(device)\n",
    "\n",
    "#Initialize dataframe for error metrics and array for ensemble predictions\n",
    "COT2_model_metrics=pd.DataFrame(columns=['Ensemble_mean','Ensemble_index','MSE','R2_score','MAE'])\n",
    "preds_total=[]\n",
    "\n",
    "#Make predictions and find errors\n",
    "for i,model in enumerate(COT_est_models):\n",
    "    preds = 50*model(tX_test_norm).cpu().detach().numpy()\n",
    "    #Keep track of ensemble prediction\n",
    "    if i==0:\n",
    "        preds_total=preds\n",
    "    else:\n",
    "        preds_total=preds_total+preds\n",
    "\n",
    "    #Find errors\n",
    "    mse=mean_squared_error(y_test.to_numpy(),preds[:,0])\n",
    "    r2=r2_score(y_test.to_numpy(),preds[:,0])\n",
    "    MAE=np.mean(np.abs(y_test.to_numpy()-preds))\n",
    "    #Add to dataframe\n",
    "    tmp_metrics=pd.DataFrame(data=[[False,i,mse,r2,MAE]],columns=['Ensemble_mean','Ensemble_index','MSE','R2_score','MAE'])\n",
    "    COT2_model_metrics=pd.concat([COT2_model_metrics,tmp_metrics])\n",
    "\n",
    "#Now do the same for ensemble predictions\n",
    "preds_total=preds_total/len(COT_model_paths)\n",
    "\n",
    "mse=mean_squared_error(y_test.to_numpy(),preds_total[:,0])\n",
    "r2=r2_score(y_test.to_numpy(),preds_total[:,0])\n",
    "MAE=np.mean(np.abs(y_test.to_numpy()-preds_total))\n",
    "\n",
    "tmp_metrics=pd.DataFrame(data=[[True,np.nan,mse,r2,MAE]],columns=['Ensemble_mean','Ensemble_index','MSE','R2_score','MAE'])\n",
    "COT2_model_metrics=pd.concat([COT2_model_metrics,tmp_metrics])\n",
    "\n",
    "if save:\n",
    "    COT2_model_metrics=COT2_model_metrics.reset_index(drop=True)\n",
    "    COT2_model_metrics.to_csv(filepath+'/model_metrics.csv',index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ensemble_mean</th>\n",
       "      <th>Ensemble_index</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2_score</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Mean_Quantile_Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>18.749951</td>\n",
       "      <td>0.926429</td>\n",
       "      <td>2.097113</td>\n",
       "      <td>7.337143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>19.257174</td>\n",
       "      <td>0.924439</td>\n",
       "      <td>2.117094</td>\n",
       "      <td>7.415202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>18.775662</td>\n",
       "      <td>0.926328</td>\n",
       "      <td>2.098432</td>\n",
       "      <td>7.330111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>18.776029</td>\n",
       "      <td>0.926327</td>\n",
       "      <td>2.112563</td>\n",
       "      <td>7.369339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>18.785021</td>\n",
       "      <td>0.926292</td>\n",
       "      <td>2.108568</td>\n",
       "      <td>7.393313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.507435</td>\n",
       "      <td>0.931305</td>\n",
       "      <td>2.032781</td>\n",
       "      <td>7.093999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ensemble_mean Ensemble_index        MSE  R2_score       MAE  \\\n",
       "0         False              0  18.749951  0.926429  2.097113   \n",
       "1         False              1  19.257174  0.924439  2.117094   \n",
       "2         False              2  18.775662  0.926328  2.098432   \n",
       "3         False              3  18.776029  0.926327  2.112563   \n",
       "4         False              4  18.785021  0.926292  2.108568   \n",
       "5          True            NaN  17.507435  0.931305  2.032781   \n",
       "\n",
       "   Mean_Quantile_Loss  \n",
       "0            7.337143  \n",
       "1            7.415202  \n",
       "2            7.330111  \n",
       "3            7.369339  \n",
       "4            7.393313  \n",
       "5            7.093999  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COT_model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ensemble_mean</th>\n",
       "      <th>Ensemble_index</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2_score</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>18.310374</td>\n",
       "      <td>0.928154</td>\n",
       "      <td>2.317118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>18.760399</td>\n",
       "      <td>0.926388</td>\n",
       "      <td>2.413007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>18.938435</td>\n",
       "      <td>0.925690</td>\n",
       "      <td>2.330338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>19.081660</td>\n",
       "      <td>0.925128</td>\n",
       "      <td>2.328644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>18.662185</td>\n",
       "      <td>0.926774</td>\n",
       "      <td>2.393497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.310384</td>\n",
       "      <td>0.932078</td>\n",
       "      <td>2.255509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ensemble_mean Ensemble_index        MSE  R2_score       MAE\n",
       "0         False              0  18.310374  0.928154  2.317118\n",
       "0         False              1  18.760399  0.926388  2.413007\n",
       "0         False              2  18.938435  0.925690  2.330338\n",
       "0         False              3  19.081660  0.925128  2.328644\n",
       "0         False              4  18.662185  0.926774  2.393497\n",
       "0          True            NaN  17.310384  0.932078  2.255509"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COT2_model_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try to train COT est model with sun zen angle as input aswell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find same trainval/test split as Aleksis alg.\n",
    "#Load training, val and test data for indices\n",
    "traindata = pd.read_csv('cot_train/data/synthetic-cot-data/train_df.csv', index_col=[0])\n",
    "valdata = pd.read_csv('cot_train/data/synthetic-cot-data/val_df.csv', index_col=[0])\n",
    "testdata = pd.read_csv('cot_train/data/synthetic-cot-data/test_df.csv', index_col=[0])\n",
    "\n",
    "#Merge train and val data\n",
    "trainvaldata = pd.concat([traindata,valdata])\n",
    "\n",
    "#Split X's and y's\n",
    "X_cols = ['Cloud_B02','Cloud_B03','Cloud_B04','Cloud_B05','Cloud_B06',\n",
    "          'Cloud_B07','Cloud_B08','Cloud_B08A','Cloud_B09','Cloud_B10','Cloud_B11','Cloud_B12','Sun_Zenith_Angle']\n",
    "y_cols = ['COT']\n",
    "\n",
    "X_trainval = trainvaldata[X_cols]\n",
    "X_test = testdata[X_cols]\n",
    "y_trainval = trainvaldata[y_cols]\n",
    "y_test = testdata[y_cols]\n",
    "\n",
    "#Add noise to X_test\n",
    "np.random.seed(313)\n",
    "X_test = X_test + np.random.randn(np.shape(X_test)[0],np.shape(X_test)[1]) * np.mean(X_trainval.to_numpy(),axis=0)*0.03\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up network parameters\n",
    "quantiles=np.array([0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9])\n",
    "no_nodes=100\n",
    "est= np.where(quantiles==0.5)[0].item()\n",
    "\n",
    "sequence= lambda: nn.Sequential(\n",
    "    nn.Linear(len(X_cols),no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(no_nodes, len(quantiles)*len(y_cols)) #Output dimesion is number of quantiles times number of target variables\n",
    ")\n",
    "\n",
    "val_size=0.1\n",
    "num_models=5 #Set number of ensambles\n",
    "batch_size=500\n",
    "nepochs=1000\n",
    "lr=0.003\n",
    "noise_ratio = 0.03\n",
    "early_break=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 100%|██████████| 320/320 [00:00<00:00, 357.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.37886465] Validation loss [0.38638365]\n",
      "Epoch 352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 100%|██████████| 320/320 [00:00<00:00, 373.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.37821856] Validation loss [0.3862812]\n",
      "Epoch 353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:00<00:00, 390.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.37902716] Validation loss [0.38521114]\n",
      "Epoch 354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:00<00:00, 388.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.37640718] Validation loss [0.38535565]\n",
      "Epoch 355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:00<00:00, 394.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.3762974] Validation loss [0.38419768]\n",
      "Epoch 356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:00<00:00, 396.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.37817258] Validation loss [0.38244364]\n",
      "---No improvement in 100 epochs, broke early---\n",
      "Best model out of total max epochs found at epoch 256\n",
      "With validation loss: 0.37934136390686035\n"
     ]
    }
   ],
   "source": [
    "#Choose if to save models and metrics, if so set path\n",
    "save = True\n",
    "if save:\n",
    "    test_name = \"COT_estimators_w_SunZen\"\n",
    "    main_filepath = 'pytorch_models/'+test_name\n",
    "\n",
    "\n",
    "#Initalize models\n",
    "models = [QuantileNetwork(quantiles=quantiles) for _ in range(num_models)]\n",
    "\n",
    "#Train models\n",
    "for i,model in enumerate(models):\n",
    "    #Find new train/val splits for each model for robustness\n",
    "    validation_indices=np.array(random.sample(range(len(X_trainval['Cloud_B02'])), int((len(X_trainval['Cloud_B02'])+len(X_test['Cloud_B02']))*val_size)))\n",
    "    train_indices=[i for i in range(len(X_trainval['Cloud_B02'])) if np.any(validation_indices==i)==False]  \n",
    "    #Fit model\n",
    "    model.fit(X_trainval.to_numpy(),y_trainval.to_numpy(), \n",
    "            train_indices=train_indices, \n",
    "            validation_indices=validation_indices, \n",
    "            batch_size=batch_size,\n",
    "            nepochs=nepochs,\n",
    "            sequence=sequence(),\n",
    "            lr=lr,\n",
    "            noise_ratio=noise_ratio,\n",
    "            early_break=early_break)\n",
    "    \n",
    "    #Save models if wanted\n",
    "    if save:\n",
    "        filepath=main_filepath+'/model'+str(i)\n",
    "        os.makedirs(filepath,exist_ok=True)\n",
    "        torch.save(model,filepath+'/model_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_151915/3215346210.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  COTwSZ_model_metrics=pd.concat([COTwSZ_model_metrics,tmp_metrics])\n"
     ]
    }
   ],
   "source": [
    "#Initialize dataframe for error metrics and array for ensemble predictions\n",
    "COTwSZ_model_metrics=pd.DataFrame(columns=['Ensemble_mean','Ensemble_index','MSE','R2_score','MAE','Mean_Quantile_Loss'])\n",
    "preds_total=[]\n",
    "#Make predictions and evaluate\n",
    "for i,model in enumerate(models):\n",
    "    preds = model.predict(X_test.to_numpy())\n",
    "    #Keep track of ensemble prediction\n",
    "    if i==0:\n",
    "        preds_total=preds\n",
    "    else:\n",
    "        preds_total=preds_total+preds\n",
    "\n",
    "    #Find errors\n",
    "    mse=mean_squared_error(y_test.to_numpy(),preds[:,:,est])\n",
    "    r2=r2_score(y_test.to_numpy(),preds[:,:,est])\n",
    "    MAE=np.mean(np.abs(y_test.to_numpy()-preds[:,:,est]))\n",
    "    mean_quantile=QuantileNetwork.mean_marginal_loss(y_test.to_numpy(),preds,quantiles)\n",
    "    #Add to dataframe\n",
    "    tmp_metrics=pd.DataFrame(data=[[False,i,mse,r2,MAE,mean_quantile]],columns=['Ensemble_mean','Ensemble_index','MSE','R2_score','MAE','Mean_Quantile_Loss'])\n",
    "    COTwSZ_model_metrics=pd.concat([COTwSZ_model_metrics,tmp_metrics])\n",
    "\n",
    "\n",
    "#Now do the same for ensemble predictions\n",
    "preds_total=preds_total/num_models\n",
    "\n",
    "mse=mean_squared_error(y_test.to_numpy(),preds_total[:,:,est])\n",
    "r2=r2_score(y_test.to_numpy(),preds_total[:,:,est])\n",
    "MAE=np.mean(np.abs(y_test.to_numpy()-preds_total[:,:,est]))\n",
    "mean_quantile=QuantileNetwork.mean_marginal_loss(y_test.to_numpy(),preds_total,quantiles)\n",
    "\n",
    "tmp_metrics=pd.DataFrame(data=[[True,np.nan,mse,r2,MAE,mean_quantile]],columns=['Ensemble_mean','Ensemble_index','MSE','R2_score','MAE','Mean_Quantile_Loss'])\n",
    "COTwSZ_model_metrics=pd.concat([COTwSZ_model_metrics,tmp_metrics])\n",
    "\n",
    "#Save metrics if we want to\n",
    "if save:\n",
    "    COTwSZ_model_metrics=COTwSZ_model_metrics.reset_index(drop=True)\n",
    "    COTwSZ_model_metrics.to_csv(main_filepath+'/model_metrics.csv',index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ensemble_mean</th>\n",
       "      <th>Ensemble_index</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2_score</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Mean_Quantile_Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>12.476870</td>\n",
       "      <td>0.951044</td>\n",
       "      <td>1.762433</td>\n",
       "      <td>6.210402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>12.361089</td>\n",
       "      <td>0.951498</td>\n",
       "      <td>1.752743</td>\n",
       "      <td>6.169383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>13.077447</td>\n",
       "      <td>0.948687</td>\n",
       "      <td>1.775512</td>\n",
       "      <td>6.250073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>12.430350</td>\n",
       "      <td>0.951226</td>\n",
       "      <td>1.745426</td>\n",
       "      <td>6.166187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>12.564375</td>\n",
       "      <td>0.950700</td>\n",
       "      <td>1.740261</td>\n",
       "      <td>6.121135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.498256</td>\n",
       "      <td>0.954883</td>\n",
       "      <td>1.682304</td>\n",
       "      <td>5.912684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ensemble_mean Ensemble_index        MSE  R2_score       MAE  \\\n",
       "0         False              0  12.476870  0.951044  1.762433   \n",
       "1         False              1  12.361089  0.951498  1.752743   \n",
       "2         False              2  13.077447  0.948687  1.775512   \n",
       "3         False              3  12.430350  0.951226  1.745426   \n",
       "4         False              4  12.564375  0.950700  1.740261   \n",
       "5          True            NaN  11.498256  0.954883  1.682304   \n",
       "\n",
       "   Mean_Quantile_Loss  \n",
       "0            6.210402  \n",
       "1            6.169383  \n",
       "2            6.250073  \n",
       "3            6.166187  \n",
       "4            6.121135  \n",
       "5            5.912684  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COTwSZ_model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

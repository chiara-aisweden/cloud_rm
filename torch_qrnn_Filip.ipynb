{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 15:54:59.182089: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "\n",
    "import functions.parse_data as parse\n",
    "import functions.handy_functions as hf\n",
    "\n",
    "from multivariate_quantile_regression.network_model import QuantileNetwork\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_labels= ['Cloud_B02','Cloud_B03','Cloud_B04','Cloud_B05','Cloud_B06','Cloud_B07',\n",
    "                 'Cloud_B08','Cloud_B09','Cloud_B10','Cloud_B11','Cloud_B12','Cloud_B13']\n",
    "\n",
    "data_water=parse.parse('SMHIdata/cloudrm_water.dat')\n",
    "data_clear=parse.parse('SMHIdata/cloudrm_clear.dat')\n",
    "data_ice=parse.parse('SMHIdata/cloudrm_ice.dat')\n",
    "data_mixed=parse.parse('SMHIdata/cloudrm_mixed.dat')\n",
    "\n",
    "#Concatinate all datasets\n",
    "data_all=pd.concat([data_water, data_clear, data_ice, data_mixed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise standard deviation for Cloud_B02: 0.00335001428051948\n",
      "Noise standard deviation for Cloud_B03: 0.002912530185416667\n",
      "Noise standard deviation for Cloud_B04: 0.004058081082042254\n",
      "Noise standard deviation for Cloud_B05: 0.0046524891611111115\n",
      "Noise standard deviation for Cloud_B06: 0.007455351321348316\n",
      "Noise standard deviation for Cloud_B07: 0.008871707484285717\n",
      "Noise standard deviation for Cloud_B08: 0.04489677938000001\n",
      "Noise standard deviation for Cloud_B09: 0.005688141120114942\n",
      "Noise standard deviation for Cloud_B10: 0.003909328971491229\n",
      "Noise standard deviation for Cloud_B11: 0.0014014724139999996\n",
      "Noise standard deviation for Cloud_B12: 0.005030040539999999\n",
      "Noise standard deviation for Cloud_B13: 0.004041267081999999\n"
     ]
    }
   ],
   "source": [
    "channel_labels= ['Cloud_B02','Cloud_B03','Cloud_B04','Cloud_B05','Cloud_B06','Cloud_B07',\n",
    "                 'Cloud_B08','Cloud_B09','Cloud_B10','Cloud_B11','Cloud_B12','Cloud_B13']\n",
    "\n",
    "data_water=parse.parse('SMHIdata/cloudrm_water.dat')\n",
    "data_clear=parse.parse('SMHIdata/cloudrm_clear.dat')\n",
    "data_ice=parse.parse('SMHIdata/cloudrm_ice.dat')\n",
    "data_mixed=parse.parse('SMHIdata/cloudrm_mixed.dat')\n",
    "\n",
    "#Concatinate all datasets\n",
    "data_all=pd.concat([data_water, data_clear, data_ice, data_mixed])\n",
    "data_all=data_all.drop(columns=['Surface_Desc','Cloud_B01','Clear_B01'])\n",
    "data_all=hf.add_MSI_noise(data_all,channel_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Train test validation split##\n",
    "X_labels= ['Cloud_B02','Cloud_B03','Cloud_B04','Cloud_B05','Cloud_B06',\n",
    "           'Cloud_B07','Cloud_B08','Cloud_B09','Cloud_B10','Cloud_B11','Cloud_B12','Cloud_B13',\n",
    "           'Sat_Zenith_Angle','Sun_Zenith_Angle','Azimuth_Diff_Angle']\n",
    "\n",
    "#Leave out 'GOT', 'Water_Vapor'\n",
    "#Band 1 no go.\n",
    "y_labels=['Clear_B02','Clear_B03','Clear_B04','Clear_B05','Clear_B06',\n",
    "           'Clear_B07','Clear_B08','Clear_B09','Clear_B10','Clear_B11','Clear_B12','Clear_B13']\n",
    "\n",
    "df=hf.normalise_input_df(data_all,X_labels)\n",
    "df=hf.add_noise(df,X_labels,sigma=0.001)\n",
    "\n",
    "##Split data##\n",
    "X=df[X_labels]\n",
    "y=df[y_labels]\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "val_size=0.05\n",
    "validation_indices=np.array(random.sample(range(len(X_train['Cloud_B02'])), int(len(X_train['Cloud_B02'])*val_size)))\n",
    "train_indices=[i for i in range(len(X_train['Cloud_B02'])) if np.any(validation_indices==i)==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 1805it [00:05, 310.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.821985] Validation loss [0.6158754]\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 1805it [00:05, 332.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.5808215] Validation loss [0.5572314]\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 1805it [00:05, 316.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.541332] Validation loss [0.539154]\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 1805it [00:04, 370.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.5181232] Validation loss [0.5166738]\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 1805it [00:05, 318.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.50260186] Validation loss [0.4997411]\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 1805it [00:05, 314.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.49033925] Validation loss [0.4843801]\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 1805it [00:05, 345.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.4831165] Validation loss [0.47818246]\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 1805it [00:05, 333.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.47521508] Validation loss [0.4721357]\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 1805it [00:06, 274.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.46885958] Validation loss [0.4687285]\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 1805it [00:10, 171.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.46457747] Validation loss [0.45986432]\n",
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 1805it [00:04, 368.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.4607827] Validation loss [0.46006066]\n",
      "Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 1805it [00:05, 337.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.45666632] Validation loss [0.4500811]\n",
      "Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 1805it [00:04, 361.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.45338735] Validation loss [0.45308897]\n",
      "Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 1805it [00:05, 352.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.44954103] Validation loss [0.4480877]\n",
      "Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 1805it [00:05, 321.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.44732556] Validation loss [0.453572]\n",
      "Epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 1805it [00:05, 335.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.4449238] Validation loss [0.4487882]\n",
      "Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 1805it [00:06, 298.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.44276646] Validation loss [0.44012603]\n",
      "Epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 1805it [00:04, 391.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.440109] Validation loss [0.43826443]\n",
      "Epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 1805it [00:05, 338.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.43842563] Validation loss [0.43648875]\n",
      "Epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 1805it [00:05, 320.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [0.4363984] Validation loss [0.44017497]\n"
     ]
    }
   ],
   "source": [
    "quantiles=np.array([0.1,0.5,0.9])\n",
    "batch_size=100\n",
    "nepochs=20\n",
    "\n",
    "model=QuantileNetwork(quantiles=quantiles)\n",
    "model.fit(X_train.to_numpy(),y_train.to_numpy(),train_indices,validation_indices,batch_size=batch_size,nepochs=nepochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004971541083211003"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## MSE ##\n",
    "mean_squared_error(y_test.to_numpy(),preds[:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:84: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Clear_B02    25.550308\n",
       "Clear_B03    25.680776\n",
       "Clear_B04    26.098444\n",
       "Clear_B05    26.182213\n",
       "Clear_B06    26.207906\n",
       "Clear_B07    26.232023\n",
       "Clear_B08    26.223335\n",
       "Clear_B09    26.239421\n",
       "Clear_B10    25.963041\n",
       "Clear_B11    23.963525\n",
       "Clear_B12    25.950569\n",
       "Clear_B13    25.926042\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## PSNR ##\n",
    "QuantileNetwork.PSNR(y_test,preds[:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23885833333333334"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Outrate ##\n",
    "QuantileNetwork.calc_outrate(y_test.to_numpy(),preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

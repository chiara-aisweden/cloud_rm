{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quant_cross(y_pred):\n",
    "        if len(np.shape(y_pred)) == 3:\n",
    "            crosscount = 0\n",
    "            for i in range(np.shape(y_pred)[0]):\n",
    "                for j in range(np.shape(y_pred)[1]):\n",
    "                    for k in range(np.shape(y_pred)[2]-1):\n",
    "                        if y_pred[i,j,k+1] < y_pred[i,j,k]:\n",
    "                            crosscount = crosscount + 1 \n",
    "\n",
    "        else:\n",
    "            crosscount = 0\n",
    "            for i in range(np.shape(y_pred)[0]):\n",
    "                for j in range(np.shape(y_pred)[1]-1):\n",
    "                    if y_pred[i,j+1] < y_pred[i,j]:\n",
    "                        crosscount = crosscount + 1 \n",
    "\n",
    "        crossrate = crosscount/(np.size(y_pred)-np.size(y_pred[...,0]))\n",
    "\n",
    "        return crossrate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quants = np.array([[1,2,3],[3,2,1]])\n",
    "\n",
    "quant_cross(quants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "quantiles=np.array([0.1,0.5,0.9])\n",
    "est= np.where(quantiles==0.5)[0].item()\n",
    "print(est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-03-11_13-13-15'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d_%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_train = np.load('log/2024-03-11_13-47-44/train_stats/RMSE_train.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NpzFile 'log/2024-03-11_13-47-44/train_stats/RMSE_train.npz' with keys: values, means, mas, times"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.53125024, 3.65625012, 4.15625008, ..., 4.48533434, 4.48463026,\n",
       "       4.48589563])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "means = RMSE_train['mas']\n",
    "np.size(means)\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=[0,1,2,3,4,5,6,7,8,9,10,11,12,13]\n",
    "A[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500.0\n",
      "500.0\n",
      "500.0\n",
      "1000.0\n"
     ]
    }
   ],
   "source": [
    "A=np.array([500,500,500,500])\n",
    "B=np.array([0,0,2000,0])\n",
    "\n",
    "print(np.mean(np.abs(A)))\n",
    "print(np.mean(np.abs(B)))\n",
    "print(np.sqrt(np.mean(A**2)))\n",
    "print(np.sqrt(np.mean(B**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=13, out_features=100, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (7): ReLU()\n",
      "  (8): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (9): ReLU()\n",
      "  (10): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (11): ReLU()\n",
      "  (12): Linear(in_features=100, out_features=36, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Set up NN structure\n",
    "no_nodes = 100\n",
    "\n",
    "sequence= nn.Sequential(\n",
    "    nn.Linear(13,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(no_nodes, 3*12) #Output dimesion is number of quantiles times number of target variables\n",
    ")\n",
    "\n",
    "print(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=13, out_features=100, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (7): ReLU()\n",
      "  (8): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (9): ReLU()\n",
      "  (10): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (11): ReLU()\n",
      "  (12): Linear(in_features=100, out_features=36, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "no_layers=5\n",
    "modules = []\n",
    "modules.append(nn.Linear(len(X_cols),no_nodes))\n",
    "modules.append(nn.ReLU())\n",
    "for i in range(no_layers):\n",
    "    modules.append(nn.Linear(no_nodes,no_nodes))\n",
    "    modules.append(nn.ReLU())\n",
    "modules.append(nn.Linear(no_nodes, len(quantiles)*len(y_cols)))\n",
    "sequence = lambda: nn.Sequential(*modules)\n",
    "\n",
    "print(sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76923077 0.15384615 0.07692308]\n",
      "[0.76923077 0.30769231 0.23076923]\n",
      "2.0\n",
      "1.3076923076923077\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "uncs = np.array([1,5,10])\n",
    "invuncs_norm = (1/uncs)/sum(1/uncs)\n",
    "print(invuncs_norm)\n",
    "preds = np.array([1,2,3])\n",
    "uncpreds = invuncs_norm*preds\n",
    "\n",
    "prediction = sum(uncpreds)\n",
    "print(uncpreds)\n",
    "print(np.mean(preds))\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n",
      "Tensor is on device: cuda:0\n",
      "Softplus(beta=1, threshold=20)\n",
      "tensor([[[-9.0000, -8.9997, -8.9988, -8.9963, -8.9896],\n",
      "         [-9.0000, -8.9997, -8.9988, -8.9963, -8.9896]],\n",
      "\n",
      "        [[-9.0000, -8.9997, -8.9988, -8.9963, -8.9896],\n",
      "         [-9.0000, -8.9997, -8.9988, -8.9963, -8.9896]]], device='cuda:0')\n",
      "tensor([[[0.0001, 0.0005, 0.0014, 0.0038, 0.0106],\n",
      "         [0.0001, 0.0005, 0.0014, 0.0038, 0.0106]],\n",
      "\n",
      "        [[0.0001, 0.0005, 0.0014, 0.0038, 0.0106],\n",
      "         [0.0001, 0.0005, 0.0014, 0.0038, 0.0106]]], device='cuda:0')\n",
      "tensor([[[0.0001, 0.0003, 0.0009, 0.0025, 0.0067],\n",
      "         [0.0001, 0.0003, 0.0009, 0.0025, 0.0067]],\n",
      "\n",
      "        [[0.0001, 0.0003, 0.0009, 0.0025, 0.0067],\n",
      "         [0.0001, 0.0003, 0.0009, 0.0025, 0.0067]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    # CUDA is available, so let's set default device to GPU\n",
    "    torch.set_default_device(0)\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "else:\n",
    "    # CUDA is not available, so let's use the CPU\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "# Example usage:\n",
    "tensor = torch.randn(3, 3)  # Create a tensor on the selected device\n",
    "print(\"Tensor is on device:\", tensor.device)\n",
    "device = tensor.device\n",
    "\n",
    "fout = np.array([[[-9,-8,-7,-6,-5],[-9,-8,-7,-6,-5]],[[-9,-8,-7,-6,-5],[-9,-8,-7,-6,-5]]])\n",
    "\n",
    "#fout = fo.reshape((-1, 2, 3))\n",
    "\n",
    "fout=torch.tensor(fout,dtype=torch.float,device=device)\n",
    "softplus = nn.Softplus()\n",
    "print(softplus)\n",
    "print(torch.cat((fout[...,0:1], fout[...,0:1] + torch.cumsum(softplus(fout[...,1:]), dim=-1)), dim=-1))\n",
    "print(torch.cumsum(softplus(fout), dim=-1))\n",
    "print(softplus(fout))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 3)\n",
      "(2, 2, 1)\n",
      "hej\n",
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "fo = np.array([[[1,2,3],[1,2,3]],[[1,2,3],[1,2,3]]])\n",
    "print(fo.shape)\n",
    "print(fo[:,:,0:1].shape)\n",
    "print('hej')\n",
    "print(fo[:,:,0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=[1,2,3,4,5]\n",
    "A[0:1]\n",
    "A[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         2.82842712]\n",
      "1.4142135623730951\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "clip() missing 1 required positional argument: 'a_max'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(meandist)\n\u001b[1;32m     10\u001b[0m C\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m])\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: clip() missing 1 required positional argument: 'a_max'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "A=np.array([[1,1],[3,3]])\n",
    "B=np.array([1,1])\n",
    "\n",
    "dists=np.sqrt(np.sum((A-B)**2,axis=1))\n",
    "meandist=np.mean(dists)\n",
    "print(dists)\n",
    "print(meandist)\n",
    "\n",
    "C=np.array([1,2,3,4,5])\n",
    "print(np.clip(C,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n",
      "Tensor is on device: cuda:0\n",
      "tensor([1., 2., 3.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    # CUDA is available, so let's set default device to GPU\n",
    "    torch.set_default_device(0)\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "else:\n",
    "    # CUDA is not available, so let's use the CPU\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "# Example usage:\n",
    "tensor = torch.randn(3, 3)  # Create a tensor on the selected device\n",
    "print(\"Tensor is on device:\", tensor.device)\n",
    "device = tensor.device\n",
    "\n",
    "\n",
    "X=np.array([1,2,3])\n",
    "tX = torch.tensor(X,dtype=torch.float,device=device)\n",
    "tn=tX.clone()\n",
    "tb=np.array([1,1])\n",
    "ta=torch.tensor(tb,dtype=torch.float,device=device)\n",
    "tn[:2]=tn[:2]+ta\n",
    "\n",
    "print(tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

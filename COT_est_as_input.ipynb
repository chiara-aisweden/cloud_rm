{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 13:04:59.860938: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-22 13:04:59.895109: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-22 13:04:59.895127: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-22 13:04:59.895963: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-22 13:04:59.901748: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-22 13:05:00.579786: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "\n",
    "from functions.parse_data import synth_dataloader\n",
    "from multivariate_quantile_regression.network_model import QuantileNetwork\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from cot_train.utils import MLP5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n",
      "Tensor is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    # CUDA is available, so let's set default device to GPU\n",
    "    torch.set_default_device(0)\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "else:\n",
    "    # CUDA is not available, so let's use the CPU\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "# Example usage:\n",
    "tensor = torch.randn(3, 3)  # Create a tensor on the selected device\n",
    "print(\"Tensor is on device:\", tensor.device)\n",
    "device = tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cloud_B02</th>\n",
       "      <th>Cloud_B03</th>\n",
       "      <th>Cloud_B04</th>\n",
       "      <th>Cloud_B05</th>\n",
       "      <th>Cloud_B06</th>\n",
       "      <th>Cloud_B07</th>\n",
       "      <th>Cloud_B08</th>\n",
       "      <th>Cloud_B08A</th>\n",
       "      <th>Cloud_B09</th>\n",
       "      <th>Cloud_B10</th>\n",
       "      <th>...</th>\n",
       "      <th>Clear_B11</th>\n",
       "      <th>Clear_B12</th>\n",
       "      <th>Sat_Zenith_Angle</th>\n",
       "      <th>Sun_Zenith_Angle</th>\n",
       "      <th>Azimuth_Diff_Angle</th>\n",
       "      <th>COT</th>\n",
       "      <th>Cloud_Type</th>\n",
       "      <th>Profile_ID</th>\n",
       "      <th>GOT</th>\n",
       "      <th>Water_Vapor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.57804</td>\n",
       "      <td>0.51792</td>\n",
       "      <td>0.54680</td>\n",
       "      <td>0.56000</td>\n",
       "      <td>0.56824</td>\n",
       "      <td>0.57365</td>\n",
       "      <td>0.56583</td>\n",
       "      <td>0.57950</td>\n",
       "      <td>0.37962</td>\n",
       "      <td>0.01949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04745</td>\n",
       "      <td>0.03758</td>\n",
       "      <td>9.00</td>\n",
       "      <td>68.68</td>\n",
       "      <td>48.59</td>\n",
       "      <td>25.181</td>\n",
       "      <td>3</td>\n",
       "      <td>9543</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.28975</td>\n",
       "      <td>0.25479</td>\n",
       "      <td>0.29171</td>\n",
       "      <td>0.32868</td>\n",
       "      <td>0.40295</td>\n",
       "      <td>0.44817</td>\n",
       "      <td>0.45809</td>\n",
       "      <td>0.50999</td>\n",
       "      <td>0.17019</td>\n",
       "      <td>0.00067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75602</td>\n",
       "      <td>0.58746</td>\n",
       "      <td>1.60</td>\n",
       "      <td>73.05</td>\n",
       "      <td>176.23</td>\n",
       "      <td>1.730</td>\n",
       "      <td>2</td>\n",
       "      <td>3672</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.71170</td>\n",
       "      <td>0.68907</td>\n",
       "      <td>0.73376</td>\n",
       "      <td>0.76922</td>\n",
       "      <td>0.81416</td>\n",
       "      <td>0.83261</td>\n",
       "      <td>0.83383</td>\n",
       "      <td>0.85262</td>\n",
       "      <td>0.63399</td>\n",
       "      <td>0.10050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.65577</td>\n",
       "      <td>0.52408</td>\n",
       "      <td>14.75</td>\n",
       "      <td>42.45</td>\n",
       "      <td>16.45</td>\n",
       "      <td>20.746</td>\n",
       "      <td>4</td>\n",
       "      <td>3564</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.30316</td>\n",
       "      <td>0.32260</td>\n",
       "      <td>0.39997</td>\n",
       "      <td>0.43564</td>\n",
       "      <td>0.48821</td>\n",
       "      <td>0.52882</td>\n",
       "      <td>0.53207</td>\n",
       "      <td>0.58302</td>\n",
       "      <td>0.22735</td>\n",
       "      <td>0.00072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.87771</td>\n",
       "      <td>0.74346</td>\n",
       "      <td>7.49</td>\n",
       "      <td>55.96</td>\n",
       "      <td>96.60</td>\n",
       "      <td>0.721</td>\n",
       "      <td>1</td>\n",
       "      <td>2993</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.84968</td>\n",
       "      <td>0.80047</td>\n",
       "      <td>0.83504</td>\n",
       "      <td>0.80686</td>\n",
       "      <td>0.83849</td>\n",
       "      <td>0.86902</td>\n",
       "      <td>0.80830</td>\n",
       "      <td>0.88989</td>\n",
       "      <td>0.26912</td>\n",
       "      <td>0.00051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.81451</td>\n",
       "      <td>0.56093</td>\n",
       "      <td>1.45</td>\n",
       "      <td>51.76</td>\n",
       "      <td>79.44</td>\n",
       "      <td>49.984</td>\n",
       "      <td>3</td>\n",
       "      <td>6226</td>\n",
       "      <td>0.127</td>\n",
       "      <td>4.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.47968</td>\n",
       "      <td>0.45684</td>\n",
       "      <td>0.48555</td>\n",
       "      <td>0.50933</td>\n",
       "      <td>0.63299</td>\n",
       "      <td>0.71180</td>\n",
       "      <td>0.65449</td>\n",
       "      <td>0.78567</td>\n",
       "      <td>0.27385</td>\n",
       "      <td>0.01380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.91439</td>\n",
       "      <td>0.60915</td>\n",
       "      <td>9.17</td>\n",
       "      <td>64.44</td>\n",
       "      <td>87.17</td>\n",
       "      <td>11.128</td>\n",
       "      <td>2</td>\n",
       "      <td>5251</td>\n",
       "      <td>0.128</td>\n",
       "      <td>4.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.31475</td>\n",
       "      <td>0.34345</td>\n",
       "      <td>0.35773</td>\n",
       "      <td>0.44913</td>\n",
       "      <td>0.72468</td>\n",
       "      <td>0.78040</td>\n",
       "      <td>0.75561</td>\n",
       "      <td>0.80269</td>\n",
       "      <td>0.34052</td>\n",
       "      <td>0.00156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90172</td>\n",
       "      <td>0.66072</td>\n",
       "      <td>10.77</td>\n",
       "      <td>68.43</td>\n",
       "      <td>122.12</td>\n",
       "      <td>4.445</td>\n",
       "      <td>1</td>\n",
       "      <td>6703</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.71760</td>\n",
       "      <td>0.68823</td>\n",
       "      <td>0.71453</td>\n",
       "      <td>0.72291</td>\n",
       "      <td>0.81518</td>\n",
       "      <td>0.87488</td>\n",
       "      <td>0.82043</td>\n",
       "      <td>0.93069</td>\n",
       "      <td>0.37696</td>\n",
       "      <td>0.04403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.94217</td>\n",
       "      <td>0.81028</td>\n",
       "      <td>10.29</td>\n",
       "      <td>41.28</td>\n",
       "      <td>9.38</td>\n",
       "      <td>22.209</td>\n",
       "      <td>5</td>\n",
       "      <td>3031</td>\n",
       "      <td>0.128</td>\n",
       "      <td>2.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.63913</td>\n",
       "      <td>0.63027</td>\n",
       "      <td>0.67796</td>\n",
       "      <td>0.71480</td>\n",
       "      <td>0.81141</td>\n",
       "      <td>0.86388</td>\n",
       "      <td>0.85365</td>\n",
       "      <td>0.89979</td>\n",
       "      <td>0.65188</td>\n",
       "      <td>0.33643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.89019</td>\n",
       "      <td>0.62145</td>\n",
       "      <td>7.52</td>\n",
       "      <td>48.72</td>\n",
       "      <td>141.93</td>\n",
       "      <td>18.855</td>\n",
       "      <td>4</td>\n",
       "      <td>8434</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.24895</td>\n",
       "      <td>0.24306</td>\n",
       "      <td>0.24877</td>\n",
       "      <td>0.31625</td>\n",
       "      <td>0.51416</td>\n",
       "      <td>0.57959</td>\n",
       "      <td>0.58756</td>\n",
       "      <td>0.64406</td>\n",
       "      <td>0.27037</td>\n",
       "      <td>0.00287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75560</td>\n",
       "      <td>0.52477</td>\n",
       "      <td>13.00</td>\n",
       "      <td>67.88</td>\n",
       "      <td>100.70</td>\n",
       "      <td>0.664</td>\n",
       "      <td>5</td>\n",
       "      <td>2395</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cloud_B02  Cloud_B03  Cloud_B04  Cloud_B05  Cloud_B06  Cloud_B07  \\\n",
       "0    0.57804    0.51792    0.54680    0.56000    0.56824    0.57365   \n",
       "1    0.28975    0.25479    0.29171    0.32868    0.40295    0.44817   \n",
       "2    0.71170    0.68907    0.73376    0.76922    0.81416    0.83261   \n",
       "3    0.30316    0.32260    0.39997    0.43564    0.48821    0.52882   \n",
       "4    0.84968    0.80047    0.83504    0.80686    0.83849    0.86902   \n",
       "5    0.47968    0.45684    0.48555    0.50933    0.63299    0.71180   \n",
       "6    0.31475    0.34345    0.35773    0.44913    0.72468    0.78040   \n",
       "7    0.71760    0.68823    0.71453    0.72291    0.81518    0.87488   \n",
       "8    0.63913    0.63027    0.67796    0.71480    0.81141    0.86388   \n",
       "9    0.24895    0.24306    0.24877    0.31625    0.51416    0.57959   \n",
       "\n",
       "   Cloud_B08  Cloud_B08A  Cloud_B09  Cloud_B10  ...  Clear_B11  Clear_B12  \\\n",
       "0    0.56583     0.57950    0.37962    0.01949  ...    0.04745    0.03758   \n",
       "1    0.45809     0.50999    0.17019    0.00067  ...    0.75602    0.58746   \n",
       "2    0.83383     0.85262    0.63399    0.10050  ...    0.65577    0.52408   \n",
       "3    0.53207     0.58302    0.22735    0.00072  ...    0.87771    0.74346   \n",
       "4    0.80830     0.88989    0.26912    0.00051  ...    0.81451    0.56093   \n",
       "5    0.65449     0.78567    0.27385    0.01380  ...    0.91439    0.60915   \n",
       "6    0.75561     0.80269    0.34052    0.00156  ...    0.90172    0.66072   \n",
       "7    0.82043     0.93069    0.37696    0.04403  ...    0.94217    0.81028   \n",
       "8    0.85365     0.89979    0.65188    0.33643  ...    0.89019    0.62145   \n",
       "9    0.58756     0.64406    0.27037    0.00287  ...    0.75560    0.52477   \n",
       "\n",
       "   Sat_Zenith_Angle  Sun_Zenith_Angle  Azimuth_Diff_Angle     COT  Cloud_Type  \\\n",
       "0              9.00             68.68               48.59  25.181           3   \n",
       "1              1.60             73.05              176.23   1.730           2   \n",
       "2             14.75             42.45               16.45  20.746           4   \n",
       "3              7.49             55.96               96.60   0.721           1   \n",
       "4              1.45             51.76               79.44  49.984           3   \n",
       "5              9.17             64.44               87.17  11.128           2   \n",
       "6             10.77             68.43              122.12   4.445           1   \n",
       "7             10.29             41.28                9.38  22.209           5   \n",
       "8              7.52             48.72              141.93  18.855           4   \n",
       "9             13.00             67.88              100.70   0.664           5   \n",
       "\n",
       "   Profile_ID    GOT  Water_Vapor  \n",
       "0        9543  0.122         0.56  \n",
       "1        3672  0.116         0.77  \n",
       "2        3564  0.124         0.23  \n",
       "3        2993  0.122         0.83  \n",
       "4        6226  0.127         4.57  \n",
       "5        5251  0.128         4.42  \n",
       "6        6703  0.080         0.71  \n",
       "7        3031  0.128         2.78  \n",
       "8        8434  0.101         0.58  \n",
       "9        2395  0.124         0.57  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data and inspect\n",
    "df = synth_dataloader('SMHIdata2_newsurf')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose if to save models and data, if so set paths\n",
    "save_load=True\n",
    "if save_load:\n",
    "    test_name_1 = \"COT_est_inp_noCOT\"\n",
    "    main_filepath_1 = 'pytorch_models/'+test_name_1\n",
    "    test_name_2 = \"COT_est_inp_wCOT\"\n",
    "    main_filepath_2 = 'pytorch_models/'+test_name_2\n",
    "    test_name_3 = \"COT_est_inp_wCOT_dum\"\n",
    "    main_filepath_3 = 'pytorch_models/'+test_name_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 1: Exclude COT estimation in input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set columns for X and y (input/output features)\n",
    "X_cols = ['Cloud_B02','Cloud_B03','Cloud_B04','Cloud_B05','Cloud_B06',\n",
    "          'Cloud_B07','Cloud_B08','Cloud_B08A','Cloud_B09','Cloud_B10','Cloud_B11','Cloud_B12','Sun_Zenith_Angle']\n",
    "y_cols = ['Clear_B02','Clear_B03','Clear_B04','Clear_B05','Clear_B06',\n",
    "          'Clear_B07','Clear_B08','Clear_B08A','Clear_B09','Clear_B10','Clear_B11','Clear_B12']\n",
    "\n",
    "#Find X and y\n",
    "X=df[X_cols]\n",
    "y=df[y_cols]\n",
    "\n",
    "#Separate testdata from rest for 80/10/10 Train/Val/Test split\n",
    "X_trainval, X_test, y_trainval, y_test=train_test_split(X,y,test_size=0.1,random_state=313)\n",
    "\n",
    "#Find clear indices in trainval\n",
    "clear_indices = np.array([])\n",
    "for i,df_idx in enumerate(X_trainval.index):\n",
    "    if df['Cloud_Type'][df_idx]==0:\n",
    "        clear_indices=np.append(clear_indices,i)\n",
    "\n",
    "#Add noise to X_test, 0 mean with stdev equal to 3% of mean of each feature\n",
    "np.random.seed(313)\n",
    "X_test = X_test + np.random.randn(np.shape(X_test)[0],np.shape(X_test)[1]) * np.mean(X.to_numpy(),axis=0)*0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up which quantiles to estimate, and find index of estimator (q=0.5)\n",
    "quantiles=np.array([0.1,0.5,0.9])\n",
    "est= np.where(quantiles==0.5)[0].item()\n",
    "\n",
    "#Set up algorithm parameters for both cases\n",
    "val_size=0.1\n",
    "num_models=5 #Set number of models in ensemble\n",
    "batch_size=500\n",
    "nepochs=1000\n",
    "lr=0.002\n",
    "noise_ratio = 0.03\n",
    "early_break=True\n",
    "no_nodes = 200\n",
    "clear_noise = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 290.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.384772] Validation loss [2.3535624]\n",
      "Epoch 212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 290.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.3854601] Validation loss [2.353019]\n",
      "Epoch 213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number:  25%|██▍       | 79/320 [00:00<00:00, 290.77it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m train_indices\u001b[38;5;241m=\u001b[39m[i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_trainval[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCloud_B02\u001b[39m\u001b[38;5;124m'\u001b[39m])) \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(validation_indices\u001b[38;5;241m==\u001b[39mi)\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m]  \n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m#Fit model\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_trainval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_trainval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43msequence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnoise_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnoise_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_break\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_break\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclear_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclear_noise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclear_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclear_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#Save models if wanted\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save:\n",
      "File \u001b[0;32m~/Anton/SEEX30_Cloud_Fog/multivariate_quantile_regression/network_model.py:72\u001b[0m, in \u001b[0;36mQuantileNetwork.fit\u001b[0;34m(self, X, y, train_indices, validation_indices, sequence, batch_size, nepochs, lr, noise_ratio, early_break, clear_noise, clear_indices)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, train_indices, validation_indices, sequence, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, nepochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,noise_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.03\u001b[39m,early_break\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,clear_noise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,clear_indices\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([])):\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loss,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_loss \u001b[38;5;241m=\u001b[39m \u001b[43mfit_quantiles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[43mquantiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[43msequence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnoise_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnoise_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[43mearly_break\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_break\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclear_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclear_noise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[43mclear_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclear_indices\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Anton/SEEX30_Cloud_Fog/multivariate_quantile_regression/network_model.py:249\u001b[0m, in \u001b[0;36mfit_quantiles\u001b[0;34m(X, y, train_indices, validation_indices, quantiles, n_epochs, batch_size, sequence, lr, noise_ratio, early_break, clear_noise, clear_indices, loss, file_checkpoints, device)\u001b[0m\n\u001b[1;32m    246\u001b[0m yhat \u001b[38;5;241m=\u001b[39m model(tX_noisy[idx]) \u001b[38;5;66;03m#Run algorithm\u001b[39;00m\n\u001b[1;32m    248\u001b[0m loss\u001b[38;5;241m=\u001b[39mlossfn(yhat,idx)\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;66;03m#Run loss function\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#Calculate gradient\u001b[39;00m\n\u001b[1;32m    251\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    253\u001b[0m train_loss\u001b[38;5;241m=\u001b[39mtrain_loss\u001b[38;5;241m+\u001b[39mloss\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;66;03m#Increment loss\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:513\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradient of current tensor wrt graph leaves.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \n\u001b[1;32m    468\u001b[0m \u001b[38;5;124;03mThe graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;124;03m        used to compute the attr::tensors.\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    524\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/overrides.py:1604\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_function_mode_enabled():\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;66;03m# if we're here, the mode must be set to a TorchFunctionStackMode\u001b[39;00m\n\u001b[1;32m   1602\u001b[0m     \u001b[38;5;66;03m# this unsets it and calls directly into TorchFunctionStackMode's torch function\u001b[39;00m\n\u001b[1;32m   1603\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _pop_mode_temporarily() \u001b[38;5;28;01mas\u001b[39;00m mode:\n\u001b[0;32m-> 1604\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mmode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1605\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1606\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_device.py:77\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Set up NW\n",
    "sequence= lambda: nn.Sequential(\n",
    "    nn.Linear(len(X_cols),no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(no_nodes),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(no_nodes),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(no_nodes),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(no_nodes),\n",
    "    nn.Linear(no_nodes, len(quantiles)*len(y_cols)) #Output dimesion is number of quantiles times number of target variables\n",
    ")\n",
    "\n",
    "#Initalize models\n",
    "models = [QuantileNetwork(quantiles=quantiles) for _ in range(num_models)]\n",
    "\n",
    "#Train models\n",
    "for i,model in enumerate(models):\n",
    "    #Find new train/val splits for each model for robustness\n",
    "    validation_indices=np.array(random.sample(range(len(X_trainval['Cloud_B02'])), int(len(X['Cloud_B02'])*val_size)))\n",
    "    train_indices=[i for i in range(len(X_trainval['Cloud_B02'])) if np.any(validation_indices==i)==False]  \n",
    "    #Fit model\n",
    "    model.fit(X_trainval.to_numpy(),y_trainval.to_numpy(), \n",
    "            train_indices=train_indices, \n",
    "            validation_indices=validation_indices, \n",
    "            batch_size=batch_size,\n",
    "            nepochs=nepochs,\n",
    "            sequence=sequence(),\n",
    "            lr=lr,\n",
    "            noise_ratio=noise_ratio,\n",
    "            early_break=early_break,\n",
    "            clear_noise=clear_noise,\n",
    "            clear_indices=clear_indices)\n",
    "    \n",
    "    #Save models if wanted\n",
    "    if save_load:\n",
    "        filepath=main_filepath_1+'/model'+str(i)\n",
    "        os.makedirs(filepath,exist_ok=True)\n",
    "        torch.save(model,filepath+'/model_file')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_54381/3055426930.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  noCOT_model_metrics=pd.concat([noCOT_model_metrics,tmp_metrics])\n"
     ]
    }
   ],
   "source": [
    "#Load models\n",
    "if save_load:\n",
    "    base_path = main_filepath_1 + '/'\n",
    "    model_paths = ['model0/model_file','model1/model_file','model2/model_file','model3/model_file','model4/model_file']\n",
    "    models = [torch.load(base_path+model_paths[i]) for i in range(len(model_paths))]\n",
    "\n",
    "#Manually set quantiles\n",
    "quantiles = np.array([0.1,0.5,0.9])\n",
    "est = np.where(quantiles==0.5)[0].item()\n",
    "\n",
    "#Initialize dataframe for error metrics and array for ensemble predictions\n",
    "noCOT_model_metrics=pd.DataFrame(columns=['Ensemble_mean','Ensemble_index','MSE','PSNR','R2_score','Mean_Quantile_Loss'])\n",
    "preds_total=[]\n",
    "#Make predictions and evaluate\n",
    "for i,model in enumerate(models):\n",
    "    preds = model.predict(X_test.to_numpy())\n",
    "    #Keep track of ensemble prediction\n",
    "    if i==0:\n",
    "        preds_total=preds\n",
    "    else:\n",
    "        preds_total=preds_total+preds\n",
    "\n",
    "    #Find errors\n",
    "    mse=mean_squared_error(y_test.to_numpy(),preds[:,:,est])\n",
    "    psnr=QuantileNetwork.PSNR(y_test.to_numpy(),preds[:,:,est])\n",
    "    r2=r2_score(y_test.to_numpy(),preds[:,:,est])\n",
    "    mean_quantile=QuantileNetwork.mean_marginal_loss(y_test.to_numpy(),preds,quantiles)\n",
    "    #Add to dataframe\n",
    "    tmp_metrics=pd.DataFrame(data=[[False,i,mse,psnr,r2,mean_quantile]],columns=['Ensemble_mean','Ensemble_index','MSE','PSNR','R2_score','Mean_Quantile_Loss'])\n",
    "    noCOT_model_metrics=pd.concat([noCOT_model_metrics,tmp_metrics])\n",
    "\n",
    "\n",
    "#Now do the same for ensemble predictions\n",
    "preds_total=preds_total/len(models)\n",
    "\n",
    "mse=mean_squared_error(y_test.to_numpy(),preds_total[:,:,est])\n",
    "psnr=QuantileNetwork.PSNR(y_test.to_numpy(),preds_total[:,:,est])\n",
    "r2=r2_score(y_test.to_numpy(),preds_total[:,:,est])\n",
    "mean_quantile=QuantileNetwork.mean_marginal_loss(y_test.to_numpy(),preds_total,quantiles)\n",
    "\n",
    "tmp_metrics=pd.DataFrame(data=[[True,np.nan,mse,psnr,r2,mean_quantile]],columns=['Ensemble_mean','Ensemble_index','MSE','PSNR','R2_score','Mean_Quantile_Loss'])\n",
    "noCOT_model_metrics=pd.concat([noCOT_model_metrics,tmp_metrics])\n",
    "\n",
    "#Save metrics if we want to\n",
    "if save_load:\n",
    "    noCOT_model_metrics=noCOT_model_metrics.reset_index(drop=True)\n",
    "    noCOT_model_metrics.to_csv(main_filepath_1+'/model_metrics.csv',index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 2: Use Aleksis COT estimation as input to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up paths for importing COT est models\n",
    "COT_model_paths = ['smhi_models4/0/model_it_2000000','smhi_models4/1/model_it_2000000','smhi_models4/2/model_it_2000000','smhi_models4/3/model_it_2000000','smhi_models4/4/model_it_2000000']\n",
    "\n",
    "#Initialize and load COT estimation models\n",
    "COT_est_models = [MLP5(13, 1, apply_relu=True) for _ in range(len(COT_model_paths))]\n",
    "for i,model in enumerate(COT_est_models):\n",
    "    model.load_state_dict(torch.load(COT_model_paths[i],map_location=device))\n",
    "\n",
    "#Create X for COT estimation (no angles)\n",
    "X_COTest = X.to_numpy()\n",
    "#Add noise for fairness\n",
    "X_COTest = X_COTest + np.random.randn(np.shape(X_COTest)[0],np.shape(X_COTest)[1]) * np.mean(X_COTest,axis=0)*0.03\n",
    "#Normalize and turn into tensor before input\n",
    "X_COTest_mu = np.mean(X_COTest,axis=0)\n",
    "X_COTest_std = np.std(X_COTest,axis=0)\n",
    "X_COTest_norm = (X_COTest-X_COTest_mu)/X_COTest_std\n",
    "tX_COTest_norm = torch.Tensor(X_COTest_norm).to(device)\n",
    "#Make predictions (*50 to denormalize predictions)\n",
    "COT_preds_total = []\n",
    "for i,model in enumerate(COT_est_models):\n",
    "    COT_preds = 50*model(tX_COTest_norm).cpu().detach().numpy()\n",
    "    #Keep track of ensemble prediction\n",
    "    if i==0:\n",
    "        COT_preds_total=COT_preds\n",
    "    else:\n",
    "        COT_preds_total=COT_preds_total+COT_preds\n",
    "\n",
    "COT_preds_total = COT_preds_total/len(COT_est_models)\n",
    "\n",
    "#Now separate into trainval and test\n",
    "COT_preds_total_trainval = COT_preds_total[X_trainval.index,0]\n",
    "COT_preds_total_test = COT_preds_total[X_test.index,0]\n",
    "\n",
    "#Create new X's including COT estimation\n",
    "X_trainval_COT = X_trainval.assign(COT_est=COT_preds_total_trainval)\n",
    "X_test_COT = X_test.assign(COT_est=COT_preds_total_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 235.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.307456] Validation loss [2.327637]\n",
      "Epoch 412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 229.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.314747] Validation loss [2.3378232]\n",
      "Epoch 413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 230.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.3119643] Validation loss [2.3336778]\n",
      "Epoch 414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 230.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.311233] Validation loss [2.3219352]\n",
      "Epoch 415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 227.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.3080847] Validation loss [2.3284247]\n",
      "Epoch 416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 249.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.3099892] Validation loss [2.334413]\n",
      "Epoch 417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 296.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.3096678] Validation loss [2.3180304]\n",
      "Epoch 418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 265.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.311021] Validation loss [2.3337336]\n",
      "Epoch 419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 294.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.3158839] Validation loss [2.3389077]\n",
      "Epoch 420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 241.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.3130164] Validation loss [2.331449]\n",
      "---No improvement in 100 epochs, broke early---\n",
      "Best model out of total max epochs found at epoch 320\n",
      "With validation loss: 2.3136236667633057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Create new net with 1 additional input\n",
    "sequence= lambda: nn.Sequential(\n",
    "    nn.Linear(len(X_cols)+1,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(no_nodes),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(no_nodes),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(no_nodes),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(no_nodes),\n",
    "    nn.Linear(no_nodes, len(quantiles)*len(y_cols)) #Output dimesion is number of quantiles times number of target variables\n",
    ")\n",
    "\n",
    "#Initalize models\n",
    "models = [QuantileNetwork(quantiles=quantiles) for _ in range(num_models)]\n",
    "\n",
    "#Train models\n",
    "for i,model in enumerate(models):\n",
    "    #Find new train/val splits for each model for robustness\n",
    "    validation_indices=np.array(random.sample(range(len(X_trainval['Cloud_B02'])), int(len(X['Cloud_B02'])*val_size)))\n",
    "    train_indices=[i for i in range(len(X_trainval['Cloud_B02'])) if np.any(validation_indices==i)==False]  \n",
    "    #Fit model with X including COT_est\n",
    "    model.fit(X_trainval_COT.to_numpy(),y_trainval.to_numpy(), \n",
    "            train_indices=train_indices, \n",
    "            validation_indices=validation_indices, \n",
    "            batch_size=batch_size,\n",
    "            nepochs=nepochs,\n",
    "            sequence=sequence(),\n",
    "            lr=lr,\n",
    "            noise_ratio=noise_ratio,\n",
    "            early_break=early_break,\n",
    "            clear_noise=clear_noise,\n",
    "            clear_indices=clear_indices)\n",
    "    \n",
    "    #Save models if wanted\n",
    "    if save_load:\n",
    "        filepath=main_filepath_2+'/model'+str(i)\n",
    "        os.makedirs(filepath,exist_ok=True)\n",
    "        torch.save(model,filepath+'/model_file')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_54381/2832525742.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  wCOT_model_metrics=pd.concat([wCOT_model_metrics,tmp_metrics])\n"
     ]
    }
   ],
   "source": [
    "#Load models\n",
    "if save_load:\n",
    "    base_path = main_filepath_2 + '/'\n",
    "    model_paths = ['model0/model_file','model1/model_file','model2/model_file','model3/model_file','model4/model_file']\n",
    "    models = [torch.load(base_path+model_paths[i]) for i in range(len(model_paths))]\n",
    "\n",
    "#Manually set quantiles\n",
    "quantiles = np.array([0.1,0.5,0.9])\n",
    "est = np.where(quantiles==0.5)[0].item()\n",
    "\n",
    "#Initialize dataframe for error metrics and array for ensemble predictions\n",
    "wCOT_model_metrics=pd.DataFrame(columns=['Ensemble_mean','Ensemble_index','MSE','PSNR','R2_score','Mean_Quantile_Loss'])\n",
    "preds_total=[]\n",
    "#Make predictions and evaluate\n",
    "for i,model in enumerate(models):\n",
    "    preds = model.predict(X_test_COT.to_numpy())\n",
    "    #Keep track of ensemble prediction\n",
    "    if i==0:\n",
    "        preds_total=preds\n",
    "    else:\n",
    "        preds_total=preds_total+preds\n",
    "\n",
    "    #Find errors\n",
    "    mse=mean_squared_error(y_test.to_numpy(),preds[:,:,est])\n",
    "    psnr=QuantileNetwork.PSNR(y_test.to_numpy(),preds[:,:,est])\n",
    "    r2=r2_score(y_test.to_numpy(),preds[:,:,est])\n",
    "    mean_quantile=QuantileNetwork.mean_marginal_loss(y_test.to_numpy(),preds,quantiles)\n",
    "    #Add to dataframe\n",
    "    tmp_metrics=pd.DataFrame(data=[[False,i,mse,psnr,r2,mean_quantile]],columns=['Ensemble_mean','Ensemble_index','MSE','PSNR','R2_score','Mean_Quantile_Loss'])\n",
    "    wCOT_model_metrics=pd.concat([wCOT_model_metrics,tmp_metrics])\n",
    "\n",
    "\n",
    "#Now do the same for ensemble predictions\n",
    "preds_total=preds_total/num_models\n",
    "\n",
    "mse=mean_squared_error(y_test.to_numpy(),preds_total[:,:,est])\n",
    "psnr=QuantileNetwork.PSNR(y_test.to_numpy(),preds_total[:,:,est])\n",
    "r2=r2_score(y_test.to_numpy(),preds_total[:,:,est])\n",
    "mean_quantile=QuantileNetwork.mean_marginal_loss(y_test.to_numpy(),preds_total,quantiles)\n",
    "\n",
    "tmp_metrics=pd.DataFrame(data=[[True,np.nan,mse,psnr,r2,mean_quantile]],columns=['Ensemble_mean','Ensemble_index','MSE','PSNR','R2_score','Mean_Quantile_Loss'])\n",
    "wCOT_model_metrics=pd.concat([wCOT_model_metrics,tmp_metrics])\n",
    "\n",
    "#Save metrics if we want to\n",
    "if save_load:\n",
    "    wCOT_model_metrics=wCOT_model_metrics.reset_index(drop=True)\n",
    "    wCOT_model_metrics.to_csv(main_filepath_2+'/model_metrics.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 3: Categorical dummy COT estimation as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort into categories instead\n",
    "t_is_cloud = 0.025*50 #From Pirinen et. al.\n",
    "t_thin_cloud = 0.015*50 #From Pirinen et. al.\n",
    "\n",
    "pred_clear = np.zeros(COT_preds_total.shape)\n",
    "pred_thin = np.zeros(COT_preds_total.shape)\n",
    "pred_thick = np.zeros(COT_preds_total.shape)\n",
    "\n",
    "pred_clear[COT_preds_total<t_thin_cloud]=1\n",
    "pred_thin[(COT_preds_total>=t_thin_cloud)&(COT_preds_total<t_is_cloud)]=1\n",
    "pred_thick[COT_preds_total>=t_is_cloud]=1\n",
    "\n",
    "#Create new Xs including COT dummies\n",
    "X = X.assign(Clear=pred_clear[:,0])\n",
    "X = X.assign(Thin=pred_thin[:,0])\n",
    "X = X.assign(Thick=pred_thick[:,0])\n",
    "\n",
    "#Now separate into trainval and test\n",
    "Clear_trainval = pred_clear[X_trainval.index,0]\n",
    "Clear_test = pred_clear[X_test.index,0]\n",
    "Thin_trainval = pred_thin[X_trainval.index,0]\n",
    "Thin_test = pred_thin[X_test.index,0]\n",
    "Thick_trainval = pred_thick[X_trainval.index,0]\n",
    "Thick_test = pred_thick[X_test.index,0]\n",
    "\n",
    "#Create new X's including dummy COT estimation\n",
    "X_trainval_COT_dum = X_trainval.assign(Clear = Clear_trainval)\n",
    "X_test_COT_dum = X_test.assign(Clear=Clear_test)\n",
    "X_trainval_COT_dum = X_trainval_COT_dum.assign(Thin = Thin_trainval)\n",
    "X_test_COT_dum = X_test_COT_dum.assign(Thin=Thin_test)\n",
    "X_trainval_COT_dum = X_trainval_COT_dum.assign(Thick = Thick_trainval)\n",
    "X_test_COT_dum = X_test_COT_dum.assign(Thick=Thick_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 307.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.3532262] Validation loss [2.3257678]\n",
      "Epoch 332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 307.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.3577774] Validation loss [2.327489]\n",
      "Epoch 333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 307.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.3571541] Validation loss [2.32969]\n",
      "Epoch 334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 303.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.355802] Validation loss [2.3191006]\n",
      "Epoch 335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 307.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.3577526] Validation loss [2.3403833]\n",
      "Epoch 336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 306.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.3667178] Validation loss [2.3377368]\n",
      "Epoch 337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 306.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.354515] Validation loss [2.3294616]\n",
      "Epoch 338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 304.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.3624234] Validation loss [2.3278055]\n",
      "Epoch 339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 304.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.357945] Validation loss [2.3207965]\n",
      "Epoch 340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 305.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.3548305] Validation loss [2.3521652]\n",
      "---No improvement in 100 epochs, broke early---\n",
      "Best model out of total max epochs found at epoch 240\n",
      "With validation loss: 2.3106424808502197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Create new net with 1 additional input\n",
    "sequence= lambda: nn.Sequential(\n",
    "    nn.Linear(len(X_cols)+3,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(no_nodes),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(no_nodes),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(no_nodes),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(no_nodes),\n",
    "    nn.Linear(no_nodes, len(quantiles)*len(y_cols)) #Output dimesion is number of quantiles times number of target variables\n",
    ")\n",
    "\n",
    "#Initalize models\n",
    "models = [QuantileNetwork(quantiles=quantiles) for _ in range(num_models)]\n",
    "\n",
    "#Train models\n",
    "for i,model in enumerate(models):\n",
    "    #Find new train/val splits for each model for robustness\n",
    "    validation_indices=np.array(random.sample(range(len(X_trainval['Cloud_B02'])), int(len(X['Cloud_B02'])*val_size)))\n",
    "    train_indices=[i for i in range(len(X_trainval['Cloud_B02'])) if np.any(validation_indices==i)==False]  \n",
    "    #Fit model with X including COT_est\n",
    "    model.fit(X_trainval_COT_dum.to_numpy(),y_trainval.to_numpy(), \n",
    "            train_indices=train_indices, \n",
    "            validation_indices=validation_indices, \n",
    "            batch_size=batch_size,\n",
    "            nepochs=nepochs,\n",
    "            sequence=sequence(),\n",
    "            lr=lr,\n",
    "            noise_ratio=noise_ratio,\n",
    "            early_break=early_break,\n",
    "            clear_noise=clear_noise,\n",
    "            clear_indices=clear_indices)\n",
    "    \n",
    "    #Save models if wanted\n",
    "    if save_load:\n",
    "        filepath=main_filepath_3+'/model'+str(i)\n",
    "        os.makedirs(filepath,exist_ok=True)\n",
    "        torch.save(model,filepath+'/model_file')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_54381/3078255963.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  wCOT_dum_model_metrics=pd.concat([wCOT_dum_model_metrics,tmp_metrics])\n"
     ]
    }
   ],
   "source": [
    "#Load models\n",
    "if save_load:\n",
    "    base_path = main_filepath_3 + '/'\n",
    "    model_paths = ['model0/model_file','model1/model_file','model2/model_file','model3/model_file','model4/model_file']\n",
    "    models = [torch.load(base_path+model_paths[i]) for i in range(len(model_paths))]\n",
    "\n",
    "#Manually set quantiles\n",
    "quantiles = np.array([0.1,0.5,0.9])\n",
    "est = np.where(quantiles==0.5)[0].item()\n",
    "\n",
    "#Initialize dataframe for error metrics and array for ensemble predictions\n",
    "wCOT_dum_model_metrics=pd.DataFrame(columns=['Ensemble_mean','Ensemble_index','MSE','PSNR','R2_score','Mean_Quantile_Loss'])\n",
    "preds_total=[]\n",
    "#Make predictions and evaluate\n",
    "for i,model in enumerate(models):\n",
    "    preds = model.predict(X_test_COT_dum.to_numpy())\n",
    "    #Keep track of ensemble prediction\n",
    "    if i==0:\n",
    "        preds_total=preds\n",
    "    else:\n",
    "        preds_total=preds_total+preds\n",
    "\n",
    "    #Find errors\n",
    "    mse=mean_squared_error(y_test.to_numpy(),preds[:,:,est])\n",
    "    psnr=QuantileNetwork.PSNR(y_test.to_numpy(),preds[:,:,est])\n",
    "    r2=r2_score(y_test.to_numpy(),preds[:,:,est])\n",
    "    mean_quantile=QuantileNetwork.mean_marginal_loss(y_test.to_numpy(),preds,quantiles)\n",
    "    #Add to dataframe\n",
    "    tmp_metrics=pd.DataFrame(data=[[False,i,mse,psnr,r2,mean_quantile]],columns=['Ensemble_mean','Ensemble_index','MSE','PSNR','R2_score','Mean_Quantile_Loss'])\n",
    "    wCOT_dum_model_metrics=pd.concat([wCOT_dum_model_metrics,tmp_metrics])\n",
    "\n",
    "\n",
    "#Now do the same for ensemble predictions\n",
    "preds_total=preds_total/len(models)\n",
    "\n",
    "mse=mean_squared_error(y_test.to_numpy(),preds_total[:,:,est])\n",
    "psnr=QuantileNetwork.PSNR(y_test.to_numpy(),preds_total[:,:,est])\n",
    "r2=r2_score(y_test.to_numpy(),preds_total[:,:,est])\n",
    "mean_quantile=QuantileNetwork.mean_marginal_loss(y_test.to_numpy(),preds_total,quantiles)\n",
    "\n",
    "tmp_metrics=pd.DataFrame(data=[[True,np.nan,mse,psnr,r2,mean_quantile]],columns=['Ensemble_mean','Ensemble_index','MSE','PSNR','R2_score','Mean_Quantile_Loss'])\n",
    "wCOT_dum_model_metrics=pd.concat([wCOT_dum_model_metrics,tmp_metrics])\n",
    "\n",
    "#Save metrics if we want to\n",
    "if save_load:\n",
    "    wCOT_dum_model_metrics=wCOT_dum_model_metrics.reset_index(drop=True)\n",
    "    wCOT_dum_model_metrics.to_csv(main_filepath_3+'/model_metrics.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ensemble_mean</th>\n",
       "      <th>Ensemble_index</th>\n",
       "      <th>MSE</th>\n",
       "      <th>PSNR</th>\n",
       "      <th>R2_score</th>\n",
       "      <th>Mean_Quantile_Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004911</td>\n",
       "      <td>23.109470</td>\n",
       "      <td>0.838393</td>\n",
       "      <td>0.439172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004969</td>\n",
       "      <td>23.058931</td>\n",
       "      <td>0.836799</td>\n",
       "      <td>0.440598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.004920</td>\n",
       "      <td>23.101861</td>\n",
       "      <td>0.837970</td>\n",
       "      <td>0.439957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>23.075642</td>\n",
       "      <td>0.837860</td>\n",
       "      <td>0.439557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.004917</td>\n",
       "      <td>23.104641</td>\n",
       "      <td>0.838708</td>\n",
       "      <td>0.440252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004811</td>\n",
       "      <td>23.199307</td>\n",
       "      <td>0.842014</td>\n",
       "      <td>0.432190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ensemble_mean  Ensemble_index       MSE       PSNR  R2_score  \\\n",
       "0          False             0.0  0.004911  23.109470  0.838393   \n",
       "1          False             1.0  0.004969  23.058931  0.836799   \n",
       "2          False             2.0  0.004920  23.101861  0.837970   \n",
       "3          False             3.0  0.004950  23.075642  0.837860   \n",
       "4          False             4.0  0.004917  23.104641  0.838708   \n",
       "5           True             NaN  0.004811  23.199307  0.842014   \n",
       "\n",
       "   Mean_Quantile_Loss  \n",
       "0            0.439172  \n",
       "1            0.440598  \n",
       "2            0.439957  \n",
       "3            0.439557  \n",
       "4            0.440252  \n",
       "5            0.432190  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display noCOT results\n",
    "if save_load:\n",
    "    file_name = main_filepath_1 + '/model_metrics.csv'\n",
    "    noCOT_model_metrics=pd.read_csv(file_name)\n",
    "\n",
    "noCOT_model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ensemble_mean</th>\n",
       "      <th>Ensemble_index</th>\n",
       "      <th>MSE</th>\n",
       "      <th>PSNR</th>\n",
       "      <th>R2_score</th>\n",
       "      <th>Mean_Quantile_Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004825</td>\n",
       "      <td>23.186874</td>\n",
       "      <td>0.841511</td>\n",
       "      <td>0.433850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>23.141267</td>\n",
       "      <td>0.840358</td>\n",
       "      <td>0.435206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.004814</td>\n",
       "      <td>23.195924</td>\n",
       "      <td>0.842387</td>\n",
       "      <td>0.433273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.004863</td>\n",
       "      <td>23.152805</td>\n",
       "      <td>0.840461</td>\n",
       "      <td>0.435163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.004870</td>\n",
       "      <td>23.145673</td>\n",
       "      <td>0.840672</td>\n",
       "      <td>0.434619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004708</td>\n",
       "      <td>23.292763</td>\n",
       "      <td>0.845737</td>\n",
       "      <td>0.425872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ensemble_mean  Ensemble_index       MSE       PSNR  R2_score  \\\n",
       "0          False             0.0  0.004825  23.186874  0.841511   \n",
       "1          False             1.0  0.004875  23.141267  0.840358   \n",
       "2          False             2.0  0.004814  23.195924  0.842387   \n",
       "3          False             3.0  0.004863  23.152805  0.840461   \n",
       "4          False             4.0  0.004870  23.145673  0.840672   \n",
       "5           True             NaN  0.004708  23.292763  0.845737   \n",
       "\n",
       "   Mean_Quantile_Loss  \n",
       "0            0.433850  \n",
       "1            0.435206  \n",
       "2            0.433273  \n",
       "3            0.435163  \n",
       "4            0.434619  \n",
       "5            0.425872  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display wCOT results\n",
    "if save_load:\n",
    "    file_name = main_filepath_2 + '/model_metrics.csv'\n",
    "    wCOT_model_metrics=pd.read_csv(file_name)\n",
    "\n",
    "wCOT_model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ensemble_mean</th>\n",
       "      <th>Ensemble_index</th>\n",
       "      <th>MSE</th>\n",
       "      <th>PSNR</th>\n",
       "      <th>R2_score</th>\n",
       "      <th>Mean_Quantile_Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>23.053160</td>\n",
       "      <td>0.836234</td>\n",
       "      <td>0.439600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004999</td>\n",
       "      <td>23.032947</td>\n",
       "      <td>0.836235</td>\n",
       "      <td>0.440334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.004942</td>\n",
       "      <td>23.082708</td>\n",
       "      <td>0.838040</td>\n",
       "      <td>0.438292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.004932</td>\n",
       "      <td>23.090970</td>\n",
       "      <td>0.837855</td>\n",
       "      <td>0.437804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.004850</td>\n",
       "      <td>23.163883</td>\n",
       "      <td>0.840682</td>\n",
       "      <td>0.435777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004798</td>\n",
       "      <td>23.211023</td>\n",
       "      <td>0.842523</td>\n",
       "      <td>0.430116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ensemble_mean  Ensemble_index       MSE       PSNR  R2_score  \\\n",
       "0          False             0.0  0.004975  23.053160  0.836234   \n",
       "1          False             1.0  0.004999  23.032947  0.836235   \n",
       "2          False             2.0  0.004942  23.082708  0.838040   \n",
       "3          False             3.0  0.004932  23.090970  0.837855   \n",
       "4          False             4.0  0.004850  23.163883  0.840682   \n",
       "5           True             NaN  0.004798  23.211023  0.842523   \n",
       "\n",
       "   Mean_Quantile_Loss  \n",
       "0            0.439600  \n",
       "1            0.440334  \n",
       "2            0.438292  \n",
       "3            0.437804  \n",
       "4            0.435777  \n",
       "5            0.430116  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display wCOT dum results\n",
    "if save_load:\n",
    "    file_name = main_filepath_3 + '/model_metrics.csv'\n",
    "    wCOT_dum_model_metrics=pd.read_csv(file_name)\n",
    "\n",
    "wCOT_dum_model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23796/4037808937.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "2024-03-18 13:22:51.882024: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-18 13:22:51.916388: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-18 13:22:51.916413: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-18 13:22:51.917241: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-18 13:22:51.924111: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-18 13:22:52.657180: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import sys\n",
    "import random\n",
    "import os\n",
    "\n",
    "from IPython import display\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from functions.parse_data import synth_dataloader\n",
    "from multivariate_quantile_regression.network_model import QuantileNetwork\n",
    "\n",
    "from cot_train.utils import MLP5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n",
      "Tensor is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    # CUDA is available, so let's set default device to GPU\n",
    "    torch.set_default_device(0)\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "else:\n",
    "    # CUDA is not available, so let's use the CPU\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "# Example usage and check:\n",
    "tensor = torch.randn(3, 3)  # Create a tensor on the selected device\n",
    "print(\"Tensor is on device:\", tensor.device)\n",
    "device = tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all data\n",
    "df=synth_dataloader(path_name='SMHIdata',drop_cols=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load training, val and test data for indices\n",
    "traindata = pd.read_csv('cot_train/data/synthetic-cot-data/train_df.csv', index_col=[0])\n",
    "valdata = pd.read_csv('cot_train/data/synthetic-cot-data/val_df.csv', index_col=[0])\n",
    "testdata = pd.read_csv('cot_train/data/synthetic-cot-data/test_df.csv', index_col=[0])\n",
    "\n",
    "#Find indices for each\n",
    "trainidx = traindata['index'].to_numpy()\n",
    "validx = valdata['index'].to_numpy()\n",
    "testidx = testdata['index'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find X and y\n",
    "X_cols = ['Cloud_B02','Cloud_B03','Cloud_B04','Cloud_B05','Cloud_B06',\n",
    "          'Cloud_B07','Cloud_B08','Cloud_B08A','Cloud_B09','Cloud_B10','Cloud_B11','Cloud_B12']\n",
    "y_cols = ['Clear_B02','Clear_B03','Clear_B04','Clear_B05','Clear_B06',\n",
    "          'Clear_B07','Clear_B08','Clear_B08A','Clear_B09','Clear_B10','Clear_B11','Clear_B12']\n",
    "\n",
    "X=df[X_cols].to_numpy()\n",
    "y=df[y_cols].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for our alg:\n",
      "MAE = 2.080872156246265\n",
      "RMSE = 4.303570789316039\n",
      "L1 loss = 2.080872058868408\n",
      "Stats for Aleksis alg:\n",
      "MAE = 2.3033979227756647\n",
      "RMSE = 4.2616078193695675\n",
      "L1 loss = 2.3033976554870605\n"
     ]
    }
   ],
   "source": [
    "#load pretrained COT-prediction models\n",
    "model0 = MLP5(12, 1, apply_relu=True)\n",
    "model0.load_state_dict(torch.load('cot_train/log/2024-03-14_09-24-00/model_it_2000000', map_location=device))\n",
    "#model0.to(device)\n",
    "#model0.eval()\n",
    "\n",
    "COT_model0 = torch.load('pytorch_models/Loop_learning_rate/0.003/model0/model_file')\n",
    "COT_model1 = torch.load('pytorch_models/Loop_learning_rate/0.003/model1/model_file')\n",
    "COT_model2 = torch.load('pytorch_models/Loop_learning_rate/0.003/model2/model_file')\n",
    "COT_model3 = torch.load('pytorch_models/Loop_learning_rate/0.003/model3/model_file')\n",
    "COT_model4 = torch.load('pytorch_models/Loop_learning_rate/0.003/model4/model_file')\n",
    "\n",
    "#Find real COT values\n",
    "trueCOT = df['COT'].to_numpy()\n",
    "\n",
    "#Add noise to X and predict COT_pred w/ each model and take mean\n",
    "X_noisy = X + np.random.randn(np.shape(X)[0],np.shape(X)[1]) * np.mean(X,axis=0)*0.03\n",
    "X_train_mu = np.mean(X,axis=0)\n",
    "X_train_std= np.std(X,axis=0)\n",
    "X_n = (X_noisy-X_train_mu)/X_train_std\n",
    "tX_n = torch.Tensor(X_n).to(device)\n",
    "\n",
    "COT_pred0 = COT_model0.predict(X_noisy)[:,:,4]\n",
    "COT_pred1 = COT_model1.predict(X_noisy)[:,:,4]\n",
    "COT_pred2 = COT_model2.predict(X_noisy)[:,:,4]\n",
    "COT_pred3 = COT_model3.predict(X_noisy)[:,:,4]\n",
    "COT_pred4 = COT_model4.predict(X_noisy)[:,:,4]\n",
    "COT_pred = COT_pred0\n",
    "#COT_pred = (COT_pred0+COT_pred1+COT_pred2+COT_pred3+COT_pred4)/5\n",
    "\n",
    "COT_pred0_smhi = 50*model0(tX_n).cpu().detach().numpy()\n",
    "\n",
    "\n",
    "#print different error metrics\n",
    "print('Stats for our alg:')\n",
    "print('MAE = ' +str(np.mean(np.abs(COT_pred[:,0]-trueCOT))))\n",
    "print('RMSE = ' + str(np.sqrt(mean_squared_error(COT_pred[:,0],trueCOT))))\n",
    "criterion = nn.L1Loss().to(device)\n",
    "print('L1 loss = ' + str(criterion(torch.tensor(COT_pred[:,0],dtype=torch.float,device=device),torch.tensor(trueCOT,dtype=torch.float,device=device)).cpu().detach().numpy().item()))\n",
    "\n",
    "print('Stats for Aleksis alg:')\n",
    "print('MAE = ' +str(np.mean(np.abs(COT_pred0_smhi[:,0]-trueCOT))))\n",
    "print('RMSE = ' + str(np.sqrt(mean_squared_error(COT_pred0_smhi[:,0],trueCOT))))\n",
    "criterion = nn.L1Loss().to(device)\n",
    "print('L1 loss = ' + str(criterion(torch.tensor(COT_pred0_smhi[:,0],dtype=torch.float,device=device),torch.tensor(trueCOT,dtype=torch.float,device=device)).cpu().detach().numpy().item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 200000 and the array at index 1 has size 20000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Add COT-estimation to X\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_wcot \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mCOT_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m X_test \u001b[38;5;241m=\u001b[39m X_wcot[testidx,:]\n\u001b[1;32m      4\u001b[0m y_test \u001b[38;5;241m=\u001b[39m y[testidx,:]\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 200000 and the array at index 1 has size 20000"
     ]
    }
   ],
   "source": [
    "#Add COT-estimation to X\n",
    "X_wcot = np.concatenate((X,COT_pred),axis=1)\n",
    "X_test = X_wcot[testidx,:]\n",
    "y_test = y[testidx,:]\n",
    "\n",
    "#Add noise to X_test\n",
    "X_test = X_test + np.random.randn(np.shape(X_test)[0],np.shape(X_test)[1]) * np.mean(X_wcot,axis=0)*0.03\n",
    "\n",
    "np.shape(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles=np.array([0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9])\n",
    "no_nodes=100\n",
    "est= np.where(quantiles==0.5)[0].item()\n",
    "\n",
    "sequence= lambda: nn.Sequential(\n",
    "    nn.Linear(len(X_wcot[0,:]),no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(no_nodes, len(quantiles)*len(y_cols)) #Output dimesion is number of quantiles times number of target variables\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 100%|██████████| 320/320 [00:00<00:00, 360.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [8.485631] Validation loss [8.461695]\n",
      "Epoch 362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 100%|██████████| 320/320 [00:00<00:00, 364.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [8.449384] Validation loss [8.564287]\n",
      "Epoch 363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:00<00:00, 362.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [8.474473] Validation loss [8.601286]\n",
      "Epoch 364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 100%|██████████| 320/320 [00:00<00:00, 362.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [8.474639] Validation loss [8.580434]\n",
      "Epoch 365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 100%|██████████| 320/320 [00:00<00:00, 362.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [8.465659] Validation loss [8.563169]\n",
      "Epoch 366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 100%|██████████| 320/320 [00:00<00:00, 361.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [8.446693] Validation loss [8.5077095]\n",
      "Epoch 367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 100%|██████████| 320/320 [00:00<00:00, 362.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [8.463192] Validation loss [8.563638]\n",
      "Epoch 368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 100%|██████████| 320/320 [00:00<00:00, 363.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [8.4563] Validation loss [8.527656]\n",
      "Epoch 369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 100%|██████████| 320/320 [00:00<00:00, 362.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [8.487512] Validation loss [8.542857]\n",
      "Epoch 370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 100%|██████████| 320/320 [00:00<00:00, 348.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [8.459714] Validation loss [8.434978]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---No improvement in 100 epochs, broke early---\n",
      "Best model out of total max epochs found at epoch 270\n",
      "With validation loss: 8.409407615661621\n"
     ]
    }
   ],
   "source": [
    "val_size=0.1\n",
    "lr_s=[0.003]\n",
    "num_models=5 #Set number of ensambles\n",
    "batch_size=500\n",
    "nepochs=1000\n",
    "lr=0.003\n",
    "noise_ratio = 0.03\n",
    "early_break=True\n",
    "\n",
    "looped_metric=\"Loop_learning_rate_w_COT\"\n",
    "main_filepath='pytorch_models/'+looped_metric\n",
    "\n",
    "model_metrics=pd.DataFrame(columns=['Ensemble_mean','Ensemble_index',looped_metric,'MSE','PSNR','R2_score','Mean_Quantile_Loss','Quant_Rate','Quantiles'])\n",
    "for lr in lr_s:\n",
    "\n",
    "    \n",
    "    models=[QuantileNetwork(quantiles=quantiles) for _ in range(num_models)]\n",
    "    preds_total=[]\n",
    "    for i,model in enumerate(models):       \n",
    "\n",
    "        model.fit(X_wcot,y, \n",
    "            train_indices=trainidx, \n",
    "            validation_indices=validx, \n",
    "            batch_size=batch_size,\n",
    "            nepochs=nepochs,\n",
    "            sequence=sequence(),\n",
    "            lr=lr,\n",
    "            noise_ratio=noise_ratio,\n",
    "            early_break=early_break)\n",
    "        \n",
    "        filepath=main_filepath+'/'+str(lr)+'/model'+str(i)\n",
    "        os.makedirs(filepath,exist_ok=True)\n",
    "        torch.save(model,filepath+'/model_file')\n",
    "\n",
    "        preds = model.predict(X_test)\n",
    "        if i==0:\n",
    "            preds_total=preds\n",
    "        else:\n",
    "            preds_total=preds_total+preds\n",
    "\n",
    "        mse=mean_squared_error(y_test,preds[:,:,est])\n",
    "        psnr=QuantileNetwork.PSNR(y_test,preds[:,:,est])\n",
    "        r2=r2_score(y_test,preds[:,:,est])\n",
    "        mean_quantile=QuantileNetwork.mean_marginal_loss(y_test,preds,quantiles)\n",
    "        quant_rate=QuantileNetwork.quant_rate(y_test,preds)\n",
    "\n",
    "        tmp_metrics=pd.DataFrame(data=[[False,i,lr,mse,psnr,r2,mean_quantile,quant_rate,quantiles]],columns=['Ensemble_mean','Ensemble_index',looped_metric,'MSE','PSNR','R2_score','Mean_Quantile_Loss','Quant_Rate','Quantiles'])\n",
    "        model_metrics=pd.concat([model_metrics,tmp_metrics])\n",
    "    \n",
    "    preds_total=preds_total/num_models\n",
    "\n",
    "    mse=mean_squared_error(y_test,preds_total[:,:,est])\n",
    "    psnr=QuantileNetwork.PSNR(y_test,preds_total[:,:,est])\n",
    "    r2=r2_score(y_test,preds_total[:,:,est])\n",
    "    mean_quantile=QuantileNetwork.mean_marginal_loss(y_test,preds_total,quantiles)\n",
    "    quant_rate=QuantileNetwork.quant_rate(y_test,preds_total)\n",
    "\n",
    "    tmp_metrics=pd.DataFrame(data=[[True,np.nan,lr,mse,psnr,r2,mean_quantile,quant_rate,quantiles]],columns=['Ensemble_mean','Ensemble_index',looped_metric,'MSE','PSNR','R2_score','Mean_Quantile_Loss','Quant_Rate','Quantiles'])\n",
    "    model_metrics=pd.concat([model_metrics,tmp_metrics])\n",
    "\n",
    "\n",
    "model_metrics=model_metrics.reset_index(drop=True)\n",
    "model_metrics.to_csv(main_filepath+'/model_metrics.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ensemble_mean</th>\n",
       "      <th>Ensemble_index</th>\n",
       "      <th>Loop_learning_rate_w_COT</th>\n",
       "      <th>MSE</th>\n",
       "      <th>PSNR</th>\n",
       "      <th>R2_score</th>\n",
       "      <th>Mean_Quantile_Loss</th>\n",
       "      <th>Quant_Rate</th>\n",
       "      <th>Quantiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.007889</td>\n",
       "      <td>21.060109</td>\n",
       "      <td>0.815219</td>\n",
       "      <td>1.770330</td>\n",
       "      <td>[0.11910416666666666, 0.21740833333333334, 0.3...</td>\n",
       "      <td>[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.007770</td>\n",
       "      <td>21.126184</td>\n",
       "      <td>0.817985</td>\n",
       "      <td>1.757368</td>\n",
       "      <td>[0.09772916666666667, 0.18453333333333333, 0.2...</td>\n",
       "      <td>[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.007859</td>\n",
       "      <td>21.076680</td>\n",
       "      <td>0.816533</td>\n",
       "      <td>1.762746</td>\n",
       "      <td>[0.106625, 0.198825, 0.30085, 0.39775416666666...</td>\n",
       "      <td>[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.007743</td>\n",
       "      <td>21.140856</td>\n",
       "      <td>0.818673</td>\n",
       "      <td>1.763871</td>\n",
       "      <td>[0.0999, 0.1938125, 0.30750833333333333, 0.403...</td>\n",
       "      <td>[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.007702</td>\n",
       "      <td>21.164437</td>\n",
       "      <td>0.819779</td>\n",
       "      <td>1.760423</td>\n",
       "      <td>[0.09139166666666666, 0.18505, 0.2847791666666...</td>\n",
       "      <td>[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>21.349001</td>\n",
       "      <td>0.827284</td>\n",
       "      <td>1.697924</td>\n",
       "      <td>[0.08546666666666666, 0.17257916666666667, 0.2...</td>\n",
       "      <td>[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ensemble_mean Ensemble_index  Loop_learning_rate_w_COT       MSE       PSNR  \\\n",
       "0         False              0                     0.003  0.007889  21.060109   \n",
       "1         False              1                     0.003  0.007770  21.126184   \n",
       "2         False              2                     0.003  0.007859  21.076680   \n",
       "3         False              3                     0.003  0.007743  21.140856   \n",
       "4         False              4                     0.003  0.007702  21.164437   \n",
       "5          True            NaN                     0.003  0.007381  21.349001   \n",
       "\n",
       "   R2_score  Mean_Quantile_Loss  \\\n",
       "0  0.815219            1.770330   \n",
       "1  0.817985            1.757368   \n",
       "2  0.816533            1.762746   \n",
       "3  0.818673            1.763871   \n",
       "4  0.819779            1.760423   \n",
       "5  0.827284            1.697924   \n",
       "\n",
       "                                          Quant_Rate  \\\n",
       "0  [0.11910416666666666, 0.21740833333333334, 0.3...   \n",
       "1  [0.09772916666666667, 0.18453333333333333, 0.2...   \n",
       "2  [0.106625, 0.198825, 0.30085, 0.39775416666666...   \n",
       "3  [0.0999, 0.1938125, 0.30750833333333333, 0.403...   \n",
       "4  [0.09139166666666666, 0.18505, 0.2847791666666...   \n",
       "5  [0.08546666666666666, 0.17257916666666667, 0.2...   \n",
       "\n",
       "                                       Quantiles  \n",
       "0  [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]  \n",
       "1  [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]  \n",
       "2  [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]  \n",
       "3  [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]  \n",
       "4  [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]  \n",
       "5  [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 33041, 146492, 150424, ..., 123473,  65089,  52290])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 13:56:14.648956: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-08 13:56:14.683152: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-08 13:56:14.683169: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-08 13:56:14.683985: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-08 13:56:14.689743: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-08 13:56:15.365121: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "\n",
    "from functions.parse_data import synth_dataloader\n",
    "from multivariate_quantile_regression.network_model import QuantileNetwork\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from cot_train.utils import MLP5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n",
      "Tensor is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    # CUDA is available, so let's set default device to GPU\n",
    "    torch.set_default_device(0)\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "else:\n",
    "    # CUDA is not available, so let's use the CPU\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "# Example usage:\n",
    "tensor = torch.randn(3, 3)  # Create a tensor on the selected device\n",
    "print(\"Tensor is on device:\", tensor.device)\n",
    "device = tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cloud_B02</th>\n",
       "      <th>Cloud_B03</th>\n",
       "      <th>Cloud_B04</th>\n",
       "      <th>Cloud_B05</th>\n",
       "      <th>Cloud_B06</th>\n",
       "      <th>Cloud_B07</th>\n",
       "      <th>Cloud_B08</th>\n",
       "      <th>Cloud_B08A</th>\n",
       "      <th>Cloud_B09</th>\n",
       "      <th>Cloud_B10</th>\n",
       "      <th>...</th>\n",
       "      <th>Clear_B11</th>\n",
       "      <th>Clear_B12</th>\n",
       "      <th>Sat_Zenith_Angle</th>\n",
       "      <th>Sun_Zenith_Angle</th>\n",
       "      <th>Azimuth_Diff_Angle</th>\n",
       "      <th>COT</th>\n",
       "      <th>Cloud_Type</th>\n",
       "      <th>Profile_ID</th>\n",
       "      <th>GOT</th>\n",
       "      <th>Water_Vapor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.90032</td>\n",
       "      <td>0.81937</td>\n",
       "      <td>0.88448</td>\n",
       "      <td>0.89139</td>\n",
       "      <td>0.91441</td>\n",
       "      <td>0.92868</td>\n",
       "      <td>0.89153</td>\n",
       "      <td>0.94145</td>\n",
       "      <td>0.38836</td>\n",
       "      <td>0.00412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.49194</td>\n",
       "      <td>0.59996</td>\n",
       "      <td>14.16</td>\n",
       "      <td>68.38</td>\n",
       "      <td>17.39</td>\n",
       "      <td>0.383</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.50882</td>\n",
       "      <td>0.48280</td>\n",
       "      <td>0.50241</td>\n",
       "      <td>0.50951</td>\n",
       "      <td>0.53268</td>\n",
       "      <td>0.55200</td>\n",
       "      <td>0.53915</td>\n",
       "      <td>0.57368</td>\n",
       "      <td>0.38162</td>\n",
       "      <td>0.09903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.47565</td>\n",
       "      <td>0.36631</td>\n",
       "      <td>14.46</td>\n",
       "      <td>48.11</td>\n",
       "      <td>134.05</td>\n",
       "      <td>11.760</td>\n",
       "      <td>2</td>\n",
       "      <td>5325</td>\n",
       "      <td>0.129</td>\n",
       "      <td>4.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.29507</td>\n",
       "      <td>0.30924</td>\n",
       "      <td>0.39888</td>\n",
       "      <td>0.47970</td>\n",
       "      <td>0.70832</td>\n",
       "      <td>0.80920</td>\n",
       "      <td>0.78422</td>\n",
       "      <td>0.88195</td>\n",
       "      <td>0.24766</td>\n",
       "      <td>0.00405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.85240</td>\n",
       "      <td>0.55603</td>\n",
       "      <td>4.06</td>\n",
       "      <td>62.25</td>\n",
       "      <td>110.10</td>\n",
       "      <td>2.322</td>\n",
       "      <td>3</td>\n",
       "      <td>472</td>\n",
       "      <td>0.124</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.49327</td>\n",
       "      <td>0.45420</td>\n",
       "      <td>0.47264</td>\n",
       "      <td>0.47603</td>\n",
       "      <td>0.54040</td>\n",
       "      <td>0.57843</td>\n",
       "      <td>0.53577</td>\n",
       "      <td>0.60191</td>\n",
       "      <td>0.17078</td>\n",
       "      <td>0.00039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.52631</td>\n",
       "      <td>0.28269</td>\n",
       "      <td>11.69</td>\n",
       "      <td>67.75</td>\n",
       "      <td>171.25</td>\n",
       "      <td>14.460</td>\n",
       "      <td>1</td>\n",
       "      <td>9224</td>\n",
       "      <td>0.124</td>\n",
       "      <td>6.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.42440</td>\n",
       "      <td>0.46368</td>\n",
       "      <td>0.55680</td>\n",
       "      <td>0.66378</td>\n",
       "      <td>0.99693</td>\n",
       "      <td>1.10311</td>\n",
       "      <td>1.06547</td>\n",
       "      <td>1.11276</td>\n",
       "      <td>0.51378</td>\n",
       "      <td>0.00201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.96576</td>\n",
       "      <td>0.84695</td>\n",
       "      <td>2.06</td>\n",
       "      <td>31.39</td>\n",
       "      <td>60.48</td>\n",
       "      <td>4.085</td>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.57723</td>\n",
       "      <td>0.56114</td>\n",
       "      <td>0.58273</td>\n",
       "      <td>0.59771</td>\n",
       "      <td>0.69069</td>\n",
       "      <td>0.74887</td>\n",
       "      <td>0.70231</td>\n",
       "      <td>0.79981</td>\n",
       "      <td>0.37254</td>\n",
       "      <td>0.04232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.60220</td>\n",
       "      <td>0.43186</td>\n",
       "      <td>4.28</td>\n",
       "      <td>31.34</td>\n",
       "      <td>121.12</td>\n",
       "      <td>12.575</td>\n",
       "      <td>2</td>\n",
       "      <td>7450</td>\n",
       "      <td>0.124</td>\n",
       "      <td>4.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.22774</td>\n",
       "      <td>0.21962</td>\n",
       "      <td>0.21671</td>\n",
       "      <td>0.28301</td>\n",
       "      <td>0.44403</td>\n",
       "      <td>0.49655</td>\n",
       "      <td>0.47319</td>\n",
       "      <td>0.53980</td>\n",
       "      <td>0.09922</td>\n",
       "      <td>0.00088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75935</td>\n",
       "      <td>0.51803</td>\n",
       "      <td>11.32</td>\n",
       "      <td>77.27</td>\n",
       "      <td>76.27</td>\n",
       "      <td>0.409</td>\n",
       "      <td>2</td>\n",
       "      <td>3915</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.45606</td>\n",
       "      <td>0.42810</td>\n",
       "      <td>0.52413</td>\n",
       "      <td>0.58870</td>\n",
       "      <td>0.70659</td>\n",
       "      <td>0.74662</td>\n",
       "      <td>0.71055</td>\n",
       "      <td>0.75669</td>\n",
       "      <td>0.35452</td>\n",
       "      <td>0.02653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.84929</td>\n",
       "      <td>0.59307</td>\n",
       "      <td>7.30</td>\n",
       "      <td>71.64</td>\n",
       "      <td>84.00</td>\n",
       "      <td>10.886</td>\n",
       "      <td>1</td>\n",
       "      <td>2477</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.19051</td>\n",
       "      <td>0.13602</td>\n",
       "      <td>0.11961</td>\n",
       "      <td>0.13199</td>\n",
       "      <td>0.16400</td>\n",
       "      <td>0.17147</td>\n",
       "      <td>0.16864</td>\n",
       "      <td>0.17660</td>\n",
       "      <td>0.08699</td>\n",
       "      <td>0.00207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.19513</td>\n",
       "      <td>0.14873</td>\n",
       "      <td>5.85</td>\n",
       "      <td>80.11</td>\n",
       "      <td>54.84</td>\n",
       "      <td>1.421</td>\n",
       "      <td>5</td>\n",
       "      <td>3165</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.47401</td>\n",
       "      <td>0.42948</td>\n",
       "      <td>0.48083</td>\n",
       "      <td>0.50990</td>\n",
       "      <td>0.54598</td>\n",
       "      <td>0.56741</td>\n",
       "      <td>0.56494</td>\n",
       "      <td>0.58547</td>\n",
       "      <td>0.36209</td>\n",
       "      <td>0.04438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53375</td>\n",
       "      <td>0.39198</td>\n",
       "      <td>5.03</td>\n",
       "      <td>70.37</td>\n",
       "      <td>31.65</td>\n",
       "      <td>13.598</td>\n",
       "      <td>2</td>\n",
       "      <td>1139</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cloud_B02  Cloud_B03  Cloud_B04  Cloud_B05  Cloud_B06  Cloud_B07  \\\n",
       "0    0.90032    0.81937    0.88448    0.89139    0.91441    0.92868   \n",
       "1    0.50882    0.48280    0.50241    0.50951    0.53268    0.55200   \n",
       "2    0.29507    0.30924    0.39888    0.47970    0.70832    0.80920   \n",
       "3    0.49327    0.45420    0.47264    0.47603    0.54040    0.57843   \n",
       "4    0.42440    0.46368    0.55680    0.66378    0.99693    1.10311   \n",
       "5    0.57723    0.56114    0.58273    0.59771    0.69069    0.74887   \n",
       "6    0.22774    0.21962    0.21671    0.28301    0.44403    0.49655   \n",
       "7    0.45606    0.42810    0.52413    0.58870    0.70659    0.74662   \n",
       "8    0.19051    0.13602    0.11961    0.13199    0.16400    0.17147   \n",
       "9    0.47401    0.42948    0.48083    0.50990    0.54598    0.56741   \n",
       "\n",
       "   Cloud_B08  Cloud_B08A  Cloud_B09  Cloud_B10  ...  Clear_B11  Clear_B12  \\\n",
       "0    0.89153     0.94145    0.38836    0.00412  ...    0.49194    0.59996   \n",
       "1    0.53915     0.57368    0.38162    0.09903  ...    0.47565    0.36631   \n",
       "2    0.78422     0.88195    0.24766    0.00405  ...    0.85240    0.55603   \n",
       "3    0.53577     0.60191    0.17078    0.00039  ...    0.52631    0.28269   \n",
       "4    1.06547     1.11276    0.51378    0.00201  ...    0.96576    0.84695   \n",
       "5    0.70231     0.79981    0.37254    0.04232  ...    0.60220    0.43186   \n",
       "6    0.47319     0.53980    0.09922    0.00088  ...    0.75935    0.51803   \n",
       "7    0.71055     0.75669    0.35452    0.02653  ...    0.84929    0.59307   \n",
       "8    0.16864     0.17660    0.08699    0.00207  ...    0.19513    0.14873   \n",
       "9    0.56494     0.58547    0.36209    0.04438  ...    0.53375    0.39198   \n",
       "\n",
       "   Sat_Zenith_Angle  Sun_Zenith_Angle  Azimuth_Diff_Angle     COT  Cloud_Type  \\\n",
       "0             14.16             68.38               17.39   0.383           3   \n",
       "1             14.46             48.11              134.05  11.760           2   \n",
       "2              4.06             62.25              110.10   2.322           3   \n",
       "3             11.69             67.75              171.25  14.460           1   \n",
       "4              2.06             31.39               60.48   4.085           5   \n",
       "5              4.28             31.34              121.12  12.575           2   \n",
       "6             11.32             77.27               76.27   0.409           2   \n",
       "7              7.30             71.64               84.00  10.886           1   \n",
       "8              5.85             80.11               54.84   1.421           5   \n",
       "9              5.03             70.37               31.65  13.598           2   \n",
       "\n",
       "   Profile_ID    GOT  Water_Vapor  \n",
       "0         642  0.127         0.49  \n",
       "1        5325  0.129         4.86  \n",
       "2         472  0.124         1.17  \n",
       "3        9224  0.124         6.23  \n",
       "4          51  0.099         0.75  \n",
       "5        7450  0.124         4.30  \n",
       "6        3915  0.125         1.32  \n",
       "7        2477  0.123         0.67  \n",
       "8        3165  0.121         0.57  \n",
       "9        1139  0.111         0.41  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data and inspect\n",
    "df = synth_dataloader('SMHIdata3_newsurf')\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set columns for X and y (input/output features)\n",
    "X_cols = ['Cloud_B02','Cloud_B03','Cloud_B04','Cloud_B05','Cloud_B06',\n",
    "          'Cloud_B07','Cloud_B08','Cloud_B08A','Cloud_B09','Cloud_B10','Cloud_B11','Cloud_B12','Sun_Zenith_Angle']\n",
    "y_cols = ['Clear_B02','Clear_B03','Clear_B04','Clear_B05','Clear_B06',\n",
    "          'Clear_B07','Clear_B08','Clear_B08A','Clear_B09','Clear_B10','Clear_B11','Clear_B12']\n",
    "\n",
    "#Find X and y\n",
    "X=df[X_cols]\n",
    "y=df[y_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Set up paths for importing COT est models\n",
    "#COT_model_paths = ['smhi_models3/0/model_it_2000000','smhi_models3/1/model_it_2000000','smhi_models3/2/model_it_2000000','smhi_models3/3/model_it_2000000','smhi_models3/4/model_it_2000000',\n",
    "#                   'smhi_models3/5/model_it_2000000','smhi_models3/6/model_it_2000000','smhi_models3/7/model_it_2000000','smhi_models3/8/model_it_2000000','smhi_models3/9/model_it_2000000']\n",
    "\n",
    "COT_model_paths = ['smhi_models4/0/model_it_2000000','smhi_models4/1/model_it_2000000','smhi_models4/2/model_it_2000000','smhi_models4/3/model_it_2000000','smhi_models4/4/model_it_2000000']\n",
    "\n",
    "\n",
    "\n",
    "#Initialize and load COT estimation models\n",
    "COT_est_models = [MLP5(13, 1, apply_relu=True) for _ in range(len(COT_model_paths))]\n",
    "for i,model in enumerate(COT_est_models):\n",
    "    model.load_state_dict(torch.load(COT_model_paths[i],map_location=device))\n",
    "\n",
    "#Create X for COT estimation\n",
    "X_COTest = X.to_numpy()\n",
    "#Add noise for fairness\n",
    "X_COTest= X_COTest + np.random.randn(np.shape(X_COTest)[0],np.shape(X_COTest)[1]) * np.mean(X_COTest,axis=0)*0.03\n",
    "#Normalize and turn into tensor before input\n",
    "X_COTest_mu = np.mean(X_COTest,axis=0)\n",
    "X_COTest_std = np.std(X_COTest,axis=0)\n",
    "X_COTest_norm = (X_COTest-X_COTest_mu)/X_COTest_std\n",
    "tX_COTest_norm = torch.Tensor(X_COTest_norm).to(device)\n",
    "#Make predictions (*50 to denormalize predictions)\n",
    "COT_preds_total = []\n",
    "for i,model in enumerate(COT_est_models):\n",
    "    COT_preds = 50*model(tX_COTest_norm).cpu().detach().numpy()\n",
    "    #Keep track of ensemble prediction\n",
    "    if i==0:\n",
    "        COT_preds_total=COT_preds\n",
    "    else:\n",
    "        COT_preds_total=COT_preds_total+COT_preds\n",
    "\n",
    "COT_preds_total = COT_preds_total/len(COT_est_models)\n",
    "\n",
    "#Sort into categories instead\n",
    "t_is_cloud = 0.025*50 #From Pirinen et. al.\n",
    "t_thin_cloud = 0.015*50 #From Pirinen et. al.\n",
    "\n",
    "pred_clear = np.zeros(COT_preds_total.shape)\n",
    "pred_thin = np.zeros(COT_preds_total.shape)\n",
    "pred_thick = np.zeros(COT_preds_total.shape)\n",
    "\n",
    "pred_clear[COT_preds_total<t_thin_cloud]=1\n",
    "pred_thin[(COT_preds_total>=t_thin_cloud)&(COT_preds_total<t_is_cloud)]=1\n",
    "pred_thick[COT_preds_total>=t_is_cloud]=1\n",
    "\n",
    "#Create new X including COT dummies\n",
    "X = X.assign(Clear=pred_clear[:,0])\n",
    "X = X.assign(Thin=pred_thin[:,0])\n",
    "X = X.assign(Thick=pred_thick[:,0])\n",
    "\n",
    "#Update X_cols\n",
    "X_cols = ['Cloud_B02','Cloud_B03','Cloud_B04','Cloud_B05','Cloud_B06',\n",
    "          'Cloud_B07','Cloud_B08','Cloud_B08A','Cloud_B09','Cloud_B10','Cloud_B11','Cloud_B12',\n",
    "          'Sun_Zenith_Angle','Clear','Thin','Thick']\n",
    "\n",
    "'''\n",
    "\n",
    "#Separate testdata from rest for 80/10/10 Train/Val/Test split\n",
    "X_trainval, X_test, y_trainval, y_test=train_test_split(X,y,test_size=0.1,random_state=313)\n",
    "\n",
    "#Remove 25%\n",
    "X_trainval = X_trainval.iloc[: -int(X_trainval.shape[0] * 0.75), :]\n",
    "y_trainval = y_trainval.iloc[: -int(y_trainval.shape[0] * 0.75), :]\n",
    "\n",
    "#Find clear indices in trainval\n",
    "clear_indices = np.array([])\n",
    "for i,df_idx in enumerate(X_trainval.index):\n",
    "    if df['Cloud_Type'][df_idx]==0:\n",
    "        clear_indices=np.append(clear_indices,i)\n",
    "\n",
    "#Add noise to X_test, 0 mean with stdev equal to 3% of mean of each feature\n",
    "np.random.seed(313)\n",
    "X_test.iloc[:,:13] = X_test.iloc[:,:13] + np.random.randn(np.shape(X_test.iloc[:,:13])[0],np.shape(X_test.iloc[:,:13])[1]) * np.mean(X.iloc[:,:13].to_numpy(),axis=0)*0.03\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 100%|██████████| 50/50 [00:00<00:00, 305.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.4522178] Validation loss [2.7299142]\n",
      "Epoch 322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 100%|██████████| 50/50 [00:00<00:00, 306.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.4548113] Validation loss [2.7009661]\n",
      "Epoch 323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 100%|██████████| 50/50 [00:00<00:00, 305.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.4462059] Validation loss [2.7024176]\n",
      "Epoch 324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 100%|██████████| 50/50 [00:00<00:00, 306.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.4656432] Validation loss [2.697497]\n",
      "Epoch 325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 100%|██████████| 50/50 [00:00<00:00, 307.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.4529986] Validation loss [2.703104]\n",
      "---No improvement in 100 epochs, broke early---\n",
      "Best model out of total max epochs found at epoch 225\n",
      "With validation loss: 2.6381125450134277\n"
     ]
    }
   ],
   "source": [
    "#Choose if to save models and data, if so set path\n",
    "save = True\n",
    "if save:\n",
    "    test_name = \"Ultimate_model_025\"\n",
    "    main_filepath = 'pytorch_models/'+test_name\n",
    "\n",
    "#Set up which quantiles to estimate, and find index of estimator (q=0.5)\n",
    "quantiles=np.array([0.1,0.5,0.9])\n",
    "est= np.where(quantiles==0.5)[0].item()\n",
    "\n",
    "#Set up algorithm parameters\n",
    "val_size=0.1\n",
    "num_models=10\n",
    "batch_size=500\n",
    "nepochs=1000\n",
    "lr=0.002\n",
    "noise_ratio = 0.03\n",
    "early_break=True\n",
    "no_nodes = 200\n",
    "clear_noise=True\n",
    "\n",
    "#Create network\n",
    "sequence= lambda: nn.Sequential(\n",
    "    nn.Linear(len(X_cols),no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(no_nodes),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(no_nodes),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(no_nodes),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(no_nodes),\n",
    "    nn.Linear(no_nodes, len(quantiles)*len(y_cols)) #Output dimesion is number of quantiles times number of target variables\n",
    ")\n",
    "\n",
    "#Initalize models\n",
    "models = [QuantileNetwork(quantiles=quantiles) for _ in range(num_models)]\n",
    "\n",
    "#Train models\n",
    "for i,model in enumerate(models):\n",
    "    #Find new train/val splits for each model for robustness\n",
    "    validation_indices=np.array(random.sample(range(len(X_trainval['Cloud_B02'])), int(len(X['Cloud_B02'])*val_size)))\n",
    "    train_indices=[i for i in range(len(X_trainval['Cloud_B02'])) if np.any(validation_indices==i)==False]  \n",
    "    #Fit model with X\n",
    "    model.fit(X_trainval.to_numpy(),y_trainval.to_numpy(), \n",
    "            train_indices=train_indices, \n",
    "            validation_indices=validation_indices, \n",
    "            batch_size=batch_size,\n",
    "            nepochs=nepochs,\n",
    "            sequence=sequence(),\n",
    "            lr=lr,\n",
    "            noise_ratio=noise_ratio,\n",
    "            early_break=early_break,\n",
    "            clear_noise=clear_noise,\n",
    "            clear_indices=clear_indices)\n",
    "    \n",
    "    #Save models if wanted\n",
    "    if save:\n",
    "        filepath=main_filepath+'/model'+str(i)\n",
    "        os.makedirs(filepath,exist_ok=True)\n",
    "        torch.save(model,filepath+'/model_file')\n",
    "\n",
    "#Finally save data if wanted\n",
    "if save: \n",
    "    filepath=main_filepath+'/data'\n",
    "    os.makedirs(filepath,exist_ok=True)\n",
    "    #Save datasplits\n",
    "    X_trainval.to_csv(filepath+'/X_trainval.csv')\n",
    "    y_trainval.to_csv(filepath+'/y_trainval.csv')\n",
    "    X_test.to_csv(filepath+'/X_test.csv')\n",
    "    y_test.to_csv(filepath+'/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(model.train_loss.cpu())\n",
    "plt.plot(model.val_loss.cpu())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

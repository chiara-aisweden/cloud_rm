{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 09:23:02.943310: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-06 09:23:02.976091: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-06 09:23:02.976108: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-06 09:23:02.976922: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-06 09:23:02.982616: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-06 09:23:03.658887: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "\n",
    "from functions.parse_data import synth_dataloader\n",
    "from multivariate_quantile_regression.network_model import QuantileNetwork\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from cot_train.utils import MLP5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n",
      "Tensor is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    # CUDA is available, so let's set default device to GPU\n",
    "    torch.set_default_device(0)\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "else:\n",
    "    # CUDA is not available, so let's use the CPU\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "# Example usage:\n",
    "tensor = torch.randn(3, 3)  # Create a tensor on the selected device\n",
    "print(\"Tensor is on device:\", tensor.device)\n",
    "device = tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cloud_B02</th>\n",
       "      <th>Cloud_B03</th>\n",
       "      <th>Cloud_B04</th>\n",
       "      <th>Cloud_B05</th>\n",
       "      <th>Cloud_B06</th>\n",
       "      <th>Cloud_B07</th>\n",
       "      <th>Cloud_B08</th>\n",
       "      <th>Cloud_B08A</th>\n",
       "      <th>Cloud_B09</th>\n",
       "      <th>Cloud_B10</th>\n",
       "      <th>...</th>\n",
       "      <th>Clear_B11</th>\n",
       "      <th>Clear_B12</th>\n",
       "      <th>Sat_Zenith_Angle</th>\n",
       "      <th>Sun_Zenith_Angle</th>\n",
       "      <th>Azimuth_Diff_Angle</th>\n",
       "      <th>COT</th>\n",
       "      <th>Cloud_Type</th>\n",
       "      <th>Profile_ID</th>\n",
       "      <th>GOT</th>\n",
       "      <th>Water_Vapor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.90032</td>\n",
       "      <td>0.81937</td>\n",
       "      <td>0.88448</td>\n",
       "      <td>0.89139</td>\n",
       "      <td>0.91441</td>\n",
       "      <td>0.92868</td>\n",
       "      <td>0.89153</td>\n",
       "      <td>0.94145</td>\n",
       "      <td>0.38836</td>\n",
       "      <td>0.00412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.49194</td>\n",
       "      <td>0.59996</td>\n",
       "      <td>14.16</td>\n",
       "      <td>68.38</td>\n",
       "      <td>17.39</td>\n",
       "      <td>0.383</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.50882</td>\n",
       "      <td>0.48280</td>\n",
       "      <td>0.50241</td>\n",
       "      <td>0.50951</td>\n",
       "      <td>0.53268</td>\n",
       "      <td>0.55200</td>\n",
       "      <td>0.53915</td>\n",
       "      <td>0.57368</td>\n",
       "      <td>0.38162</td>\n",
       "      <td>0.09903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.47565</td>\n",
       "      <td>0.36631</td>\n",
       "      <td>14.46</td>\n",
       "      <td>48.11</td>\n",
       "      <td>134.05</td>\n",
       "      <td>11.760</td>\n",
       "      <td>2</td>\n",
       "      <td>5325</td>\n",
       "      <td>0.129</td>\n",
       "      <td>4.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.29507</td>\n",
       "      <td>0.30924</td>\n",
       "      <td>0.39888</td>\n",
       "      <td>0.47970</td>\n",
       "      <td>0.70832</td>\n",
       "      <td>0.80920</td>\n",
       "      <td>0.78422</td>\n",
       "      <td>0.88195</td>\n",
       "      <td>0.24766</td>\n",
       "      <td>0.00405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.85240</td>\n",
       "      <td>0.55603</td>\n",
       "      <td>4.06</td>\n",
       "      <td>62.25</td>\n",
       "      <td>110.10</td>\n",
       "      <td>2.322</td>\n",
       "      <td>3</td>\n",
       "      <td>472</td>\n",
       "      <td>0.124</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.49327</td>\n",
       "      <td>0.45420</td>\n",
       "      <td>0.47264</td>\n",
       "      <td>0.47603</td>\n",
       "      <td>0.54040</td>\n",
       "      <td>0.57843</td>\n",
       "      <td>0.53577</td>\n",
       "      <td>0.60191</td>\n",
       "      <td>0.17078</td>\n",
       "      <td>0.00039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.52631</td>\n",
       "      <td>0.28269</td>\n",
       "      <td>11.69</td>\n",
       "      <td>67.75</td>\n",
       "      <td>171.25</td>\n",
       "      <td>14.460</td>\n",
       "      <td>1</td>\n",
       "      <td>9224</td>\n",
       "      <td>0.124</td>\n",
       "      <td>6.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.42440</td>\n",
       "      <td>0.46368</td>\n",
       "      <td>0.55680</td>\n",
       "      <td>0.66378</td>\n",
       "      <td>0.99693</td>\n",
       "      <td>1.10311</td>\n",
       "      <td>1.06547</td>\n",
       "      <td>1.11276</td>\n",
       "      <td>0.51378</td>\n",
       "      <td>0.00201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.96576</td>\n",
       "      <td>0.84695</td>\n",
       "      <td>2.06</td>\n",
       "      <td>31.39</td>\n",
       "      <td>60.48</td>\n",
       "      <td>4.085</td>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.57723</td>\n",
       "      <td>0.56114</td>\n",
       "      <td>0.58273</td>\n",
       "      <td>0.59771</td>\n",
       "      <td>0.69069</td>\n",
       "      <td>0.74887</td>\n",
       "      <td>0.70231</td>\n",
       "      <td>0.79981</td>\n",
       "      <td>0.37254</td>\n",
       "      <td>0.04232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.60220</td>\n",
       "      <td>0.43186</td>\n",
       "      <td>4.28</td>\n",
       "      <td>31.34</td>\n",
       "      <td>121.12</td>\n",
       "      <td>12.575</td>\n",
       "      <td>2</td>\n",
       "      <td>7450</td>\n",
       "      <td>0.124</td>\n",
       "      <td>4.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.22774</td>\n",
       "      <td>0.21962</td>\n",
       "      <td>0.21671</td>\n",
       "      <td>0.28301</td>\n",
       "      <td>0.44403</td>\n",
       "      <td>0.49655</td>\n",
       "      <td>0.47319</td>\n",
       "      <td>0.53980</td>\n",
       "      <td>0.09922</td>\n",
       "      <td>0.00088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75935</td>\n",
       "      <td>0.51803</td>\n",
       "      <td>11.32</td>\n",
       "      <td>77.27</td>\n",
       "      <td>76.27</td>\n",
       "      <td>0.409</td>\n",
       "      <td>2</td>\n",
       "      <td>3915</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.45606</td>\n",
       "      <td>0.42810</td>\n",
       "      <td>0.52413</td>\n",
       "      <td>0.58870</td>\n",
       "      <td>0.70659</td>\n",
       "      <td>0.74662</td>\n",
       "      <td>0.71055</td>\n",
       "      <td>0.75669</td>\n",
       "      <td>0.35452</td>\n",
       "      <td>0.02653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.84929</td>\n",
       "      <td>0.59307</td>\n",
       "      <td>7.30</td>\n",
       "      <td>71.64</td>\n",
       "      <td>84.00</td>\n",
       "      <td>10.886</td>\n",
       "      <td>1</td>\n",
       "      <td>2477</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.19051</td>\n",
       "      <td>0.13602</td>\n",
       "      <td>0.11961</td>\n",
       "      <td>0.13199</td>\n",
       "      <td>0.16400</td>\n",
       "      <td>0.17147</td>\n",
       "      <td>0.16864</td>\n",
       "      <td>0.17660</td>\n",
       "      <td>0.08699</td>\n",
       "      <td>0.00207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.19513</td>\n",
       "      <td>0.14873</td>\n",
       "      <td>5.85</td>\n",
       "      <td>80.11</td>\n",
       "      <td>54.84</td>\n",
       "      <td>1.421</td>\n",
       "      <td>5</td>\n",
       "      <td>3165</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.47401</td>\n",
       "      <td>0.42948</td>\n",
       "      <td>0.48083</td>\n",
       "      <td>0.50990</td>\n",
       "      <td>0.54598</td>\n",
       "      <td>0.56741</td>\n",
       "      <td>0.56494</td>\n",
       "      <td>0.58547</td>\n",
       "      <td>0.36209</td>\n",
       "      <td>0.04438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53375</td>\n",
       "      <td>0.39198</td>\n",
       "      <td>5.03</td>\n",
       "      <td>70.37</td>\n",
       "      <td>31.65</td>\n",
       "      <td>13.598</td>\n",
       "      <td>2</td>\n",
       "      <td>1139</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cloud_B02  Cloud_B03  Cloud_B04  Cloud_B05  Cloud_B06  Cloud_B07  \\\n",
       "0    0.90032    0.81937    0.88448    0.89139    0.91441    0.92868   \n",
       "1    0.50882    0.48280    0.50241    0.50951    0.53268    0.55200   \n",
       "2    0.29507    0.30924    0.39888    0.47970    0.70832    0.80920   \n",
       "3    0.49327    0.45420    0.47264    0.47603    0.54040    0.57843   \n",
       "4    0.42440    0.46368    0.55680    0.66378    0.99693    1.10311   \n",
       "5    0.57723    0.56114    0.58273    0.59771    0.69069    0.74887   \n",
       "6    0.22774    0.21962    0.21671    0.28301    0.44403    0.49655   \n",
       "7    0.45606    0.42810    0.52413    0.58870    0.70659    0.74662   \n",
       "8    0.19051    0.13602    0.11961    0.13199    0.16400    0.17147   \n",
       "9    0.47401    0.42948    0.48083    0.50990    0.54598    0.56741   \n",
       "\n",
       "   Cloud_B08  Cloud_B08A  Cloud_B09  Cloud_B10  ...  Clear_B11  Clear_B12  \\\n",
       "0    0.89153     0.94145    0.38836    0.00412  ...    0.49194    0.59996   \n",
       "1    0.53915     0.57368    0.38162    0.09903  ...    0.47565    0.36631   \n",
       "2    0.78422     0.88195    0.24766    0.00405  ...    0.85240    0.55603   \n",
       "3    0.53577     0.60191    0.17078    0.00039  ...    0.52631    0.28269   \n",
       "4    1.06547     1.11276    0.51378    0.00201  ...    0.96576    0.84695   \n",
       "5    0.70231     0.79981    0.37254    0.04232  ...    0.60220    0.43186   \n",
       "6    0.47319     0.53980    0.09922    0.00088  ...    0.75935    0.51803   \n",
       "7    0.71055     0.75669    0.35452    0.02653  ...    0.84929    0.59307   \n",
       "8    0.16864     0.17660    0.08699    0.00207  ...    0.19513    0.14873   \n",
       "9    0.56494     0.58547    0.36209    0.04438  ...    0.53375    0.39198   \n",
       "\n",
       "   Sat_Zenith_Angle  Sun_Zenith_Angle  Azimuth_Diff_Angle     COT  Cloud_Type  \\\n",
       "0             14.16             68.38               17.39   0.383           3   \n",
       "1             14.46             48.11              134.05  11.760           2   \n",
       "2              4.06             62.25              110.10   2.322           3   \n",
       "3             11.69             67.75              171.25  14.460           1   \n",
       "4              2.06             31.39               60.48   4.085           5   \n",
       "5              4.28             31.34              121.12  12.575           2   \n",
       "6             11.32             77.27               76.27   0.409           2   \n",
       "7              7.30             71.64               84.00  10.886           1   \n",
       "8              5.85             80.11               54.84   1.421           5   \n",
       "9              5.03             70.37               31.65  13.598           2   \n",
       "\n",
       "   Profile_ID    GOT  Water_Vapor  \n",
       "0         642  0.127         0.49  \n",
       "1        5325  0.129         4.86  \n",
       "2         472  0.124         1.17  \n",
       "3        9224  0.124         6.23  \n",
       "4          51  0.099         0.75  \n",
       "5        7450  0.124         4.30  \n",
       "6        3915  0.125         1.32  \n",
       "7        2477  0.123         0.67  \n",
       "8        3165  0.121         0.57  \n",
       "9        1139  0.111         0.41  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data and inspect\n",
    "df = synth_dataloader('SMHIdata3_newsurf')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set columns for X and y (input/output features)\n",
    "X_cols = ['Cloud_B02','Cloud_B03','Cloud_B04','Cloud_B05','Cloud_B06',\n",
    "          'Cloud_B07','Cloud_B08','Cloud_B08A','Cloud_B09','Cloud_B10','Cloud_B11','Cloud_B12','Sun_Zenith_Angle']\n",
    "y_cols = ['Clear_B02','Clear_B03','Clear_B04','Clear_B05','Clear_B06',\n",
    "          'Clear_B07','Clear_B08','Clear_B08A','Clear_B09','Clear_B10','Clear_B11','Clear_B12']\n",
    "\n",
    "#Find X and y\n",
    "X=df[X_cols]\n",
    "y=df[y_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Set up paths for importing COT est models\n",
    "#COT_model_paths = ['smhi_models3/0/model_it_2000000','smhi_models3/1/model_it_2000000','smhi_models3/2/model_it_2000000','smhi_models3/3/model_it_2000000','smhi_models3/4/model_it_2000000',\n",
    "#                   'smhi_models3/5/model_it_2000000','smhi_models3/6/model_it_2000000','smhi_models3/7/model_it_2000000','smhi_models3/8/model_it_2000000','smhi_models3/9/model_it_2000000']\n",
    "\n",
    "COT_model_paths = ['smhi_models4/0/model_it_2000000','smhi_models4/1/model_it_2000000','smhi_models4/2/model_it_2000000','smhi_models4/3/model_it_2000000','smhi_models4/4/model_it_2000000']\n",
    "\n",
    "\n",
    "\n",
    "#Initialize and load COT estimation models\n",
    "COT_est_models = [MLP5(13, 1, apply_relu=True) for _ in range(len(COT_model_paths))]\n",
    "for i,model in enumerate(COT_est_models):\n",
    "    model.load_state_dict(torch.load(COT_model_paths[i],map_location=device))\n",
    "\n",
    "#Create X for COT estimation\n",
    "X_COTest = X.to_numpy()\n",
    "#Add noise for fairness\n",
    "X_COTest= X_COTest + np.random.randn(np.shape(X_COTest)[0],np.shape(X_COTest)[1]) * np.mean(X_COTest,axis=0)*0.03\n",
    "#Normalize and turn into tensor before input\n",
    "X_COTest_mu = np.mean(X_COTest,axis=0)\n",
    "X_COTest_std = np.std(X_COTest,axis=0)\n",
    "X_COTest_norm = (X_COTest-X_COTest_mu)/X_COTest_std\n",
    "tX_COTest_norm = torch.Tensor(X_COTest_norm).to(device)\n",
    "#Make predictions (*50 to denormalize predictions)\n",
    "COT_preds_total = []\n",
    "for i,model in enumerate(COT_est_models):\n",
    "    COT_preds = 50*model(tX_COTest_norm).cpu().detach().numpy()\n",
    "    #Keep track of ensemble prediction\n",
    "    if i==0:\n",
    "        COT_preds_total=COT_preds\n",
    "    else:\n",
    "        COT_preds_total=COT_preds_total+COT_preds\n",
    "\n",
    "COT_preds_total = COT_preds_total/len(COT_est_models)\n",
    "\n",
    "#Sort into categories instead\n",
    "t_is_cloud = 0.025*50 #From Pirinen et. al.\n",
    "t_thin_cloud = 0.015*50 #From Pirinen et. al.\n",
    "\n",
    "pred_clear = np.zeros(COT_preds_total.shape)\n",
    "pred_thin = np.zeros(COT_preds_total.shape)\n",
    "pred_thick = np.zeros(COT_preds_total.shape)\n",
    "\n",
    "pred_clear[COT_preds_total<t_thin_cloud]=1\n",
    "pred_thin[(COT_preds_total>=t_thin_cloud)&(COT_preds_total<t_is_cloud)]=1\n",
    "pred_thick[COT_preds_total>=t_is_cloud]=1\n",
    "\n",
    "#Create new X including COT dummies\n",
    "X = X.assign(Clear=pred_clear[:,0])\n",
    "X = X.assign(Thin=pred_thin[:,0])\n",
    "X = X.assign(Thick=pred_thick[:,0])\n",
    "\n",
    "#Update X_cols\n",
    "X_cols = ['Cloud_B02','Cloud_B03','Cloud_B04','Cloud_B05','Cloud_B06',\n",
    "          'Cloud_B07','Cloud_B08','Cloud_B08A','Cloud_B09','Cloud_B10','Cloud_B11','Cloud_B12',\n",
    "          'Sun_Zenith_Angle','Clear','Thin','Thick']\n",
    "\n",
    "'''\n",
    "\n",
    "#Separate testdata from rest for 80/10/10 Train/Val/Test split\n",
    "X_trainval, X_test, y_trainval, y_test=train_test_split(X,y,test_size=0.1,random_state=313)\n",
    "\n",
    "#Find clear indices in trainval\n",
    "clear_indices = np.array([])\n",
    "for i,df_idx in enumerate(X_trainval.index):\n",
    "    if df['Cloud_Type'][df_idx]==0:\n",
    "        clear_indices=np.append(clear_indices,i)\n",
    "\n",
    "#Add noise to X_test, 0 mean with stdev equal to 3% of mean of each feature\n",
    "np.random.seed(313)\n",
    "X_test.iloc[:,:13] = X_test.iloc[:,:13] + np.random.randn(np.shape(X_test.iloc[:,:13])[0],np.shape(X_test.iloc[:,:13])[1]) * np.mean(X.iloc[:,:13].to_numpy(),axis=0)*0.03\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 311.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.480414] Validation loss [2.5157444]\n",
      "Epoch 362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 310.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.487669] Validation loss [2.5055454]\n",
      "Epoch 363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 311.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.4771035] Validation loss [2.5037994]\n",
      "Epoch 364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 310.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.487282] Validation loss [2.5170047]\n",
      "Epoch 365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 310.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.483067] Validation loss [2.5071762]\n",
      "Epoch 366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 310.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.4728584] Validation loss [2.507175]\n",
      "Epoch 367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 310.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.4813101] Validation loss [2.511864]\n",
      "Epoch 368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 310.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.482846] Validation loss [2.4881587]\n",
      "Epoch 369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch number: 100%|██████████| 320/320 [00:01<00:00, 309.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss [2.4789946] Validation loss [2.4996026]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---No improvement in 100 epochs, broke early---\n",
      "Best model out of total max epochs found at epoch 269\n",
      "With validation loss: 2.471048593521118\n"
     ]
    }
   ],
   "source": [
    "#Choose if to save models and data, if so set path\n",
    "save = True\n",
    "if save:\n",
    "    test_name = \"Ultimate_model\"\n",
    "    main_filepath = 'pytorch_models/'+test_name\n",
    "\n",
    "#Set up which quantiles to estimate, and find index of estimator (q=0.5)\n",
    "quantiles=np.array([0.1,0.5,0.9])\n",
    "est= np.where(quantiles==0.5)[0].item()\n",
    "\n",
    "#Set up algorithm parameters\n",
    "val_size=0.1\n",
    "num_models=10\n",
    "batch_size=500\n",
    "nepochs=1000\n",
    "lr=0.002\n",
    "noise_ratio = 0.03\n",
    "early_break=True\n",
    "no_nodes = 200\n",
    "clear_noise=True\n",
    "\n",
    "#Create network\n",
    "sequence= lambda: nn.Sequential(\n",
    "    nn.Linear(len(X_cols),no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(no_nodes),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(no_nodes),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(no_nodes),\n",
    "    nn.Linear(no_nodes,no_nodes),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(no_nodes),\n",
    "    nn.Linear(no_nodes, len(quantiles)*len(y_cols)) #Output dimesion is number of quantiles times number of target variables\n",
    ")\n",
    "\n",
    "#Initalize models\n",
    "models = [QuantileNetwork(quantiles=quantiles) for _ in range(num_models)]\n",
    "\n",
    "#Train models\n",
    "for i,model in enumerate(models):\n",
    "    #Find new train/val splits for each model for robustness\n",
    "    validation_indices=np.array(random.sample(range(len(X_trainval['Cloud_B02'])), int(len(X['Cloud_B02'])*val_size)))\n",
    "    train_indices=[i for i in range(len(X_trainval['Cloud_B02'])) if np.any(validation_indices==i)==False]  \n",
    "    #Fit model with X\n",
    "    model.fit(X_trainval.to_numpy(),y_trainval.to_numpy(), \n",
    "            train_indices=train_indices, \n",
    "            validation_indices=validation_indices, \n",
    "            batch_size=batch_size,\n",
    "            nepochs=nepochs,\n",
    "            sequence=sequence(),\n",
    "            lr=lr,\n",
    "            noise_ratio=noise_ratio,\n",
    "            early_break=early_break,\n",
    "            clear_noise=clear_noise,\n",
    "            clear_indices=clear_indices)\n",
    "    \n",
    "    #Save models if wanted\n",
    "    if save:\n",
    "        filepath=main_filepath+'/model'+str(i)\n",
    "        os.makedirs(filepath,exist_ok=True)\n",
    "        torch.save(model,filepath+'/model_file')\n",
    "\n",
    "#Finally save data if wanted\n",
    "if save: \n",
    "    filepath=main_filepath+'/data'\n",
    "    os.makedirs(filepath,exist_ok=True)\n",
    "    #Save datasplits\n",
    "    X_trainval.to_csv(filepath+'/X_trainval.csv')\n",
    "    y_trainval.to_csv(filepath+'/y_trainval.csv')\n",
    "    X_test.to_csv(filepath+'/X_test.csv')\n",
    "    y_test.to_csv(filepath+'/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(model.train_loss.cpu())\n",
    "plt.plot(model.val_loss.cpu())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
